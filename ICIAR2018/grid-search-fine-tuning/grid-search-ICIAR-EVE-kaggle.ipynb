{
  "cells": [
    {
      "metadata": {
        "_uuid": "b9a993d180f1a520a86812c8b22f7143bbc0020a",
        "trusted": true
      },
      "cell_type": "code",
      "source": "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\nfrom sklearn.metrics import log_loss\nimport sys\n\n\nimport os\nimport pandas as pd\n\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport skimage\nfrom skimage.transform import resize\n\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.models import load_model\nimport keras.callbacks as kcall\nfrom keras.optimizers import Adam\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\nimport matplotlib.pyplot as plt\nfrom keras.applications.resnet50 import ResNet50\nfrom keras import optimizers, metrics, models\nfrom keras.layers import Input, Flatten, Dense\nfrom keras.optimizers import SGD, Adam, rmsprop\n\n%matplotlib inline",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": "/opt/conda/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n  from ._conv import register_converters as _register_converters\nUsing TensorFlow backend.\n",
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true,
        "collapsed": true,
        "_uuid": "7b6c86f9a40f48ca6e0bb8fd1bff609ba5c6430e"
      },
      "cell_type": "code",
      "source": "import keras.backend as K\nfrom keras.optimizers import Optimizer\n\n\nclass Eve(Optimizer):\n    '''Eve optimizer.\n\n    Default parameters follow those provided in the original paper.\n\n    # Arguments\n        lr: float >= 0. Learning rate.\n        beta_1/beta_2/beta_3: floats, 0 < beta < 1. Generally close to 1.\n        small_k/big_K: floats\n        epsilon: float >= 0. Fuzz factor.\n\n    # References\n        - [Improving Stochastic Gradient Descent With FeedBack](http://arxiv.org/abs/1611.01505v1.pdf)\n    '''\n\n    def __init__(self, lr=0.001, beta_1=0.9, beta_2=0.999,\n                 beta_3=0.999, small_k=0.1, big_K=10,\n                 epsilon=1e-8, decay=0., **kwargs):\n        super(Eve, self).__init__(**kwargs)\n        self.__dict__.update(locals())\n        self.iterations = K.variable(0)\n        self.lr = K.variable(lr)\n        self.beta_1 = K.variable(beta_1)\n        self.beta_2 = K.variable(beta_2)\n        self.beta_3 = K.variable(beta_3)\n        self.small_k = K.variable(small_k)\n        self.big_K = K.variable(big_K)\n        self.decay = K.variable(decay)\n        self.inital_decay = decay\n\n    def get_updates(self, params, loss):\n        grads = self.get_gradients(loss, params)\n        self.updates = [K.update_add(self.iterations, 1)]\n\n        lr = self.lr\n        if self.inital_decay > 0:\n            lr *= (1. / (1. + self.decay * self.iterations))\n\n        t = self.iterations + 1\n        lr_t = lr * K.sqrt(1. - K.pow(self.beta_2, t)) / (1. - K.pow(self.beta_1, t))\n\n        shapes = [K.get_variable_shape(p) for p in params]\n        ms = [K.zeros(shape) for shape in shapes]\n        vs = [K.zeros(shape) for shape in shapes]\n        f = K.variable(0)\n        d = K.variable(1)\n        self.weights = [self.iterations] + ms + vs + [f, d]\n\n        cond = K.greater(t, K.variable(1))\n        small_delta_t = K.switch(K.greater(loss, f), self.small_k + 1, 1. / (self.big_K + 1))\n        big_delta_t = K.switch(K.greater(loss, f), self.big_K + 1, 1. / (self.small_k + 1))\n\n        c_t = K.minimum(K.maximum(small_delta_t, loss / (f + self.epsilon)), big_delta_t)\n        f_t = c_t * f\n        r_t = K.abs(f_t - f) / (K.minimum(f_t, f))\n        d_t = self.beta_3 * d + (1 - self.beta_3) * r_t\n\n        f_t = K.switch(cond, f_t, loss)\n        d_t = K.switch(cond, d_t, K.variable(1.))\n\n        self.updates.append(K.update(f, f_t))\n        self.updates.append(K.update(d, d_t))\n\n        for p, g, m, v in zip(params, grads, ms, vs):\n            m_t = (self.beta_1 * m) + (1. - self.beta_1) * g\n            v_t = (self.beta_2 * v) + (1. - self.beta_2) * K.square(g)\n            p_t = p - lr_t * m_t / (d_t * K.sqrt(v_t) + self.epsilon)\n\n            self.updates.append(K.update(m, m_t))\n            self.updates.append(K.update(v, v_t))\n\n            new_p = p_t\n            self.updates.append(K.update(p, new_p))\n        return self.updates\n\n    def get_config(self):\n        config = {'lr': float(K.get_value(self.lr)),\n                  'beta_1': float(K.get_value(self.beta_1)),\n                  'beta_2': float(K.get_value(self.beta_2)),\n                  'beta_3': float(K.get_value(self.beta_3)),\n                  'small_k': float(K.get_value(self.small_k)),\n                  'big_K': float(K.get_value(self.big_K)),\n                  'epsilon': self.epsilon}\n        base_config = super(Eve, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "469bc6705d524cb8739eefffb752dc19cbdd089c",
        "trusted": true
      },
      "cell_type": "code",
      "source": "print(os.listdir('../input/pretrained-models/pretrained-models'))",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": "['xception_weights_tf_dim_ordering_tf_kernels_notop.h5']\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "74272bb10a59f27d58600920f7b08105477b587b",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "## Intilizing variables\noutput_classes = 4\n# batch_size = 32 \n# epochs = 30\n\n# sgd_opt = SGD(lr=1E-2, decay=1E-4, momentum=0.9, nesterov=True)\n# adam_opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=1E-4)\n# eve_opt = Eve(lr=1E-4, decay=1E-4, beta_1=0.9, beta_2=0.999, beta_3=0.999, small_k=0.1, big_K=10, epsilon=1e-08)\n\nxception_weights = '../input/pretrained-models/pretrained-models/xception_weights_tf_dim_ordering_tf_kernels_notop.h5'",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "31fab7218083e8aa3b9e9fc88cf10045cb47167c",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "space = {\n         'lr': hp.choice('lr',[0.001, 0.0001, 0.00001, 0.000001]),\n#          'dropout': hp.choice('dropout', [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7]),\n         'batch_size': hp.choice('batch_size', [32, 64]),\n         'epochs': hp.choice('epochs', [20]),\n#        'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n#          'activation': hp.choice('activation',['relu',\n#                                                 'tanh']),\n        }",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "5cd9fc51951d479e3ad77627926397cf4e5ed9e2",
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_dir = '../input/iciarreinhardfull/reinhard/Reinhard'\nfor root,dirs,files in os.walk(train_dir):\n    print (root, len(files))",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "../input/iciarreinhardfull/reinhard/Reinhard 0\n../input/iciarreinhardfull/reinhard/Reinhard/InSitu 3500\n../input/iciarreinhardfull/reinhard/Reinhard/Normal 3500\n../input/iciarreinhardfull/reinhard/Reinhard/Invasive 3500\n../input/iciarreinhardfull/reinhard/Reinhard/Benign 3500\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "378d5d9184e33383a6c6ae0531a699df9079b404",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def f_nn(params):   \n    print ('Parameters testing: ', params)\n    batch_size=params['batch_size']\n    epochs=params['epochs']\n\n    from keras.preprocessing.image import ImageDataGenerator\n\n    # this is the augmentation configuration we will use for training\n    train_datagen = ImageDataGenerator(\n        rescale=1. / 255,\n        shear_range=0.2,\n        zoom_range=0.2,\n            width_shift_range=0.2,\n            height_shift_range=0.2,\n            fill_mode='nearest',\n        horizontal_flip=True,\n        validation_split=0.25)\n\n    # this is the augmentation configuration we will use for testing:\n    # only rescaling\n    test_datagen = ImageDataGenerator(rescale=1. / 255)\n\n\n    #target_size: Tuple of integers (height, width), default: (256, 256). \n    #The dimensions to which all images found will be resized.\n    target_size = (256, 256)\n    #target_size = (height, width)\n    train_generator = train_datagen.flow_from_directory(\n            train_dir,\n            target_size = target_size,       \n            class_mode = 'categorical',\n            batch_size=32,\n            subset=\"training\",\n            shuffle = True)\n\n    validation_generator = train_datagen.flow_from_directory(\n            train_dir,\n            target_size = target_size,        \n            class_mode = 'categorical',\n            batch_size=32,\n            subset = \"validation\",\n            shuffle = True)\n\n    \n    model = Sequential()\n\n    model.add(Xception(weights = xception_weights , include_top=False, pooling = 'avg'))\n    model.add(Dense(units=output_classes, activation='softmax'))\n\n\n    model.compile(loss = 'categorical_crossentropy',\n                  optimizer = Eve(lr=params['lr'], decay=1E-4, beta_1=0.9, beta_2=0.999, beta_3=0.999, small_k=0.1, big_K=10, epsilon=1e-08),\n                  metrics = ['accuracy'])\n\n    history = model.fit_generator(\n      train_generator,\n      steps_per_epoch = 2000,\n      epochs = epochs,\n      validation_data = validation_generator,\n#       validation_steps = 100,\n      verbose = 1, callbacks=get_callbacks(params))\n    \n    \n    best_epoch = np.argmax(history.history['val_acc'])\n    best_val_acc = np.max(history.history['val_acc'])\n    print('Epoch {} - val acc: {}'.format(best_epoch, best_val_acc))\n    sys.stdout.flush() \n    \n    return {'val_acc': best_val_acc, 'best_epoch': best_epoch, 'eval_time': time.time(), 'status': STATUS_OK}",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "e1abd5240499d10fe36059fad182ee6749c72cc5",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "output_classes = 4",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "9e3dcb0aca71f03a85b6e4a677a54803937b2341",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "def get_callbacks(params):\n    callbacks =[EarlyStopping(monitor='val_acc', patience=5, verbose=1),\n                ModelCheckpoint('callbacks/{}.h5'.format(params['batch_size']), save_best_only=True),\n             TensorBoard('tensor-logs/logs-gridsearch', write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)]\n    return callbacks",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "ad58082fb3528fe4a93b17b2f2aa5e87712eaded"
      },
      "cell_type": "markdown",
      "source": "____"
    },
    {
      "metadata": {
        "_uuid": "58ba906fe86e164a127b64490f6cf81d91955737",
        "trusted": true
      },
      "cell_type": "code",
      "source": "trials = Trials()\nbest = fmin(f_nn, space, algo=tpe.suggest, max_evals=30, trials=trials)\nprint(best)",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": "Parameters testing:  {'batch_size': 32, 'epochs': 20, 'lr': 0.001}\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "_uuid": "307852ca436f3b6f178564883600c2b73240b7f7",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "831421fc8eed78a8f2a9299b299543e3ab70b293",
        "trusted": false,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
