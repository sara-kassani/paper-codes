{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 9107088526354433228, name: \"/device:XLA_CPU:0\"\n device_type: \"XLA_CPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 12662154510138727834\n physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n device_type: \"XLA_GPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 14454161202677663126\n physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n device_type: \"GPU\"\n memory_limit: 15876469556\n locality {\n   bus_id: 1\n   links {\n   }\n }\n incarnation: 4230996228072969527\n physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\n# from sklearn.metrics import log_loss\nimport sys\n# import time\nimport math\nimport os\nimport pandas as pd\n# from keras.callbacks import EarlyStopping\nimport numpy as np\n# from glob import glob\n# import cv2\n# import skimage\n# from skimage.transform import resize\nfrom keras.utils.np_utils import to_categorical\n# import keras\n# from keras import layers\n# from keras import models\n# from keras import optimizers\n# from keras.models import load_model\n# import keras.callbacks as kcall\nfrom keras.optimizers import Adam, RMSprop,SGD\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D, Input,concatenate\n# from keras.applications.xception import Xception, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n# from keras.applications.vgg19 import VGG19\nfrom keras.regularizers import l2, l1\n\nimport matplotlib.pyplot as plt\n# from keras.layers import Input, concatenate\n# from keras import optimizers, metrics, models\n# from keras.layers import Input, Flatten, Dense\n\n%matplotlib inline","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\n\nprint(\"Keras Version\", keras.__version__)\nprint(\"tensorflow Version\", tf.__version__)\n# print(\"dim_ordering:\", K.image_dim_ordering())","execution_count":4,"outputs":[{"output_type":"stream","text":"Keras Version 2.3.1\ntensorflow Version 2.0.0\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 64\nimg_height, img_width = 256, 256\ninput_shape = (img_height, img_width, 3)\nepochs = 400","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/\"))","execution_count":6,"outputs":[{"output_type":"stream","text":"['payam-thesis', 'full-keras-pretrained-no-top']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# print(os.listdir(\"../input/full-keras-pretrained-no-top\"))","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/payam-thesis/train/'\ntest_dir = '../input/payam-thesis/test'","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_input(x):\n    # 'RGB'->'BGR'\n    x = x[:, :, ::-1]\n    # Zero-center by imagenet mean pixel\n    x[:, :, 0] -= 103.939\n    x[:, :, 1] -= 116.779\n    x[:, :, 2] -= 123.68\n    return x","execution_count":9,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = np.random.seed(1142)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n    preprocessing_function = preprocess_input,\n    rotation_range=90,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.3,\n    zoom_range=0.2,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='reflect',\n    validation_split= 0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'training',\n    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'validation',\n    class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    class_mode='categorical')","execution_count":10,"outputs":[{"output_type":"stream","text":"Found 4611 images belonging to 3 classes.\nFound 1152 images belonging to 3 classes.\nFound 765 images belonging to 3 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = len(train_generator.filenames)\nnb_validation_samples = len(validation_generator.filenames)\nnb_test_samples = len(test_generator.filenames)\n\npredict_size_train = int(math.ceil(nb_train_samples / batch_size))\npredict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\npredict_size_test = int(math.ceil(nb_test_samples / batch_size))\n\nnum_classes = len(train_generator.class_indices)\n\nprint(\"nb_train_samples:\", nb_train_samples)\nprint(\"nb_validation_samples:\", nb_validation_samples)\nprint(\"nb_test_samples:\", nb_test_samples)\n\nprint(\"\\npredict_size_train:\", predict_size_train)\nprint(\"predict_size_validation:\", predict_size_validation)\nprint(\"predict_size_test:\", predict_size_test)\n\nprint(\"\\n num_classes:\", num_classes)","execution_count":11,"outputs":[{"output_type":"stream","text":"nb_train_samples: 4611\nnb_validation_samples: 1152\nnb_test_samples: 765\n\npredict_size_train: 73\npredict_size_validation: 18\npredict_size_test: 12\n\n num_classes: 3\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg19_weights =\"../input/full-keras-pretrained-no-top/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_weights =\"../input/full-keras-pretrained-no-top//inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nvgg16_weights =\"../input/full-keras-pretrained-no-top/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet201_weights =\"../input/full-keras-pretrained-no-top/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet121_weights =\"../input/full-keras-pretrained-no-top/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nresenet50_weights =\"../input/full-keras-pretrained-no-top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_resnet_v2_weights =\"../input/full-keras-pretrained-no-top/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nnasnet_weights =\"../input/full-keras-pretrained-no-top/nasnet_large_no_top.h5\"\nnasnet_mobile_weights =\"../input/full-keras-pretrained-no-top/nasnet_mobile_no_top.h5\"\nmobilenet_weights =\"../input/full-keras-pretrained-no-top/mobilenet_1_0_224_tf_no_top.h5\"","execution_count":12,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.applications import DenseNet201\nfrom keras.applications import DenseNet121\nfrom keras.applications import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications import NASNetLarge, NASNetMobile\nfrom keras.applications import MobileNet","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape = input_shape)  \n\nbase_model1=InceptionV3(input_shape= input_shape,weights=inception_weights, include_top=False, input_tensor=input_tensor)\nbase_model2=MobileNet(input_shape= input_shape,weights=mobilenet_weights, include_top=False, input_tensor=input_tensor)\n\nx1 = base_model1.output\nx1 = GlobalAveragePooling2D()(x1)\n\nx2 = base_model2.output\nx2 = GlobalAveragePooling2D()(x2)\n\nmerge = concatenate([x1, x2])\npredictions = Dense(num_classes, activation='softmax')(merge)\n\nmodel = Model(inputs=input_tensor,outputs=predictions)","execution_count":14,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i, layer in enumerate(model.layers):\n    print(i, layer.name)","execution_count":15,"outputs":[{"output_type":"stream","text":"0 input_1\n1 conv2d_1\n2 batch_normalization_1\n3 activation_1\n4 conv2d_2\n5 batch_normalization_2\n6 activation_2\n7 conv2d_3\n8 batch_normalization_3\n9 activation_3\n10 max_pooling2d_1\n11 conv2d_4\n12 batch_normalization_4\n13 activation_4\n14 conv2d_5\n15 batch_normalization_5\n16 activation_5\n17 max_pooling2d_2\n18 conv2d_9\n19 batch_normalization_9\n20 activation_9\n21 conv2d_7\n22 conv2d_10\n23 batch_normalization_7\n24 batch_normalization_10\n25 activation_7\n26 activation_10\n27 average_pooling2d_1\n28 conv2d_6\n29 conv2d_8\n30 conv2d_11\n31 conv2d_12\n32 batch_normalization_6\n33 batch_normalization_8\n34 batch_normalization_11\n35 batch_normalization_12\n36 activation_6\n37 activation_8\n38 activation_11\n39 activation_12\n40 mixed0\n41 conv2d_16\n42 batch_normalization_16\n43 activation_16\n44 conv2d_14\n45 conv2d_17\n46 batch_normalization_14\n47 batch_normalization_17\n48 activation_14\n49 activation_17\n50 average_pooling2d_2\n51 conv2d_13\n52 conv2d_15\n53 conv2d_18\n54 conv2d_19\n55 batch_normalization_13\n56 batch_normalization_15\n57 batch_normalization_18\n58 batch_normalization_19\n59 activation_13\n60 activation_15\n61 activation_18\n62 activation_19\n63 mixed1\n64 conv2d_23\n65 batch_normalization_23\n66 activation_23\n67 conv2d_21\n68 conv2d_24\n69 batch_normalization_21\n70 batch_normalization_24\n71 activation_21\n72 activation_24\n73 average_pooling2d_3\n74 conv2d_20\n75 conv2d_22\n76 conv2d_25\n77 conv2d_26\n78 batch_normalization_20\n79 batch_normalization_22\n80 batch_normalization_25\n81 batch_normalization_26\n82 activation_20\n83 activation_22\n84 activation_25\n85 activation_26\n86 mixed2\n87 conv2d_28\n88 batch_normalization_28\n89 activation_28\n90 conv2d_29\n91 batch_normalization_29\n92 activation_29\n93 conv2d_27\n94 conv2d_30\n95 batch_normalization_27\n96 batch_normalization_30\n97 activation_27\n98 activation_30\n99 max_pooling2d_3\n100 mixed3\n101 conv2d_35\n102 batch_normalization_35\n103 activation_35\n104 conv2d_36\n105 batch_normalization_36\n106 activation_36\n107 conv2d_32\n108 conv2d_37\n109 batch_normalization_32\n110 batch_normalization_37\n111 activation_32\n112 activation_37\n113 conv2d_33\n114 conv2d_38\n115 batch_normalization_33\n116 batch_normalization_38\n117 activation_33\n118 activation_38\n119 average_pooling2d_4\n120 conv2d_31\n121 conv2d_34\n122 conv2d_39\n123 conv2d_40\n124 batch_normalization_31\n125 batch_normalization_34\n126 batch_normalization_39\n127 batch_normalization_40\n128 conv1_pad\n129 activation_31\n130 activation_34\n131 activation_39\n132 activation_40\n133 conv1\n134 mixed4\n135 conv1_bn\n136 conv2d_45\n137 conv1_relu\n138 batch_normalization_45\n139 conv_dw_1\n140 activation_45\n141 conv_dw_1_bn\n142 conv2d_46\n143 conv_dw_1_relu\n144 batch_normalization_46\n145 conv_pw_1\n146 activation_46\n147 conv_pw_1_bn\n148 conv2d_42\n149 conv2d_47\n150 conv_pw_1_relu\n151 batch_normalization_42\n152 batch_normalization_47\n153 conv_pad_2\n154 activation_42\n155 activation_47\n156 conv_dw_2\n157 conv2d_43\n158 conv2d_48\n159 conv_dw_2_bn\n160 batch_normalization_43\n161 batch_normalization_48\n162 conv_dw_2_relu\n163 activation_43\n164 activation_48\n165 average_pooling2d_5\n166 conv_pw_2\n167 conv2d_41\n168 conv2d_44\n169 conv2d_49\n170 conv2d_50\n171 conv_pw_2_bn\n172 batch_normalization_41\n173 batch_normalization_44\n174 batch_normalization_49\n175 batch_normalization_50\n176 conv_pw_2_relu\n177 activation_41\n178 activation_44\n179 activation_49\n180 activation_50\n181 conv_dw_3\n182 mixed5\n183 conv_dw_3_bn\n184 conv2d_55\n185 conv_dw_3_relu\n186 batch_normalization_55\n187 conv_pw_3\n188 activation_55\n189 conv_pw_3_bn\n190 conv2d_56\n191 conv_pw_3_relu\n192 batch_normalization_56\n193 conv_pad_4\n194 activation_56\n195 conv_dw_4\n196 conv2d_52\n197 conv2d_57\n198 conv_dw_4_bn\n199 batch_normalization_52\n200 batch_normalization_57\n201 conv_dw_4_relu\n202 activation_52\n203 activation_57\n204 conv_pw_4\n205 conv2d_53\n206 conv2d_58\n207 conv_pw_4_bn\n208 batch_normalization_53\n209 batch_normalization_58\n210 conv_pw_4_relu\n211 activation_53\n212 activation_58\n213 average_pooling2d_6\n214 conv_dw_5\n215 conv2d_51\n216 conv2d_54\n217 conv2d_59\n218 conv2d_60\n219 conv_dw_5_bn\n220 batch_normalization_51\n221 batch_normalization_54\n222 batch_normalization_59\n223 batch_normalization_60\n224 conv_dw_5_relu\n225 activation_51\n226 activation_54\n227 activation_59\n228 activation_60\n229 conv_pw_5\n230 mixed6\n231 conv_pw_5_bn\n232 conv2d_65\n233 conv_pw_5_relu\n234 batch_normalization_65\n235 conv_pad_6\n236 activation_65\n237 conv_dw_6\n238 conv2d_66\n239 conv_dw_6_bn\n240 batch_normalization_66\n241 conv_dw_6_relu\n242 activation_66\n243 conv_pw_6\n244 conv2d_62\n245 conv2d_67\n246 conv_pw_6_bn\n247 batch_normalization_62\n248 batch_normalization_67\n249 conv_pw_6_relu\n250 activation_62\n251 activation_67\n252 conv_dw_7\n253 conv2d_63\n254 conv2d_68\n255 conv_dw_7_bn\n256 batch_normalization_63\n257 batch_normalization_68\n258 conv_dw_7_relu\n259 activation_63\n260 activation_68\n261 average_pooling2d_7\n262 conv_pw_7\n263 conv2d_61\n264 conv2d_64\n265 conv2d_69\n266 conv2d_70\n267 conv_pw_7_bn\n268 batch_normalization_61\n269 batch_normalization_64\n270 batch_normalization_69\n271 batch_normalization_70\n272 conv_pw_7_relu\n273 activation_61\n274 activation_64\n275 activation_69\n276 activation_70\n277 conv_dw_8\n278 mixed7\n279 conv_dw_8_bn\n280 conv2d_73\n281 conv_dw_8_relu\n282 batch_normalization_73\n283 conv_pw_8\n284 activation_73\n285 conv_pw_8_bn\n286 conv2d_74\n287 conv_pw_8_relu\n288 batch_normalization_74\n289 conv_dw_9\n290 activation_74\n291 conv_dw_9_bn\n292 conv2d_71\n293 conv2d_75\n294 conv_dw_9_relu\n295 batch_normalization_71\n296 batch_normalization_75\n297 conv_pw_9\n298 activation_71\n299 activation_75\n300 conv_pw_9_bn\n301 conv2d_72\n302 conv2d_76\n303 conv_pw_9_relu\n304 batch_normalization_72\n305 batch_normalization_76\n306 conv_dw_10\n307 activation_72\n308 activation_76\n309 max_pooling2d_4\n310 conv_dw_10_bn\n311 mixed8\n312 conv_dw_10_relu\n313 conv2d_81\n314 conv_pw_10\n315 batch_normalization_81\n316 conv_pw_10_bn\n317 activation_81\n318 conv_pw_10_relu\n319 conv2d_78\n320 conv2d_82\n321 conv_dw_11\n322 batch_normalization_78\n323 batch_normalization_82\n324 conv_dw_11_bn\n325 activation_78\n326 activation_82\n327 conv_dw_11_relu\n328 conv2d_79\n329 conv2d_80\n330 conv2d_83\n331 conv2d_84\n332 average_pooling2d_8\n333 conv_pw_11\n334 conv2d_77\n335 batch_normalization_79\n336 batch_normalization_80\n337 batch_normalization_83\n338 batch_normalization_84\n339 conv2d_85\n340 conv_pw_11_bn\n341 batch_normalization_77\n342 activation_79\n343 activation_80\n344 activation_83\n345 activation_84\n346 batch_normalization_85\n347 conv_pw_11_relu\n348 activation_77\n349 mixed9_0\n350 concatenate_1\n351 activation_85\n352 conv_pad_12\n353 mixed9\n354 conv_dw_12\n355 conv2d_90\n356 conv_dw_12_bn\n357 batch_normalization_90\n358 conv_dw_12_relu\n359 activation_90\n360 conv_pw_12\n361 conv2d_87\n362 conv2d_91\n363 conv_pw_12_bn\n364 batch_normalization_87\n365 batch_normalization_91\n366 conv_pw_12_relu\n367 activation_87\n368 activation_91\n369 conv_dw_13\n370 conv2d_88\n371 conv2d_89\n372 conv2d_92\n373 conv2d_93\n374 average_pooling2d_9\n375 conv_dw_13_bn\n376 conv2d_86\n377 batch_normalization_88\n378 batch_normalization_89\n379 batch_normalization_92\n380 batch_normalization_93\n381 conv2d_94\n382 conv_dw_13_relu\n383 batch_normalization_86\n384 activation_88\n385 activation_89\n386 activation_92\n387 activation_93\n388 batch_normalization_94\n389 conv_pw_13\n390 activation_86\n391 mixed9_1\n392 concatenate_2\n393 activation_94\n394 conv_pw_13_bn\n395 mixed10\n396 conv_pw_13_relu\n397 global_average_pooling2d_1\n398 global_average_pooling2d_2\n399 concatenate_3\n400 dense_1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"c1 = model.layers[11].output \nc1 = GlobalAveragePooling2D()(c1)       \n\nc2 = model.layers[18].output\nc2 = GlobalAveragePooling2D()(c2)       \n\nc3 = model.layers[28].output\nc3 = GlobalAveragePooling2D()(c3)       \n\nc4 = model.layers[51].output\nc4 = GlobalAveragePooling2D()(c4) \n\nc5 = model.layers[74].output\nc5 = GlobalAveragePooling2D()(c5) \n\nc6 = model.layers[101].output\nc6 = GlobalAveragePooling2D()(c6) \n\nc7 = model.layers[120].output\nc7 = GlobalAveragePooling2D()(c7) \n\nc8 = model.layers[167].output\nc8 = GlobalAveragePooling2D()(c8) \n\nc9 = model.layers[215].output\nc9 = GlobalAveragePooling2D()(c9) \n\nc10 = model.layers[263].output\nc10 = GlobalAveragePooling2D()(c10) \n\nc11 = model.layers[313].output\nc11 = GlobalAveragePooling2D()(c11) \n\nc12 = model.layers[334].output\nc12 = GlobalAveragePooling2D()(c12) \n\nc13 = model.layers[376].output\nc13 = GlobalAveragePooling2D()(c13) \n\nc14 = model.layers[291].output\nc14 = GlobalAveragePooling2D()(c14) \n\nc15 = model.layers[305].output\nc15 = GlobalAveragePooling2D()(c15) \n\nc16 = model.layers[311].output\nc16 = GlobalAveragePooling2D()(c16) \n\ncon = concatenate([c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15, c16])\n\nbottleneck_final_model = Model(inputs=model.input, outputs=con)","execution_count":16,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"extracted_features\")\nextracted_features_dir = \"extracted_features/\"\nmodel_name = \"densenet201_InceptionResNetV2_descriptors\"","execution_count":17,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train, max_q_size=1, pickle_safe=False)\nnp.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)","execution_count":18,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\nnp.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\nnp.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\nvalidation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\ntest_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n\ntrain_labels = train_generator.classes\ntrain_labels = to_categorical(train_labels, num_classes=num_classes)\n\nvalidation_labels = validation_generator.classes\nvalidation_labels = to_categorical(validation_labels, num_classes=num_classes)\n\ntest_labels = test_generator.classes\ntest_labels = to_categorical(test_labels, num_classes=num_classes)","execution_count":21,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Machine Learning Algorithms"},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score, classification_report\n\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n\nk_fold = KFold(n_splits=10, shuffle=True, random_state=5)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = np.asarray(test_labels)\ny_test = np.argmax(y_test, axis=1)\n\ny_train = np.asarray(train_labels)\ny_train = np.argmax(y_train, axis=1)","execution_count":23,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Bagging Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":24,"outputs":[{"output_type":"stream","text":"Train accuracy 1.0\nTest accuracy 0.9934640522875817\nAdaBoost Classifier test accuracies 0.9935\n              precision    recall  f1-score   support\n\n           0       0.99      1.00      0.99       329\n           1       1.00      0.98      0.99       211\n           2       1.00      1.00      1.00       225\n\n    accuracy                           0.99       765\n   macro avg       1.00      0.99      0.99       765\nweighted avg       0.99      0.99      0.99       765\n\n0.9934640522875817\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\nscoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"BaggingClassifier - Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":25,"outputs":[{"output_type":"stream","text":"Scores Mean: 96.3483 and (STDEV 0.0283)\nBest result for fold 2\nBest accuracy is 0.987012987012987\nScores of all folds: [0.8961039  0.96103896 0.98701299 0.93506494 0.97402597 0.97368421\n 0.94736842 0.98684211 0.98684211 0.98684211]\nBaggingClassifier - Test Accuracy on all folds: 0.96 (+/- 0.06)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# AdaBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 300 )\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":26,"outputs":[{"output_type":"stream","text":"Train accuracy 1.0\nTest accuracy 0.9372549019607843\nAdaBoost Classifier test accuracies 0.9373\n              precision    recall  f1-score   support\n\n           0       0.94      0.94      0.94       329\n           1       0.89      0.92      0.90       211\n           2       0.98      0.95      0.96       225\n\n    accuracy                           0.94       765\n   macro avg       0.94      0.94      0.94       765\nweighted avg       0.94      0.94      0.94       765\n\n0.9372549019607843\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"(AdaBoost Classifier) Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":27,"outputs":[{"output_type":"stream","text":"Scores Mean: 85.3674 and (STDEV 0.0332)\nBest result for fold 6\nBest accuracy is 0.8947368421052632\nScores of all folds: [0.81818182 0.81818182 0.85714286 0.85714286 0.85714286 0.78947368\n 0.89473684 0.89473684 0.86842105 0.88157895]\n(AdaBoost Classifier) Test Accuracy on all folds: 0.85 (+/- 0.07)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Decision Tree Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('DecisionTree Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":28,"outputs":[{"output_type":"stream","text":"Train accuracy 1.0\nTest accuracy 0.9437908496732026\nDecisionTree Classifier test accuracies 0.9438\n              precision    recall  f1-score   support\n\n           0       0.94      0.96      0.95       329\n           1       0.91      0.92      0.92       211\n           2       0.98      0.94      0.96       225\n\n    accuracy                           0.94       765\n   macro avg       0.94      0.94      0.94       765\nweighted avg       0.94      0.94      0.94       765\n\n0.9437908496732026\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"DecisionTree - Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":29,"outputs":[{"output_type":"stream","text":"Scores Mean: 85.5058 and (STDEV 0.0356)\nBest result for fold 9\nBest accuracy is 0.9210526315789473\nScores of all folds: [0.80519481 0.79220779 0.85714286 0.85714286 0.84415584 0.85526316\n 0.89473684 0.86842105 0.85526316 0.92105263]\nDecisionTree - Test Accuracy on all folds: 0.86 (+/- 0.07)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# Random Forest Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=5)\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('RandomForest Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":30,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9971806549555411\nTest accuracy 0.9699346405228758\nRandomForest Classifier test accuracies 0.9699\n              precision    recall  f1-score   support\n\n           0       0.97      0.98      0.98       329\n           1       0.95      0.96      0.96       211\n           2       0.99      0.96      0.98       225\n\n    accuracy                           0.97       765\n   macro avg       0.97      0.97      0.97       765\nweighted avg       0.97      0.97      0.97       765\n\n0.9699346405228758\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, test_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"(RandomForest) Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":31,"outputs":[{"output_type":"stream","text":"Scores Mean: 88.4877 and (STDEV 0.0496)\nBest result for fold 7\nBest accuracy is 0.9605263157894737\nScores of all folds: [0.88311688 0.84415584 0.92207792 0.92207792 0.92207792 0.82894737\n 0.80263158 0.96052632 0.84210526 0.92105263]\n(RandomForest) Test Accuracy on all folds: 0.88 (+/- 0.10)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"# XGBoost Classifier"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier()\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('XGB Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":32,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9995662546085448\nTest accuracy 0.9973856209150327\nXGB Classifier test accuracies 0.9974\n              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00       329\n           1       1.00      0.99      1.00       211\n           2       1.00      1.00      1.00       225\n\n    accuracy                           1.00       765\n   macro avg       1.00      1.00      1.00       765\nweighted avg       1.00      1.00      1.00       765\n\n0.9973856209150327\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"XGB - Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":33,"outputs":[{"output_type":"stream","text":"Scores Mean: 97.2573 and (STDEV 0.0169)\nBest result for fold 7\nBest accuracy is 1.0\nScores of all folds: [0.93506494 0.97402597 0.97402597 0.97402597 0.98701299 0.96052632\n 0.96052632 1.         0.98684211 0.97368421]\nXGB - Test Accuracy on all folds: 0.97 (+/- 0.03)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Done!\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}