{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "import math\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, add, GlobalAveragePooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import DenseNet121\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
    "from keras.layers import SeparableConv2D, AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/iciar/train/'\n",
    "test_dir = \"data/iciar/test/\"\n",
    "\n",
    "extracted_features_dir = \"extracted_features/\"\n",
    "model_name = \"Reinhard_Xception_concate\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.9.0\n",
      "dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/iciar/train/ 0\n",
      "data/iciar/train/carcinoma 2310\n",
      "data/iciar/train/non-carcinoma 2310\n",
      "******************************\n",
      "data/iciar/test/ 0\n",
      "data/iciar/test/carcinoma 50\n",
      "data/iciar/test/non-carcinoma 50\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(train_dir):\n",
    "    print (root, len(files))\n",
    "\n",
    "print(\"*\"*30)\n",
    "for root,dirs,files in os.walk(test_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3466 images belonging to 2 classes.\n",
      "Found 1154 images belonging to 2 classes.\n",
      "Found 100 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True,\n",
    "    validation_split= 0.25,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'training',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'validation',\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 3466\n",
      "nb_validation_samples: 1154\n",
      "\n",
      "predict_size_train: 109\n",
      "predict_size_validation: 37\n",
      "nb_test_samples: 100\n",
      "predict_size_test: 4\n",
      "\n",
      " num_classes: 2\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "\n",
    "nb_test_samples = len(test_generator.filenames)\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "# nb_test_without_aug_samples = len(test_generator_without_aug.filenames)\n",
    "# predict_size_test_without_aug = int(math.ceil(nb_test_without_aug_samples / batch_size))\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "# print(\"nb_test_without_aug_samples:\", nb_test_without_aug_samples)\n",
    "# print(\"predict_size_test_without_aug_samples:\", predict_size_test_without_aug)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "print(\"predict_size_test:\", predict_size_test)\n",
    "\n",
    "print(\"\\n num_classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import get_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def reset_keras_tf_session():\n",
    "    \"\"\"\n",
    "    this function clears the gpu memory and set the \n",
    "    tf session to not use the whole gpu\n",
    "    \"\"\"\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "reset_keras_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\n",
    "validation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\n",
    "test_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n",
    "\n",
    "train_labels = train_generator.classes\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "validation_labels = validation_generator.classes\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "test_labels = test_generator.classes\n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape : (3466, 2592)\n",
      "Training Data label Shape : (3466, 2)\n",
      "Test Data Shape : (100, 2592)\n",
      "Test Data label Shape : (100, 2)\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Data Shape : {0}\".format(train_data.shape))\n",
    "print(\"Training Data label Shape : {0}\".format(train_labels.shape))\n",
    "\n",
    "print(\"Test Data Shape : {0}\".format(test_data.shape))\n",
    "print(\"Test Data label Shape : {0}\".format(test_labels.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KFold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 1.0\n",
      "Validation accuracy 0.8925476603119584\n",
      "Test accuracy 0.77\n",
      "DecisionTree Classifier test accuracies 0.7700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.82      0.78        50\n",
      "           1       0.80      0.72      0.76        50\n",
      "\n",
      "   micro avg       0.77      0.77      0.77       100\n",
      "   macro avg       0.77      0.77      0.77       100\n",
      "weighted avg       0.77      0.77      0.77       100\n",
      " samples avg       0.77      0.77      0.77       100\n",
      "\n",
      "0.77\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('DecisionTree Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 82.0000 and (STDEV 0.0748)\n",
      "Best result for fold 3\n",
      "Best accuracy is 0.9\n",
      "Scores of all folds: [0.8 0.8 0.8 0.9 0.9 0.9 0.9 0.8 0.7 0.7]\n",
      "Accuracy: 0.82 (+/- 0.15)\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, test_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9924985574148875\n",
      "Validation accuracy 0.925476603119584\n",
      "Test accuracy 0.85\n",
      "RandomForest Classifier test accuracies 0.8500\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.84      0.85        50\n",
      "           1       0.84      0.86      0.85        50\n",
      "\n",
      "   micro avg       0.85      0.85      0.85       100\n",
      "   macro avg       0.85      0.85      0.85       100\n",
      "weighted avg       0.85      0.85      0.85       100\n",
      " samples avg       0.85      0.85      0.85       100\n",
      "\n",
      "0.85\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('RandomForest Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 71.0000 and (STDEV 0.1300)\n",
      "Best result for fold 6\n",
      "Best accuracy is 0.9\n",
      "Scores of all folds: [0.7 0.5 0.8 0.7 0.5 0.7 0.9 0.9 0.7 0.7]\n",
      "Accuracy: 0.71 (+/- 0.26)\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, test_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.asarray(test_labels)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = np.asarray(validation_labels)\n",
    "y_validation = np.argmax(y_validation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels)\n",
    "y_train = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.84333525678015\n",
      "Validation accuracy 0.8344887348353552\n",
      "Test accuracy 0.84\n",
      "SVM Classifier test accuracies 0.8400\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.80      0.83        50\n",
      "           1       0.81      0.88      0.85        50\n",
      "\n",
      "   micro avg       0.84      0.84      0.84       100\n",
      "   macro avg       0.84      0.84      0.84       100\n",
      "weighted avg       0.84      0.84      0.84       100\n",
      "\n",
      "0.84\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('SVM Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 60.0000 and (STDEV 0.1414)\n",
      "Best result for fold 3\n",
      "Best accuracy is 0.8\n",
      "Scores of all folds: [0.3 0.7 0.6 0.8 0.6 0.6 0.6 0.5 0.5 0.8]\n",
      "Accuracy: 0.60 (+/- 0.28)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9971148297749567\n",
      "Validation accuracy 0.975736568457539\n",
      "Test accuracy 0.89\n",
      "XGB Classifier test accuracies 0.8900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.90      0.89        50\n",
      "           1       0.90      0.88      0.89        50\n",
      "\n",
      "   micro avg       0.89      0.89      0.89       100\n",
      "   macro avg       0.89      0.89      0.89       100\n",
      "weighted avg       0.89      0.89      0.89       100\n",
      "\n",
      "0.89\n"
     ]
    }
   ],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('XGB Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 81.0000 and (STDEV 0.1446)\n",
      "Best result for fold 3\n",
      "Best accuracy is 1.0\n",
      "Scores of all folds: [0.8 0.5 0.8 1.  0.7 0.7 0.8 0.9 1.  0.9]\n",
      "Accuracy: 0.81 (+/- 0.29)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 1.0\n",
      "Validation accuracy 0.8804159445407279\n",
      "Test accuracy 0.79\n",
      "AdaBoost Classifier test accuracies 0.7900\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.84      0.80        50\n",
      "           1       0.82      0.74      0.78        50\n",
      "\n",
      "   micro avg       0.79      0.79      0.79       100\n",
      "   macro avg       0.79      0.79      0.79       100\n",
      "weighted avg       0.79      0.79      0.79       100\n",
      "\n",
      "0.79\n"
     ]
    }
   ],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 300 )\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 75.0000 and (STDEV 0.1432)\n",
      "Best result for fold 4\n",
      "Best accuracy is 0.9\n",
      "Scores of all folds: [0.7 0.8 0.6 0.6 0.9 0.7 0.9 0.9 0.9 0.5]\n",
      "Accuracy: 0.75 (+/- 0.29)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9988459319099827\n",
      "Validation accuracy 0.9575389948006933\n",
      "Test accuracy 0.87\n",
      "AdaBoost Classifier test accuracies 0.8700\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.90      0.87        50\n",
      "           1       0.89      0.84      0.87        50\n",
      "\n",
      "   micro avg       0.87      0.87      0.87       100\n",
      "   macro avg       0.87      0.87      0.87       100\n",
      "weighted avg       0.87      0.87      0.87       100\n",
      "\n",
      "0.87\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores Mean: 83.0000 and (STDEV 0.1269)\n",
      "Best result for fold 5\n",
      "Best accuracy is 1.0\n",
      "Scores of all folds: [0.8 0.6 0.7 0.8 0.7 1.  0.9 0.9 1.  0.9]\n",
      "Accuracy: 0.83 (+/- 0.25)\n"
     ]
    }
   ],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
