{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from tensorflow.python.client import device_lib\ndevice_lib.list_local_devices()","execution_count":2,"outputs":[{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"[name: \"/device:CPU:0\"\n device_type: \"CPU\"\n memory_limit: 268435456\n locality {\n }\n incarnation: 2017791077311023893, name: \"/device:XLA_CPU:0\"\n device_type: \"XLA_CPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 14450031014294794741\n physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n device_type: \"XLA_GPU\"\n memory_limit: 17179869184\n locality {\n }\n incarnation: 6912780737520207718\n physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n device_type: \"GPU\"\n memory_limit: 15884438733\n locality {\n   bus_id: 1\n   links {\n   }\n }\n incarnation: 362047958909962457\n physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\nfrom sklearn.metrics import log_loss\nimport sys\nimport time\nimport math\nimport os\nimport pandas as pd\nfrom keras.callbacks import EarlyStopping\nimport numpy as np\nfrom glob import glob\nimport cv2\nimport skimage\nfrom skimage.transform import resize\nfrom keras.utils.np_utils import to_categorical\nimport keras\nfrom keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.models import load_model\n# import keras.callbacks as kcall\nfrom keras.optimizers import Adam, RMSprop,SGD\nfrom keras.models import Model\nfrom keras.models import Sequential\nfrom keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\n# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\nfrom keras.applications.vgg19 import VGG19\nfrom keras.regularizers import l2, l1\n\nimport matplotlib.pyplot as plt\nfrom keras.layers import Input, concatenate\nfrom keras import optimizers, metrics, models\nfrom keras.layers import Input, Flatten, Dense\n\n%matplotlib inline","execution_count":3,"outputs":[{"output_type":"stream","text":"Using TensorFlow backend.\n","name":"stderr"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import keras\nimport tensorflow as tf\n\nprint(\"Keras Version\", keras.__version__)\nprint(\"tensorflow Version\", tf.__version__)\n# print(\"dim_ordering:\", K.image_dim_ordering())","execution_count":4,"outputs":[{"output_type":"stream","text":"Keras Version 2.2.4\ntensorflow Version 1.13.1\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\nimg_height, img_width = 300, 300\ninput_shape = (img_height, img_width, 3)\nepochs = 1000","execution_count":5,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(os.listdir(\"../input/aptos-binary-noaug/aptos_binary/APTOS_Binary/\"))","execution_count":6,"outputs":[{"output_type":"stream","text":"['train', 'test']\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dir = '../input/aptos-binary-noaug/aptos_binary/APTOS_Binary/train/'\ntest_dir = '../input/aptos-binary-noaug/aptos_binary/APTOS_Binary/test/'","execution_count":7,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess_input(x):\n    # 'RGB'->'BGR'\n    x = x[:, :, ::-1]\n    # Zero-center by imagenet mean pixel\n    x[:, :, 0] -= 103.939\n    x[:, :, 1] -= 116.779\n    x[:, :, 2] -= 123.68\n    return x","execution_count":8,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"random_seed = np.random.seed(1142)\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n#     featurewise_center=True,\n#     featurewise_std_normalization=True,\n    preprocessing_function = preprocess_input,\n#     zoom_range=0.2,\n#     shear_range=0.2,\n    validation_split= 0.2)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'training',\n    class_mode='categorical')\n\nvalidation_generator = train_datagen.flow_from_directory(\n    train_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    subset = 'validation',\n    class_mode='categorical')\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\ntest_generator = test_datagen.flow_from_directory(\n    test_dir,\n    target_size=(img_height, img_width),\n    batch_size=batch_size,\n    seed = random_seed,\n    shuffle = False,\n    class_mode='categorical')","execution_count":9,"outputs":[{"output_type":"stream","text":"Found 2656 images belonging to 2 classes.\nFound 663 images belonging to 2 classes.\nFound 343 images belonging to 2 classes.\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"nb_train_samples = len(train_generator.filenames)\nnb_validation_samples = len(validation_generator.filenames)\nnb_test_samples = len(test_generator.filenames)\n\npredict_size_train = int(math.ceil(nb_train_samples / batch_size))\npredict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\npredict_size_test = int(math.ceil(nb_test_samples / batch_size))\n\nnum_classes = len(train_generator.class_indices)\n\nprint(\"nb_train_samples:\", nb_train_samples)\nprint(\"nb_validation_samples:\", nb_validation_samples)\nprint(\"nb_test_samples:\", nb_test_samples)\n\nprint(\"\\npredict_size_train:\", predict_size_train)\nprint(\"predict_size_validation:\", predict_size_validation)\nprint(\"predict_size_test:\", predict_size_test)\n\nprint(\"\\n num_classes:\", num_classes)","execution_count":10,"outputs":[{"output_type":"stream","text":"nb_train_samples: 2656\nnb_validation_samples: 663\nnb_test_samples: 343\n\npredict_size_train: 83\npredict_size_validation: 21\npredict_size_test: 11\n\n num_classes: 2\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"os.mkdir(\"extracted_features\")\nextracted_features_dir = \"extracted_features/\"\nmodel_name = \"MobileNet_descriptors\"","execution_count":19,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"vgg19_weights =\"../input/full-keras-pretrained-no-top/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_weights =\"../input/full-keras-pretrained-no-top//inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nvgg16_weights =\"../input/full-keras-pretrained-no-top/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet201_weights =\"../input/full-keras-pretrained-no-top/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ndenseNet121_weights =\"../input/full-keras-pretrained-no-top/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nresenet50_weights =\"../input/full-keras-pretrained-no-top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\ninception_resnet_v2_weights =\"../input/full-keras-pretrained-no-top/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\nnasnet_weights =\"../input/full-keras-pretrained-no-top/nasnet_large_no_top.h5\"\nnasnet_mobile_weights =\"../input/full-keras-pretrained-no-top/nasnet_mobile_no_top.h5\"\nmobilenet_weights =\"../input/full-keras-pretrained-no-top/mobilenet_1_0_224_tf_no_top.h5\"\nxception_weights = \"../input/full-keras-pretrained-no-top/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\"","execution_count":20,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.applications.vgg19 import VGG19\nfrom keras.applications.inception_v3 import InceptionV3\nfrom keras.applications.vgg16 import VGG16\nfrom keras.applications.xception import Xception, preprocess_input\nfrom keras.applications import DenseNet201\nfrom keras.applications import DenseNet121\nfrom keras.applications import ResNet50\nfrom keras.applications.inception_resnet_v2 import InceptionResNetV2\nfrom keras.applications import NASNetLarge, NASNetMobile\nfrom keras.applications import MobileNet","execution_count":21,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"input_tensor = Input(shape = input_shape)  \n\nbase_model1=DenseNet121(weights=denseNet121_weights, include_top=False, pooling = \"avg\", input_tensor = input_tensor )\n# base_model2=Xception(input_shape= input_shape,weights=xception_weights, include_top=False, input_tensor=input_tensor)\n\n# x1 = base_model1.output\n# x1 = GlobalAveragePooling2D()(x1)\n\n# x2 = base_model2.output\n# x2 = GlobalAveragePooling2D()(x2)\n\n# merge = concatenate([x1, x2])\n# predictions = Dense(num_classes, activation='softmax')(merge)\n\n# model = Model(inputs=input_tensor,outputs=predictions)","execution_count":22,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"base_model1.summary()","execution_count":23,"outputs":[{"output_type":"stream","text":"__________________________________________________________________________________________________\nLayer (type)                    Output Shape         Param #     Connected to                     \n==================================================================================================\ninput_2 (InputLayer)            (None, 300, 300, 3)  0                                            \n__________________________________________________________________________________________________\nzero_padding2d_3 (ZeroPadding2D (None, 306, 306, 3)  0           input_2[0][0]                    \n__________________________________________________________________________________________________\nconv1/conv (Conv2D)             (None, 150, 150, 64) 9408        zero_padding2d_3[0][0]           \n__________________________________________________________________________________________________\nconv1/bn (BatchNormalization)   (None, 150, 150, 64) 256         conv1/conv[0][0]                 \n__________________________________________________________________________________________________\nconv1/relu (Activation)         (None, 150, 150, 64) 0           conv1/bn[0][0]                   \n__________________________________________________________________________________________________\nzero_padding2d_4 (ZeroPadding2D (None, 152, 152, 64) 0           conv1/relu[0][0]                 \n__________________________________________________________________________________________________\npool1 (MaxPooling2D)            (None, 75, 75, 64)   0           zero_padding2d_4[0][0]           \n__________________________________________________________________________________________________\nconv2_block1_0_bn (BatchNormali (None, 75, 75, 64)   256         pool1[0][0]                      \n__________________________________________________________________________________________________\nconv2_block1_0_relu (Activation (None, 75, 75, 64)   0           conv2_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_1_conv (Conv2D)    (None, 75, 75, 128)  8192        conv2_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_1_relu (Activation (None, 75, 75, 128)  0           conv2_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block1_2_conv (Conv2D)    (None, 75, 75, 32)   36864       conv2_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block1_concat (Concatenat (None, 75, 75, 96)   0           pool1[0][0]                      \n                                                                 conv2_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_bn (BatchNormali (None, 75, 75, 96)   384         conv2_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_0_relu (Activation (None, 75, 75, 96)   0           conv2_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_1_conv (Conv2D)    (None, 75, 75, 128)  12288       conv2_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_1_relu (Activation (None, 75, 75, 128)  0           conv2_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block2_2_conv (Conv2D)    (None, 75, 75, 32)   36864       conv2_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block2_concat (Concatenat (None, 75, 75, 128)  0           conv2_block1_concat[0][0]        \n                                                                 conv2_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_0_relu (Activation (None, 75, 75, 128)  0           conv2_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_1_conv (Conv2D)    (None, 75, 75, 128)  16384       conv2_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_1_relu (Activation (None, 75, 75, 128)  0           conv2_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block3_2_conv (Conv2D)    (None, 75, 75, 32)   36864       conv2_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block3_concat (Concatenat (None, 75, 75, 160)  0           conv2_block2_concat[0][0]        \n                                                                 conv2_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_bn (BatchNormali (None, 75, 75, 160)  640         conv2_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_0_relu (Activation (None, 75, 75, 160)  0           conv2_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_1_conv (Conv2D)    (None, 75, 75, 128)  20480       conv2_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_1_relu (Activation (None, 75, 75, 128)  0           conv2_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block4_2_conv (Conv2D)    (None, 75, 75, 32)   36864       conv2_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block4_concat (Concatenat (None, 75, 75, 192)  0           conv2_block3_concat[0][0]        \n                                                                 conv2_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_bn (BatchNormali (None, 75, 75, 192)  768         conv2_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_0_relu (Activation (None, 75, 75, 192)  0           conv2_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_1_conv (Conv2D)    (None, 75, 75, 128)  24576       conv2_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_1_relu (Activation (None, 75, 75, 128)  0           conv2_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block5_2_conv (Conv2D)    (None, 75, 75, 32)   36864       conv2_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block5_concat (Concatenat (None, 75, 75, 224)  0           conv2_block4_concat[0][0]        \n                                                                 conv2_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_bn (BatchNormali (None, 75, 75, 224)  896         conv2_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_0_relu (Activation (None, 75, 75, 224)  0           conv2_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_1_conv (Conv2D)    (None, 75, 75, 128)  28672       conv2_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_bn (BatchNormali (None, 75, 75, 128)  512         conv2_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_1_relu (Activation (None, 75, 75, 128)  0           conv2_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv2_block6_2_conv (Conv2D)    (None, 75, 75, 32)   36864       conv2_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv2_block6_concat (Concatenat (None, 75, 75, 256)  0           conv2_block5_concat[0][0]        \n                                                                 conv2_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\npool2_bn (BatchNormalization)   (None, 75, 75, 256)  1024        conv2_block6_concat[0][0]        \n__________________________________________________________________________________________________\npool2_relu (Activation)         (None, 75, 75, 256)  0           pool2_bn[0][0]                   \n__________________________________________________________________________________________________\npool2_conv (Conv2D)             (None, 75, 75, 128)  32768       pool2_relu[0][0]                 \n__________________________________________________________________________________________________\npool2_pool (AveragePooling2D)   (None, 37, 37, 128)  0           pool2_conv[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_bn (BatchNormali (None, 37, 37, 128)  512         pool2_pool[0][0]                 \n__________________________________________________________________________________________________\nconv3_block1_0_relu (Activation (None, 37, 37, 128)  0           conv3_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_1_conv (Conv2D)    (None, 37, 37, 128)  16384       conv3_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_1_relu (Activation (None, 37, 37, 128)  0           conv3_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block1_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block1_concat (Concatenat (None, 37, 37, 160)  0           pool2_pool[0][0]                 \n                                                                 conv3_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_bn (BatchNormali (None, 37, 37, 160)  640         conv3_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_0_relu (Activation (None, 37, 37, 160)  0           conv3_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_1_conv (Conv2D)    (None, 37, 37, 128)  20480       conv3_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_1_relu (Activation (None, 37, 37, 128)  0           conv3_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block2_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block2_concat (Concatenat (None, 37, 37, 192)  0           conv3_block1_concat[0][0]        \n                                                                 conv3_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_bn (BatchNormali (None, 37, 37, 192)  768         conv3_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_0_relu (Activation (None, 37, 37, 192)  0           conv3_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_1_conv (Conv2D)    (None, 37, 37, 128)  24576       conv3_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_1_relu (Activation (None, 37, 37, 128)  0           conv3_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block3_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block3_concat (Concatenat (None, 37, 37, 224)  0           conv3_block2_concat[0][0]        \n                                                                 conv3_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_bn (BatchNormali (None, 37, 37, 224)  896         conv3_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_0_relu (Activation (None, 37, 37, 224)  0           conv3_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_1_conv (Conv2D)    (None, 37, 37, 128)  28672       conv3_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_1_relu (Activation (None, 37, 37, 128)  0           conv3_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block4_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block4_concat (Concatenat (None, 37, 37, 256)  0           conv3_block3_concat[0][0]        \n                                                                 conv3_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_bn (BatchNormali (None, 37, 37, 256)  1024        conv3_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_0_relu (Activation (None, 37, 37, 256)  0           conv3_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_1_conv (Conv2D)    (None, 37, 37, 128)  32768       conv3_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_1_relu (Activation (None, 37, 37, 128)  0           conv3_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block5_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block5_concat (Concatenat (None, 37, 37, 288)  0           conv3_block4_concat[0][0]        \n                                                                 conv3_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_bn (BatchNormali (None, 37, 37, 288)  1152        conv3_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_0_relu (Activation (None, 37, 37, 288)  0           conv3_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_1_conv (Conv2D)    (None, 37, 37, 128)  36864       conv3_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_1_relu (Activation (None, 37, 37, 128)  0           conv3_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block6_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block6_concat (Concatenat (None, 37, 37, 320)  0           conv3_block5_concat[0][0]        \n                                                                 conv3_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_bn (BatchNormali (None, 37, 37, 320)  1280        conv3_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_0_relu (Activation (None, 37, 37, 320)  0           conv3_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_1_conv (Conv2D)    (None, 37, 37, 128)  40960       conv3_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_1_relu (Activation (None, 37, 37, 128)  0           conv3_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block7_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block7_concat (Concatenat (None, 37, 37, 352)  0           conv3_block6_concat[0][0]        \n                                                                 conv3_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_bn (BatchNormali (None, 37, 37, 352)  1408        conv3_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_0_relu (Activation (None, 37, 37, 352)  0           conv3_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_1_conv (Conv2D)    (None, 37, 37, 128)  45056       conv3_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_1_relu (Activation (None, 37, 37, 128)  0           conv3_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block8_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block8_concat (Concatenat (None, 37, 37, 384)  0           conv3_block7_concat[0][0]        \n                                                                 conv3_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_bn (BatchNormali (None, 37, 37, 384)  1536        conv3_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_0_relu (Activation (None, 37, 37, 384)  0           conv3_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_1_conv (Conv2D)    (None, 37, 37, 128)  49152       conv3_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_bn (BatchNormali (None, 37, 37, 128)  512         conv3_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_1_relu (Activation (None, 37, 37, 128)  0           conv3_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv3_block9_2_conv (Conv2D)    (None, 37, 37, 32)   36864       conv3_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv3_block9_concat (Concatenat (None, 37, 37, 416)  0           conv3_block8_concat[0][0]        \n                                                                 conv3_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_bn (BatchNormal (None, 37, 37, 416)  1664        conv3_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv3_block10_0_relu (Activatio (None, 37, 37, 416)  0           conv3_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_1_conv (Conv2D)   (None, 37, 37, 128)  53248       conv3_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_bn (BatchNormal (None, 37, 37, 128)  512         conv3_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_1_relu (Activatio (None, 37, 37, 128)  0           conv3_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block10_2_conv (Conv2D)   (None, 37, 37, 32)   36864       conv3_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block10_concat (Concatena (None, 37, 37, 448)  0           conv3_block9_concat[0][0]        \n                                                                 conv3_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_bn (BatchNormal (None, 37, 37, 448)  1792        conv3_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_0_relu (Activatio (None, 37, 37, 448)  0           conv3_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_1_conv (Conv2D)   (None, 37, 37, 128)  57344       conv3_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_bn (BatchNormal (None, 37, 37, 128)  512         conv3_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_1_relu (Activatio (None, 37, 37, 128)  0           conv3_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block11_2_conv (Conv2D)   (None, 37, 37, 32)   36864       conv3_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block11_concat (Concatena (None, 37, 37, 480)  0           conv3_block10_concat[0][0]       \n                                                                 conv3_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_bn (BatchNormal (None, 37, 37, 480)  1920        conv3_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_0_relu (Activatio (None, 37, 37, 480)  0           conv3_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_1_conv (Conv2D)   (None, 37, 37, 128)  61440       conv3_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_bn (BatchNormal (None, 37, 37, 128)  512         conv3_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_1_relu (Activatio (None, 37, 37, 128)  0           conv3_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv3_block12_2_conv (Conv2D)   (None, 37, 37, 32)   36864       conv3_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv3_block12_concat (Concatena (None, 37, 37, 512)  0           conv3_block11_concat[0][0]       \n                                                                 conv3_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\npool3_bn (BatchNormalization)   (None, 37, 37, 512)  2048        conv3_block12_concat[0][0]       \n__________________________________________________________________________________________________\npool3_relu (Activation)         (None, 37, 37, 512)  0           pool3_bn[0][0]                   \n__________________________________________________________________________________________________\npool3_conv (Conv2D)             (None, 37, 37, 256)  131072      pool3_relu[0][0]                 \n__________________________________________________________________________________________________\npool3_pool (AveragePooling2D)   (None, 18, 18, 256)  0           pool3_conv[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_bn (BatchNormali (None, 18, 18, 256)  1024        pool3_pool[0][0]                 \n__________________________________________________________________________________________________\nconv4_block1_0_relu (Activation (None, 18, 18, 256)  0           conv4_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_1_conv (Conv2D)    (None, 18, 18, 128)  32768       conv4_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_1_relu (Activation (None, 18, 18, 128)  0           conv4_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block1_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block1_concat (Concatenat (None, 18, 18, 288)  0           pool3_pool[0][0]                 \n                                                                 conv4_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_bn (BatchNormali (None, 18, 18, 288)  1152        conv4_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_0_relu (Activation (None, 18, 18, 288)  0           conv4_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_1_conv (Conv2D)    (None, 18, 18, 128)  36864       conv4_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_1_relu (Activation (None, 18, 18, 128)  0           conv4_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block2_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block2_concat (Concatenat (None, 18, 18, 320)  0           conv4_block1_concat[0][0]        \n                                                                 conv4_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_bn (BatchNormali (None, 18, 18, 320)  1280        conv4_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_0_relu (Activation (None, 18, 18, 320)  0           conv4_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_1_conv (Conv2D)    (None, 18, 18, 128)  40960       conv4_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_1_relu (Activation (None, 18, 18, 128)  0           conv4_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block3_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block3_concat (Concatenat (None, 18, 18, 352)  0           conv4_block2_concat[0][0]        \n                                                                 conv4_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_bn (BatchNormali (None, 18, 18, 352)  1408        conv4_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_0_relu (Activation (None, 18, 18, 352)  0           conv4_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_1_conv (Conv2D)    (None, 18, 18, 128)  45056       conv4_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_1_relu (Activation (None, 18, 18, 128)  0           conv4_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block4_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block4_concat (Concatenat (None, 18, 18, 384)  0           conv4_block3_concat[0][0]        \n                                                                 conv4_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_bn (BatchNormali (None, 18, 18, 384)  1536        conv4_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_0_relu (Activation (None, 18, 18, 384)  0           conv4_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_1_conv (Conv2D)    (None, 18, 18, 128)  49152       conv4_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_1_relu (Activation (None, 18, 18, 128)  0           conv4_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block5_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block5_concat (Concatenat (None, 18, 18, 416)  0           conv4_block4_concat[0][0]        \n                                                                 conv4_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_bn (BatchNormali (None, 18, 18, 416)  1664        conv4_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_0_relu (Activation (None, 18, 18, 416)  0           conv4_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_1_conv (Conv2D)    (None, 18, 18, 128)  53248       conv4_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_1_relu (Activation (None, 18, 18, 128)  0           conv4_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block6_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block6_concat (Concatenat (None, 18, 18, 448)  0           conv4_block5_concat[0][0]        \n                                                                 conv4_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_bn (BatchNormali (None, 18, 18, 448)  1792        conv4_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_0_relu (Activation (None, 18, 18, 448)  0           conv4_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_1_conv (Conv2D)    (None, 18, 18, 128)  57344       conv4_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_1_relu (Activation (None, 18, 18, 128)  0           conv4_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block7_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block7_concat (Concatenat (None, 18, 18, 480)  0           conv4_block6_concat[0][0]        \n                                                                 conv4_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_bn (BatchNormali (None, 18, 18, 480)  1920        conv4_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_0_relu (Activation (None, 18, 18, 480)  0           conv4_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_1_conv (Conv2D)    (None, 18, 18, 128)  61440       conv4_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_1_relu (Activation (None, 18, 18, 128)  0           conv4_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block8_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block8_concat (Concatenat (None, 18, 18, 512)  0           conv4_block7_concat[0][0]        \n                                                                 conv4_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_bn (BatchNormali (None, 18, 18, 512)  2048        conv4_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_0_relu (Activation (None, 18, 18, 512)  0           conv4_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_1_conv (Conv2D)    (None, 18, 18, 128)  65536       conv4_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_bn (BatchNormali (None, 18, 18, 128)  512         conv4_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_1_relu (Activation (None, 18, 18, 128)  0           conv4_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv4_block9_2_conv (Conv2D)    (None, 18, 18, 32)   36864       conv4_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv4_block9_concat (Concatenat (None, 18, 18, 544)  0           conv4_block8_concat[0][0]        \n                                                                 conv4_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_bn (BatchNormal (None, 18, 18, 544)  2176        conv4_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv4_block10_0_relu (Activatio (None, 18, 18, 544)  0           conv4_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_1_conv (Conv2D)   (None, 18, 18, 128)  69632       conv4_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block10_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block10_concat (Concatena (None, 18, 18, 576)  0           conv4_block9_concat[0][0]        \n                                                                 conv4_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_bn (BatchNormal (None, 18, 18, 576)  2304        conv4_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_0_relu (Activatio (None, 18, 18, 576)  0           conv4_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_1_conv (Conv2D)   (None, 18, 18, 128)  73728       conv4_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block11_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block11_concat (Concatena (None, 18, 18, 608)  0           conv4_block10_concat[0][0]       \n                                                                 conv4_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_bn (BatchNormal (None, 18, 18, 608)  2432        conv4_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_0_relu (Activatio (None, 18, 18, 608)  0           conv4_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_1_conv (Conv2D)   (None, 18, 18, 128)  77824       conv4_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block12_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block12_concat (Concatena (None, 18, 18, 640)  0           conv4_block11_concat[0][0]       \n                                                                 conv4_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_bn (BatchNormal (None, 18, 18, 640)  2560        conv4_block12_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_0_relu (Activatio (None, 18, 18, 640)  0           conv4_block13_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_1_conv (Conv2D)   (None, 18, 18, 128)  81920       conv4_block13_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block13_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block13_concat (Concatena (None, 18, 18, 672)  0           conv4_block12_concat[0][0]       \n                                                                 conv4_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_bn (BatchNormal (None, 18, 18, 672)  2688        conv4_block13_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_0_relu (Activatio (None, 18, 18, 672)  0           conv4_block14_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_1_conv (Conv2D)   (None, 18, 18, 128)  86016       conv4_block14_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block14_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block14_concat (Concatena (None, 18, 18, 704)  0           conv4_block13_concat[0][0]       \n                                                                 conv4_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_bn (BatchNormal (None, 18, 18, 704)  2816        conv4_block14_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_0_relu (Activatio (None, 18, 18, 704)  0           conv4_block15_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_1_conv (Conv2D)   (None, 18, 18, 128)  90112       conv4_block15_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block15_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block15_concat (Concatena (None, 18, 18, 736)  0           conv4_block14_concat[0][0]       \n                                                                 conv4_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_bn (BatchNormal (None, 18, 18, 736)  2944        conv4_block15_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_0_relu (Activatio (None, 18, 18, 736)  0           conv4_block16_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_1_conv (Conv2D)   (None, 18, 18, 128)  94208       conv4_block16_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block16_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block16_concat (Concatena (None, 18, 18, 768)  0           conv4_block15_concat[0][0]       \n                                                                 conv4_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_bn (BatchNormal (None, 18, 18, 768)  3072        conv4_block16_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_0_relu (Activatio (None, 18, 18, 768)  0           conv4_block17_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_1_conv (Conv2D)   (None, 18, 18, 128)  98304       conv4_block17_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block17_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block17_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block17_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block17_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block17_concat (Concatena (None, 18, 18, 800)  0           conv4_block16_concat[0][0]       \n                                                                 conv4_block17_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_bn (BatchNormal (None, 18, 18, 800)  3200        conv4_block17_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_0_relu (Activatio (None, 18, 18, 800)  0           conv4_block18_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_1_conv (Conv2D)   (None, 18, 18, 128)  102400      conv4_block18_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block18_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block18_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block18_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block18_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block18_concat (Concatena (None, 18, 18, 832)  0           conv4_block17_concat[0][0]       \n                                                                 conv4_block18_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_bn (BatchNormal (None, 18, 18, 832)  3328        conv4_block18_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_0_relu (Activatio (None, 18, 18, 832)  0           conv4_block19_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_1_conv (Conv2D)   (None, 18, 18, 128)  106496      conv4_block19_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block19_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block19_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block19_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block19_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block19_concat (Concatena (None, 18, 18, 864)  0           conv4_block18_concat[0][0]       \n                                                                 conv4_block19_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_bn (BatchNormal (None, 18, 18, 864)  3456        conv4_block19_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_0_relu (Activatio (None, 18, 18, 864)  0           conv4_block20_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_1_conv (Conv2D)   (None, 18, 18, 128)  110592      conv4_block20_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block20_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block20_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block20_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block20_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block20_concat (Concatena (None, 18, 18, 896)  0           conv4_block19_concat[0][0]       \n                                                                 conv4_block20_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_bn (BatchNormal (None, 18, 18, 896)  3584        conv4_block20_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_0_relu (Activatio (None, 18, 18, 896)  0           conv4_block21_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_1_conv (Conv2D)   (None, 18, 18, 128)  114688      conv4_block21_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block21_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block21_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block21_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block21_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block21_concat (Concatena (None, 18, 18, 928)  0           conv4_block20_concat[0][0]       \n                                                                 conv4_block21_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_bn (BatchNormal (None, 18, 18, 928)  3712        conv4_block21_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_0_relu (Activatio (None, 18, 18, 928)  0           conv4_block22_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_1_conv (Conv2D)   (None, 18, 18, 128)  118784      conv4_block22_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block22_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block22_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block22_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block22_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block22_concat (Concatena (None, 18, 18, 960)  0           conv4_block21_concat[0][0]       \n                                                                 conv4_block22_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_bn (BatchNormal (None, 18, 18, 960)  3840        conv4_block22_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_0_relu (Activatio (None, 18, 18, 960)  0           conv4_block23_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_1_conv (Conv2D)   (None, 18, 18, 128)  122880      conv4_block23_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block23_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block23_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block23_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block23_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block23_concat (Concatena (None, 18, 18, 992)  0           conv4_block22_concat[0][0]       \n                                                                 conv4_block23_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_bn (BatchNormal (None, 18, 18, 992)  3968        conv4_block23_concat[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_0_relu (Activatio (None, 18, 18, 992)  0           conv4_block24_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_1_conv (Conv2D)   (None, 18, 18, 128)  126976      conv4_block24_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_bn (BatchNormal (None, 18, 18, 128)  512         conv4_block24_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_1_relu (Activatio (None, 18, 18, 128)  0           conv4_block24_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv4_block24_2_conv (Conv2D)   (None, 18, 18, 32)   36864       conv4_block24_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv4_block24_concat (Concatena (None, 18, 18, 1024) 0           conv4_block23_concat[0][0]       \n                                                                 conv4_block24_2_conv[0][0]       \n__________________________________________________________________________________________________\npool4_bn (BatchNormalization)   (None, 18, 18, 1024) 4096        conv4_block24_concat[0][0]       \n__________________________________________________________________________________________________\npool4_relu (Activation)         (None, 18, 18, 1024) 0           pool4_bn[0][0]                   \n__________________________________________________________________________________________________\npool4_conv (Conv2D)             (None, 18, 18, 512)  524288      pool4_relu[0][0]                 \n__________________________________________________________________________________________________\npool4_pool (AveragePooling2D)   (None, 9, 9, 512)    0           pool4_conv[0][0]                 \n__________________________________________________________________________________________________\nconv5_block1_0_bn (BatchNormali (None, 9, 9, 512)    2048        pool4_pool[0][0]                 \n__________________________________________________________________________________________________\nconv5_block1_0_relu (Activation (None, 9, 9, 512)    0           conv5_block1_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_1_conv (Conv2D)    (None, 9, 9, 128)    65536       conv5_block1_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block1_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_1_relu (Activation (None, 9, 9, 128)    0           conv5_block1_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block1_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block1_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block1_concat (Concatenat (None, 9, 9, 544)    0           pool4_pool[0][0]                 \n                                                                 conv5_block1_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_0_bn (BatchNormali (None, 9, 9, 544)    2176        conv5_block1_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_0_relu (Activation (None, 9, 9, 544)    0           conv5_block2_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_1_conv (Conv2D)    (None, 9, 9, 128)    69632       conv5_block2_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block2_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_1_relu (Activation (None, 9, 9, 128)    0           conv5_block2_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block2_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block2_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block2_concat (Concatenat (None, 9, 9, 576)    0           conv5_block1_concat[0][0]        \n                                                                 conv5_block2_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_0_bn (BatchNormali (None, 9, 9, 576)    2304        conv5_block2_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_0_relu (Activation (None, 9, 9, 576)    0           conv5_block3_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_1_conv (Conv2D)    (None, 9, 9, 128)    73728       conv5_block3_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block3_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_1_relu (Activation (None, 9, 9, 128)    0           conv5_block3_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block3_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block3_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block3_concat (Concatenat (None, 9, 9, 608)    0           conv5_block2_concat[0][0]        \n                                                                 conv5_block3_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_0_bn (BatchNormali (None, 9, 9, 608)    2432        conv5_block3_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_0_relu (Activation (None, 9, 9, 608)    0           conv5_block4_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block4_1_conv (Conv2D)    (None, 9, 9, 128)    77824       conv5_block4_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block4_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_1_relu (Activation (None, 9, 9, 128)    0           conv5_block4_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block4_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block4_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block4_concat (Concatenat (None, 9, 9, 640)    0           conv5_block3_concat[0][0]        \n                                                                 conv5_block4_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_0_bn (BatchNormali (None, 9, 9, 640)    2560        conv5_block4_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_0_relu (Activation (None, 9, 9, 640)    0           conv5_block5_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block5_1_conv (Conv2D)    (None, 9, 9, 128)    81920       conv5_block5_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block5_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_1_relu (Activation (None, 9, 9, 128)    0           conv5_block5_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block5_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block5_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block5_concat (Concatenat (None, 9, 9, 672)    0           conv5_block4_concat[0][0]        \n                                                                 conv5_block5_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_0_bn (BatchNormali (None, 9, 9, 672)    2688        conv5_block5_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_0_relu (Activation (None, 9, 9, 672)    0           conv5_block6_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block6_1_conv (Conv2D)    (None, 9, 9, 128)    86016       conv5_block6_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block6_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_1_relu (Activation (None, 9, 9, 128)    0           conv5_block6_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block6_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block6_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block6_concat (Concatenat (None, 9, 9, 704)    0           conv5_block5_concat[0][0]        \n                                                                 conv5_block6_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_0_bn (BatchNormali (None, 9, 9, 704)    2816        conv5_block6_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_0_relu (Activation (None, 9, 9, 704)    0           conv5_block7_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block7_1_conv (Conv2D)    (None, 9, 9, 128)    90112       conv5_block7_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block7_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_1_relu (Activation (None, 9, 9, 128)    0           conv5_block7_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block7_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block7_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block7_concat (Concatenat (None, 9, 9, 736)    0           conv5_block6_concat[0][0]        \n                                                                 conv5_block7_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_0_bn (BatchNormali (None, 9, 9, 736)    2944        conv5_block7_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_0_relu (Activation (None, 9, 9, 736)    0           conv5_block8_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block8_1_conv (Conv2D)    (None, 9, 9, 128)    94208       conv5_block8_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block8_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_1_relu (Activation (None, 9, 9, 128)    0           conv5_block8_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block8_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block8_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block8_concat (Concatenat (None, 9, 9, 768)    0           conv5_block7_concat[0][0]        \n                                                                 conv5_block8_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_0_bn (BatchNormali (None, 9, 9, 768)    3072        conv5_block8_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_0_relu (Activation (None, 9, 9, 768)    0           conv5_block9_0_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block9_1_conv (Conv2D)    (None, 9, 9, 128)    98304       conv5_block9_0_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_1_bn (BatchNormali (None, 9, 9, 128)    512         conv5_block9_1_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_1_relu (Activation (None, 9, 9, 128)    0           conv5_block9_1_bn[0][0]          \n__________________________________________________________________________________________________\nconv5_block9_2_conv (Conv2D)    (None, 9, 9, 32)     36864       conv5_block9_1_relu[0][0]        \n__________________________________________________________________________________________________\nconv5_block9_concat (Concatenat (None, 9, 9, 800)    0           conv5_block8_concat[0][0]        \n                                                                 conv5_block9_2_conv[0][0]        \n__________________________________________________________________________________________________\nconv5_block10_0_bn (BatchNormal (None, 9, 9, 800)    3200        conv5_block9_concat[0][0]        \n__________________________________________________________________________________________________\nconv5_block10_0_relu (Activatio (None, 9, 9, 800)    0           conv5_block10_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block10_1_conv (Conv2D)   (None, 9, 9, 128)    102400      conv5_block10_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block10_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block10_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block10_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block10_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block10_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block10_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block10_concat (Concatena (None, 9, 9, 832)    0           conv5_block9_concat[0][0]        \n                                                                 conv5_block10_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_0_bn (BatchNormal (None, 9, 9, 832)    3328        conv5_block10_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_0_relu (Activatio (None, 9, 9, 832)    0           conv5_block11_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block11_1_conv (Conv2D)   (None, 9, 9, 128)    106496      conv5_block11_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block11_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block11_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block11_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block11_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block11_concat (Concatena (None, 9, 9, 864)    0           conv5_block10_concat[0][0]       \n                                                                 conv5_block11_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_0_bn (BatchNormal (None, 9, 9, 864)    3456        conv5_block11_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_0_relu (Activatio (None, 9, 9, 864)    0           conv5_block12_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block12_1_conv (Conv2D)   (None, 9, 9, 128)    110592      conv5_block12_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block12_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block12_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block12_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block12_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block12_concat (Concatena (None, 9, 9, 896)    0           conv5_block11_concat[0][0]       \n                                                                 conv5_block12_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_0_bn (BatchNormal (None, 9, 9, 896)    3584        conv5_block12_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_0_relu (Activatio (None, 9, 9, 896)    0           conv5_block13_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block13_1_conv (Conv2D)   (None, 9, 9, 128)    114688      conv5_block13_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block13_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block13_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block13_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block13_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block13_concat (Concatena (None, 9, 9, 928)    0           conv5_block12_concat[0][0]       \n                                                                 conv5_block13_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_0_bn (BatchNormal (None, 9, 9, 928)    3712        conv5_block13_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_0_relu (Activatio (None, 9, 9, 928)    0           conv5_block14_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block14_1_conv (Conv2D)   (None, 9, 9, 128)    118784      conv5_block14_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block14_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block14_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block14_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block14_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block14_concat (Concatena (None, 9, 9, 960)    0           conv5_block13_concat[0][0]       \n                                                                 conv5_block14_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_0_bn (BatchNormal (None, 9, 9, 960)    3840        conv5_block14_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_0_relu (Activatio (None, 9, 9, 960)    0           conv5_block15_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block15_1_conv (Conv2D)   (None, 9, 9, 128)    122880      conv5_block15_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block15_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block15_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block15_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block15_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block15_concat (Concatena (None, 9, 9, 992)    0           conv5_block14_concat[0][0]       \n                                                                 conv5_block15_2_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_0_bn (BatchNormal (None, 9, 9, 992)    3968        conv5_block15_concat[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_0_relu (Activatio (None, 9, 9, 992)    0           conv5_block16_0_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block16_1_conv (Conv2D)   (None, 9, 9, 128)    126976      conv5_block16_0_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_1_bn (BatchNormal (None, 9, 9, 128)    512         conv5_block16_1_conv[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_1_relu (Activatio (None, 9, 9, 128)    0           conv5_block16_1_bn[0][0]         \n__________________________________________________________________________________________________\nconv5_block16_2_conv (Conv2D)   (None, 9, 9, 32)     36864       conv5_block16_1_relu[0][0]       \n__________________________________________________________________________________________________\nconv5_block16_concat (Concatena (None, 9, 9, 1024)   0           conv5_block15_concat[0][0]       \n                                                                 conv5_block16_2_conv[0][0]       \n__________________________________________________________________________________________________\nbn (BatchNormalization)         (None, 9, 9, 1024)   4096        conv5_block16_concat[0][0]       \n__________________________________________________________________________________________________\nrelu (Activation)               (None, 9, 9, 1024)   0           bn[0][0]                         \n__________________________________________________________________________________________________\navg_pool (GlobalAveragePooling2 (None, 1024)         0           relu[0][0]                       \n==================================================================================================\nTotal params: 7,037,504\nTrainable params: 6,953,856\nNon-trainable params: 83,648\n__________________________________________________________________________________________________\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for i, layer in enumerate(model.layers):\n#     print(i, layer.name)","execution_count":24,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_final_model = base_model1","execution_count":25,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train, max_q_size=1, pickle_safe=False)\nnp.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)","execution_count":26,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\nnp.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)","execution_count":27,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\nnp.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)","execution_count":28,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"\n# import tensorflow as tf\n# from keras.backend.tensorflow_backend import get_session\n# from keras.backend.tensorflow_backend import clear_session\n# from keras.backend.tensorflow_backend import set_session\n\n# def reset_keras_tf_session():\n#     \"\"\"\n#     this function clears the gpu memory and set the \n#     tf session to not use the whole gpu\n#     \"\"\"\n#     sess = get_session()\n#     clear_session()\n#     sess.close()\n#     sess = get_session()\n\n# #     config = tf.ConfigProto()\n# #     config.gpu_options.allow_growth = True\n# #     set_session(tf.Session(config=config))\n\n# reset_keras_tf_session()","execution_count":29,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\nvalidation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\ntest_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n\ntrain_labels = train_generator.classes\ntrain_labels = to_categorical(train_labels, num_classes=num_classes)\n\nvalidation_labels = validation_generator.classes\nvalidation_labels = to_categorical(validation_labels, num_classes=num_classes)\n\ntest_labels = test_generator.classes\ntest_labels = to_categorical(test_labels, num_classes=num_classes)","execution_count":30,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"adam_opt=Adam(lr=0.0001, beta_1=0.8, beta_2=0.9)\ndropout_rate = 0.5\n\nmodel = Sequential()\nmodel.add(Dense(4096, activation=\"elu\", kernel_regularizer=l2(1e-05), bias_regularizer=l2(0.1), activity_regularizer=l1(1e-05)))\nmodel.add(Dropout(dropout_rate))\n\nmodel.add(Dense(256, activation=\"elu\", kernel_regularizer=l2(1e-05), bias_regularizer=l2(0.1), activity_regularizer=l1(1e-05)))\nmodel.add(Dropout(dropout_rate))\n\nmodel.add(Dense(num_classes, activation=\"softmax\"))\n\nmodel.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\nhistory = model.fit(train_data, train_labels,\n                    epochs=epochs,\n                    batch_size=batch_size,\n                    validation_data=(validation_data, validation_labels),\n                    verbose= 2)\n","execution_count":31,"outputs":[{"output_type":"stream","text":"Train on 2656 samples, validate on 663 samples\nEpoch 1/1000\n - 6s - loss: 0.7857 - acc: 0.8622 - val_loss: 0.4677 - val_acc: 0.9623\nEpoch 2/1000\n - 1s - loss: 0.5922 - acc: 0.9164 - val_loss: 0.3919 - val_acc: 0.9668\nEpoch 3/1000\n - 1s - loss: 0.5192 - acc: 0.9322 - val_loss: 0.3580 - val_acc: 0.9713\nEpoch 4/1000\n - 1s - loss: 0.5047 - acc: 0.9266 - val_loss: 0.3472 - val_acc: 0.9713\nEpoch 5/1000\n - 1s - loss: 0.4947 - acc: 0.9337 - val_loss: 0.3740 - val_acc: 0.9713\nEpoch 6/1000\n - 1s - loss: 0.4681 - acc: 0.9341 - val_loss: 0.3352 - val_acc: 0.9713\nEpoch 7/1000\n - 1s - loss: 0.4711 - acc: 0.9319 - val_loss: 0.3463 - val_acc: 0.9683\nEpoch 8/1000\n - 1s - loss: 0.4657 - acc: 0.9288 - val_loss: 0.3207 - val_acc: 0.9744\nEpoch 9/1000\n - 1s - loss: 0.4595 - acc: 0.9281 - val_loss: 0.3200 - val_acc: 0.9729\nEpoch 10/1000\n - 1s - loss: 0.4559 - acc: 0.9360 - val_loss: 0.3166 - val_acc: 0.9729\nEpoch 11/1000\n - 1s - loss: 0.4216 - acc: 0.9439 - val_loss: 0.3163 - val_acc: 0.9729\nEpoch 12/1000\n - 1s - loss: 0.4363 - acc: 0.9420 - val_loss: 0.3171 - val_acc: 0.9729\nEpoch 13/1000\n - 1s - loss: 0.4267 - acc: 0.9394 - val_loss: 0.3474 - val_acc: 0.9563\nEpoch 14/1000\n - 1s - loss: 0.4185 - acc: 0.9477 - val_loss: 0.3132 - val_acc: 0.9774\nEpoch 15/1000\n - 1s - loss: 0.4109 - acc: 0.9469 - val_loss: 0.3062 - val_acc: 0.9713\nEpoch 16/1000\n - 1s - loss: 0.4051 - acc: 0.9458 - val_loss: 0.3057 - val_acc: 0.9729\nEpoch 17/1000\n - 1s - loss: 0.4190 - acc: 0.9390 - val_loss: 0.3169 - val_acc: 0.9744\nEpoch 18/1000\n - 1s - loss: 0.4103 - acc: 0.9465 - val_loss: 0.3666 - val_acc: 0.9578\nEpoch 19/1000\n - 1s - loss: 0.4025 - acc: 0.9424 - val_loss: 0.3201 - val_acc: 0.9668\nEpoch 20/1000\n - 1s - loss: 0.3957 - acc: 0.9488 - val_loss: 0.3221 - val_acc: 0.9713\nEpoch 21/1000\n - 1s - loss: 0.3985 - acc: 0.9462 - val_loss: 0.3168 - val_acc: 0.9729\nEpoch 22/1000\n - 1s - loss: 0.3834 - acc: 0.9477 - val_loss: 0.3155 - val_acc: 0.9729\nEpoch 23/1000\n - 1s - loss: 0.3805 - acc: 0.9492 - val_loss: 0.3074 - val_acc: 0.9668\nEpoch 24/1000\n - 1s - loss: 0.3832 - acc: 0.9480 - val_loss: 0.3047 - val_acc: 0.9683\nEpoch 25/1000\n - 1s - loss: 0.3759 - acc: 0.9458 - val_loss: 0.3591 - val_acc: 0.9532\nEpoch 26/1000\n - 1s - loss: 0.3906 - acc: 0.9431 - val_loss: 0.3165 - val_acc: 0.9608\nEpoch 27/1000\n - 1s - loss: 0.3776 - acc: 0.9473 - val_loss: 0.3084 - val_acc: 0.9668\nEpoch 28/1000\n - 1s - loss: 0.3849 - acc: 0.9431 - val_loss: 0.3134 - val_acc: 0.9623\nEpoch 29/1000\n - 1s - loss: 0.3727 - acc: 0.9488 - val_loss: 0.2852 - val_acc: 0.9683\nEpoch 30/1000\n - 1s - loss: 0.3633 - acc: 0.9541 - val_loss: 0.2987 - val_acc: 0.9729\nEpoch 31/1000\n - 1s - loss: 0.3698 - acc: 0.9477 - val_loss: 0.2967 - val_acc: 0.9653\nEpoch 32/1000\n - 1s - loss: 0.3821 - acc: 0.9443 - val_loss: 0.2979 - val_acc: 0.9698\nEpoch 33/1000\n - 1s - loss: 0.3567 - acc: 0.9526 - val_loss: 0.2895 - val_acc: 0.9713\nEpoch 34/1000\n - 1s - loss: 0.3623 - acc: 0.9541 - val_loss: 0.2925 - val_acc: 0.9698\nEpoch 35/1000\n - 1s - loss: 0.3608 - acc: 0.9495 - val_loss: 0.2887 - val_acc: 0.9683\nEpoch 36/1000\n - 1s - loss: 0.3605 - acc: 0.9492 - val_loss: 0.2882 - val_acc: 0.9713\nEpoch 37/1000\n - 1s - loss: 0.3543 - acc: 0.9514 - val_loss: 0.2831 - val_acc: 0.9729\nEpoch 38/1000\n - 1s - loss: 0.3569 - acc: 0.9507 - val_loss: 0.2867 - val_acc: 0.9729\nEpoch 39/1000\n - 1s - loss: 0.3533 - acc: 0.9544 - val_loss: 0.3013 - val_acc: 0.9698\nEpoch 40/1000\n - 1s - loss: 0.3572 - acc: 0.9477 - val_loss: 0.2904 - val_acc: 0.9683\nEpoch 41/1000\n - 1s - loss: 0.3485 - acc: 0.9533 - val_loss: 0.2994 - val_acc: 0.9668\nEpoch 42/1000\n - 1s - loss: 0.3449 - acc: 0.9492 - val_loss: 0.3009 - val_acc: 0.9653\nEpoch 43/1000\n - 1s - loss: 0.3491 - acc: 0.9507 - val_loss: 0.3646 - val_acc: 0.9397\nEpoch 44/1000\n - 1s - loss: 0.3517 - acc: 0.9499 - val_loss: 0.2809 - val_acc: 0.9683\nEpoch 45/1000\n - 1s - loss: 0.3403 - acc: 0.9507 - val_loss: 0.3414 - val_acc: 0.9487\nEpoch 46/1000\n - 1s - loss: 0.3356 - acc: 0.9503 - val_loss: 0.2773 - val_acc: 0.9729\nEpoch 47/1000\n - 1s - loss: 0.3416 - acc: 0.9518 - val_loss: 0.2837 - val_acc: 0.9698\nEpoch 48/1000\n - 1s - loss: 0.3333 - acc: 0.9492 - val_loss: 0.3041 - val_acc: 0.9668\nEpoch 49/1000\n - 1s - loss: 0.3343 - acc: 0.9567 - val_loss: 0.2973 - val_acc: 0.9623\nEpoch 50/1000\n - 1s - loss: 0.3337 - acc: 0.9559 - val_loss: 0.2763 - val_acc: 0.9713\nEpoch 51/1000\n - 1s - loss: 0.3246 - acc: 0.9571 - val_loss: 0.2914 - val_acc: 0.9668\nEpoch 52/1000\n - 1s - loss: 0.3218 - acc: 0.9537 - val_loss: 0.2939 - val_acc: 0.9593\nEpoch 53/1000\n - 1s - loss: 0.3197 - acc: 0.9548 - val_loss: 0.2737 - val_acc: 0.9683\nEpoch 54/1000\n - 1s - loss: 0.3338 - acc: 0.9526 - val_loss: 0.2855 - val_acc: 0.9698\nEpoch 55/1000\n - 1s - loss: 0.3269 - acc: 0.9556 - val_loss: 0.3319 - val_acc: 0.9472\nEpoch 56/1000\n - 1s - loss: 0.3221 - acc: 0.9548 - val_loss: 0.2777 - val_acc: 0.9729\nEpoch 57/1000\n - 1s - loss: 0.3189 - acc: 0.9533 - val_loss: 0.3403 - val_acc: 0.9442\nEpoch 58/1000\n - 1s - loss: 0.3204 - acc: 0.9511 - val_loss: 0.2985 - val_acc: 0.9638\nEpoch 59/1000\n - 1s - loss: 0.3261 - acc: 0.9571 - val_loss: 0.2924 - val_acc: 0.9668\nEpoch 60/1000\n - 1s - loss: 0.3113 - acc: 0.9608 - val_loss: 0.2841 - val_acc: 0.9653\nEpoch 61/1000\n - 1s - loss: 0.3138 - acc: 0.9544 - val_loss: 0.3586 - val_acc: 0.9382\nEpoch 62/1000\n - 1s - loss: 0.3230 - acc: 0.9526 - val_loss: 0.3501 - val_acc: 0.9442\nEpoch 63/1000\n - 1s - loss: 0.3016 - acc: 0.9590 - val_loss: 0.2981 - val_acc: 0.9623\nEpoch 64/1000\n - 1s - loss: 0.3067 - acc: 0.9597 - val_loss: 0.2764 - val_acc: 0.9683\nEpoch 65/1000\n - 1s - loss: 0.3096 - acc: 0.9620 - val_loss: 0.2997 - val_acc: 0.9472\nEpoch 66/1000\n - 1s - loss: 0.3179 - acc: 0.9518 - val_loss: 0.2964 - val_acc: 0.9593\nEpoch 67/1000\n - 1s - loss: 0.3074 - acc: 0.9552 - val_loss: 0.2746 - val_acc: 0.9683\nEpoch 68/1000\n - 1s - loss: 0.3025 - acc: 0.9567 - val_loss: 0.3125 - val_acc: 0.9472\nEpoch 69/1000\n - 1s - loss: 0.3075 - acc: 0.9514 - val_loss: 0.2959 - val_acc: 0.9623\nEpoch 70/1000\n - 1s - loss: 0.2972 - acc: 0.9593 - val_loss: 0.2778 - val_acc: 0.9653\nEpoch 71/1000\n - 1s - loss: 0.3069 - acc: 0.9541 - val_loss: 0.2969 - val_acc: 0.9578\nEpoch 72/1000\n - 1s - loss: 0.3020 - acc: 0.9590 - val_loss: 0.2868 - val_acc: 0.9668\nEpoch 73/1000\n - 1s - loss: 0.3058 - acc: 0.9548 - val_loss: 0.2793 - val_acc: 0.9668\nEpoch 74/1000\n - 1s - loss: 0.2985 - acc: 0.9582 - val_loss: 0.2850 - val_acc: 0.9608\nEpoch 75/1000\n - 1s - loss: 0.3150 - acc: 0.9522 - val_loss: 0.2774 - val_acc: 0.9548\nEpoch 76/1000\n - 1s - loss: 0.2928 - acc: 0.9575 - val_loss: 0.2832 - val_acc: 0.9653\nEpoch 77/1000\n - 1s - loss: 0.3035 - acc: 0.9582 - val_loss: 0.2858 - val_acc: 0.9548\nEpoch 78/1000\n - 1s - loss: 0.2947 - acc: 0.9620 - val_loss: 0.2774 - val_acc: 0.9653\nEpoch 79/1000\n - 1s - loss: 0.2907 - acc: 0.9593 - val_loss: 0.2828 - val_acc: 0.9653\nEpoch 80/1000\n - 1s - loss: 0.2960 - acc: 0.9582 - val_loss: 0.2733 - val_acc: 0.9608\nEpoch 81/1000\n - 1s - loss: 0.2932 - acc: 0.9590 - val_loss: 0.2762 - val_acc: 0.9638\nEpoch 82/1000\n - 1s - loss: 0.2953 - acc: 0.9590 - val_loss: 0.3620 - val_acc: 0.9397\nEpoch 83/1000\n - 1s - loss: 0.2882 - acc: 0.9597 - val_loss: 0.2947 - val_acc: 0.9593\nEpoch 84/1000\n - 1s - loss: 0.2889 - acc: 0.9586 - val_loss: 0.2714 - val_acc: 0.9638\nEpoch 85/1000\n - 1s - loss: 0.2860 - acc: 0.9586 - val_loss: 0.2911 - val_acc: 0.9578\nEpoch 86/1000\n - 1s - loss: 0.2862 - acc: 0.9575 - val_loss: 0.3060 - val_acc: 0.9563\nEpoch 87/1000\n - 1s - loss: 0.2817 - acc: 0.9608 - val_loss: 0.2789 - val_acc: 0.9653\nEpoch 88/1000\n - 1s - loss: 0.2695 - acc: 0.9672 - val_loss: 0.2997 - val_acc: 0.9548\nEpoch 89/1000\n - 1s - loss: 0.2883 - acc: 0.9556 - val_loss: 0.2843 - val_acc: 0.9668\nEpoch 90/1000\n - 1s - loss: 0.2854 - acc: 0.9590 - val_loss: 0.2757 - val_acc: 0.9608\nEpoch 91/1000\n - 1s - loss: 0.2779 - acc: 0.9605 - val_loss: 0.2865 - val_acc: 0.9548\nEpoch 92/1000\n - 1s - loss: 0.2812 - acc: 0.9586 - val_loss: 0.2991 - val_acc: 0.9563\nEpoch 93/1000\n - 1s - loss: 0.2792 - acc: 0.9612 - val_loss: 0.2753 - val_acc: 0.9668\nEpoch 94/1000\n - 1s - loss: 0.2747 - acc: 0.9593 - val_loss: 0.2768 - val_acc: 0.9683\nEpoch 95/1000\n - 1s - loss: 0.2729 - acc: 0.9612 - val_loss: 0.2771 - val_acc: 0.9638\n","name":"stdout"},{"output_type":"stream","text":"Epoch 96/1000\n - 1s - loss: 0.2765 - acc: 0.9631 - val_loss: 0.2849 - val_acc: 0.9623\nEpoch 97/1000\n - 1s - loss: 0.2769 - acc: 0.9631 - val_loss: 0.3079 - val_acc: 0.9472\nEpoch 98/1000\n - 1s - loss: 0.2633 - acc: 0.9657 - val_loss: 0.3080 - val_acc: 0.9502\nEpoch 99/1000\n - 1s - loss: 0.2661 - acc: 0.9639 - val_loss: 0.2845 - val_acc: 0.9578\nEpoch 100/1000\n - 1s - loss: 0.2709 - acc: 0.9601 - val_loss: 0.2853 - val_acc: 0.9623\nEpoch 101/1000\n - 1s - loss: 0.2687 - acc: 0.9642 - val_loss: 0.2943 - val_acc: 0.9578\nEpoch 102/1000\n - 1s - loss: 0.2591 - acc: 0.9676 - val_loss: 0.2884 - val_acc: 0.9608\nEpoch 103/1000\n - 1s - loss: 0.2732 - acc: 0.9605 - val_loss: 0.2836 - val_acc: 0.9623\nEpoch 104/1000\n - 1s - loss: 0.2745 - acc: 0.9590 - val_loss: 0.2871 - val_acc: 0.9623\nEpoch 105/1000\n - 1s - loss: 0.2792 - acc: 0.9605 - val_loss: 0.2800 - val_acc: 0.9623\nEpoch 106/1000\n - 1s - loss: 0.2721 - acc: 0.9605 - val_loss: 0.2807 - val_acc: 0.9623\nEpoch 107/1000\n - 1s - loss: 0.2687 - acc: 0.9601 - val_loss: 0.2790 - val_acc: 0.9638\nEpoch 108/1000\n - 1s - loss: 0.2720 - acc: 0.9590 - val_loss: 0.2903 - val_acc: 0.9623\nEpoch 109/1000\n - 1s - loss: 0.2609 - acc: 0.9672 - val_loss: 0.2708 - val_acc: 0.9683\nEpoch 110/1000\n - 1s - loss: 0.2526 - acc: 0.9676 - val_loss: 0.3078 - val_acc: 0.9608\nEpoch 111/1000\n - 1s - loss: 0.2555 - acc: 0.9665 - val_loss: 0.2963 - val_acc: 0.9668\nEpoch 112/1000\n - 1s - loss: 0.2621 - acc: 0.9631 - val_loss: 0.2857 - val_acc: 0.9623\nEpoch 113/1000\n - 1s - loss: 0.2496 - acc: 0.9688 - val_loss: 0.3096 - val_acc: 0.9532\nEpoch 114/1000\n - 1s - loss: 0.2598 - acc: 0.9639 - val_loss: 0.2989 - val_acc: 0.9517\nEpoch 115/1000\n - 1s - loss: 0.2489 - acc: 0.9676 - val_loss: 0.3049 - val_acc: 0.9472\nEpoch 116/1000\n - 1s - loss: 0.2671 - acc: 0.9635 - val_loss: 0.3050 - val_acc: 0.9532\nEpoch 117/1000\n - 1s - loss: 0.2515 - acc: 0.9684 - val_loss: 0.2997 - val_acc: 0.9532\nEpoch 118/1000\n - 1s - loss: 0.2510 - acc: 0.9635 - val_loss: 0.2974 - val_acc: 0.9638\nEpoch 119/1000\n - 1s - loss: 0.2558 - acc: 0.9639 - val_loss: 0.3287 - val_acc: 0.9517\nEpoch 120/1000\n - 1s - loss: 0.2654 - acc: 0.9627 - val_loss: 0.2928 - val_acc: 0.9608\nEpoch 121/1000\n - 1s - loss: 0.2512 - acc: 0.9680 - val_loss: 0.2912 - val_acc: 0.9517\nEpoch 122/1000\n - 1s - loss: 0.2537 - acc: 0.9672 - val_loss: 0.2893 - val_acc: 0.9578\nEpoch 123/1000\n - 1s - loss: 0.2501 - acc: 0.9672 - val_loss: 0.2980 - val_acc: 0.9532\nEpoch 124/1000\n - 1s - loss: 0.2425 - acc: 0.9691 - val_loss: 0.3086 - val_acc: 0.9532\nEpoch 125/1000\n - 1s - loss: 0.2544 - acc: 0.9635 - val_loss: 0.3046 - val_acc: 0.9638\nEpoch 126/1000\n - 1s - loss: 0.2515 - acc: 0.9654 - val_loss: 0.2827 - val_acc: 0.9653\nEpoch 127/1000\n - 1s - loss: 0.2486 - acc: 0.9676 - val_loss: 0.3271 - val_acc: 0.9382\nEpoch 128/1000\n - 1s - loss: 0.2445 - acc: 0.9684 - val_loss: 0.3263 - val_acc: 0.9563\nEpoch 129/1000\n - 1s - loss: 0.2426 - acc: 0.9695 - val_loss: 0.3239 - val_acc: 0.9412\nEpoch 130/1000\n - 1s - loss: 0.2362 - acc: 0.9710 - val_loss: 0.3009 - val_acc: 0.9578\nEpoch 131/1000\n - 1s - loss: 0.2493 - acc: 0.9642 - val_loss: 0.3327 - val_acc: 0.9517\nEpoch 132/1000\n - 1s - loss: 0.2299 - acc: 0.9710 - val_loss: 0.3015 - val_acc: 0.9502\nEpoch 133/1000\n - 1s - loss: 0.2360 - acc: 0.9721 - val_loss: 0.3008 - val_acc: 0.9548\nEpoch 134/1000\n - 1s - loss: 0.2473 - acc: 0.9665 - val_loss: 0.2969 - val_acc: 0.9608\nEpoch 135/1000\n - 1s - loss: 0.2368 - acc: 0.9733 - val_loss: 0.2892 - val_acc: 0.9638\nEpoch 136/1000\n - 1s - loss: 0.2377 - acc: 0.9714 - val_loss: 0.4148 - val_acc: 0.9125\nEpoch 137/1000\n - 1s - loss: 0.2318 - acc: 0.9740 - val_loss: 0.3256 - val_acc: 0.9457\nEpoch 138/1000\n - 1s - loss: 0.2514 - acc: 0.9680 - val_loss: 0.2951 - val_acc: 0.9563\nEpoch 139/1000\n - 1s - loss: 0.2354 - acc: 0.9695 - val_loss: 0.2951 - val_acc: 0.9517\nEpoch 140/1000\n - 1s - loss: 0.2360 - acc: 0.9718 - val_loss: 0.2930 - val_acc: 0.9593\nEpoch 141/1000\n - 1s - loss: 0.2425 - acc: 0.9703 - val_loss: 0.3095 - val_acc: 0.9593\nEpoch 142/1000\n - 1s - loss: 0.2387 - acc: 0.9699 - val_loss: 0.3108 - val_acc: 0.9532\nEpoch 143/1000\n - 1s - loss: 0.2262 - acc: 0.9755 - val_loss: 0.3057 - val_acc: 0.9593\nEpoch 144/1000\n - 1s - loss: 0.2273 - acc: 0.9752 - val_loss: 0.3071 - val_acc: 0.9608\nEpoch 145/1000\n - 1s - loss: 0.2418 - acc: 0.9695 - val_loss: 0.3198 - val_acc: 0.9487\nEpoch 146/1000\n - 1s - loss: 0.2290 - acc: 0.9725 - val_loss: 0.3363 - val_acc: 0.9442\nEpoch 147/1000\n - 1s - loss: 0.2330 - acc: 0.9736 - val_loss: 0.3476 - val_acc: 0.9502\nEpoch 148/1000\n - 1s - loss: 0.2303 - acc: 0.9725 - val_loss: 0.2959 - val_acc: 0.9532\nEpoch 149/1000\n - 1s - loss: 0.2321 - acc: 0.9740 - val_loss: 0.3087 - val_acc: 0.9502\nEpoch 150/1000\n - 1s - loss: 0.2285 - acc: 0.9744 - val_loss: 0.3092 - val_acc: 0.9548\nEpoch 151/1000\n - 1s - loss: 0.2327 - acc: 0.9703 - val_loss: 0.3732 - val_acc: 0.9170\nEpoch 152/1000\n - 1s - loss: 0.2324 - acc: 0.9725 - val_loss: 0.3187 - val_acc: 0.9487\nEpoch 153/1000\n - 1s - loss: 0.2173 - acc: 0.9774 - val_loss: 0.3161 - val_acc: 0.9532\nEpoch 154/1000\n - 1s - loss: 0.2310 - acc: 0.9729 - val_loss: 0.3279 - val_acc: 0.9457\nEpoch 155/1000\n - 1s - loss: 0.2349 - acc: 0.9703 - val_loss: 0.3217 - val_acc: 0.9563\nEpoch 156/1000\n - 1s - loss: 0.2260 - acc: 0.9759 - val_loss: 0.3073 - val_acc: 0.9593\nEpoch 157/1000\n - 1s - loss: 0.2282 - acc: 0.9699 - val_loss: 0.2989 - val_acc: 0.9548\nEpoch 158/1000\n - 1s - loss: 0.2196 - acc: 0.9755 - val_loss: 0.3267 - val_acc: 0.9427\nEpoch 159/1000\n - 1s - loss: 0.2336 - acc: 0.9710 - val_loss: 0.3113 - val_acc: 0.9593\nEpoch 160/1000\n - 1s - loss: 0.2319 - acc: 0.9710 - val_loss: 0.3162 - val_acc: 0.9593\nEpoch 161/1000\n - 1s - loss: 0.2190 - acc: 0.9740 - val_loss: 0.3809 - val_acc: 0.9291\nEpoch 162/1000\n - 1s - loss: 0.2309 - acc: 0.9729 - val_loss: 0.3199 - val_acc: 0.9548\nEpoch 163/1000\n - 1s - loss: 0.2250 - acc: 0.9729 - val_loss: 0.4472 - val_acc: 0.9306\nEpoch 164/1000\n - 1s - loss: 0.2153 - acc: 0.9752 - val_loss: 0.3222 - val_acc: 0.9608\nEpoch 165/1000\n - 1s - loss: 0.2188 - acc: 0.9755 - val_loss: 0.3061 - val_acc: 0.9608\nEpoch 166/1000\n - 1s - loss: 0.2354 - acc: 0.9718 - val_loss: 0.3168 - val_acc: 0.9563\nEpoch 167/1000\n - 1s - loss: 0.2209 - acc: 0.9759 - val_loss: 0.3404 - val_acc: 0.9487\nEpoch 168/1000\n - 1s - loss: 0.2124 - acc: 0.9804 - val_loss: 0.3158 - val_acc: 0.9563\nEpoch 169/1000\n - 1s - loss: 0.2197 - acc: 0.9767 - val_loss: 0.3738 - val_acc: 0.9276\nEpoch 170/1000\n - 1s - loss: 0.2165 - acc: 0.9755 - val_loss: 0.3817 - val_acc: 0.9457\nEpoch 171/1000\n - 1s - loss: 0.2185 - acc: 0.9759 - val_loss: 0.3405 - val_acc: 0.9502\nEpoch 172/1000\n - 1s - loss: 0.2199 - acc: 0.9789 - val_loss: 0.3256 - val_acc: 0.9578\nEpoch 173/1000\n - 1s - loss: 0.2216 - acc: 0.9752 - val_loss: 0.3098 - val_acc: 0.9532\nEpoch 174/1000\n - 1s - loss: 0.2187 - acc: 0.9759 - val_loss: 0.3041 - val_acc: 0.9593\nEpoch 175/1000\n - 1s - loss: 0.2023 - acc: 0.9816 - val_loss: 0.3186 - val_acc: 0.9517\nEpoch 176/1000\n - 1s - loss: 0.2133 - acc: 0.9744 - val_loss: 0.3273 - val_acc: 0.9563\nEpoch 177/1000\n - 1s - loss: 0.2183 - acc: 0.9748 - val_loss: 0.3198 - val_acc: 0.9532\nEpoch 178/1000\n - 1s - loss: 0.2173 - acc: 0.9744 - val_loss: 0.3345 - val_acc: 0.9517\nEpoch 179/1000\n - 1s - loss: 0.2068 - acc: 0.9819 - val_loss: 0.3924 - val_acc: 0.9412\nEpoch 180/1000\n - 1s - loss: 0.2123 - acc: 0.9793 - val_loss: 0.3252 - val_acc: 0.9517\nEpoch 181/1000\n - 1s - loss: 0.2056 - acc: 0.9819 - val_loss: 0.3448 - val_acc: 0.9548\nEpoch 182/1000\n - 1s - loss: 0.2206 - acc: 0.9744 - val_loss: 0.3464 - val_acc: 0.9548\nEpoch 183/1000\n - 1s - loss: 0.2037 - acc: 0.9800 - val_loss: 0.3088 - val_acc: 0.9578\nEpoch 184/1000\n - 1s - loss: 0.2058 - acc: 0.9804 - val_loss: 0.3300 - val_acc: 0.9548\nEpoch 185/1000\n - 1s - loss: 0.2088 - acc: 0.9812 - val_loss: 0.3713 - val_acc: 0.9427\nEpoch 186/1000\n - 1s - loss: 0.2053 - acc: 0.9793 - val_loss: 0.3188 - val_acc: 0.9563\nEpoch 187/1000\n - 1s - loss: 0.2154 - acc: 0.9767 - val_loss: 0.3314 - val_acc: 0.9578\nEpoch 188/1000\n - 1s - loss: 0.2082 - acc: 0.9804 - val_loss: 0.3344 - val_acc: 0.9563\nEpoch 189/1000\n - 1s - loss: 0.2061 - acc: 0.9785 - val_loss: 0.3148 - val_acc: 0.9548\nEpoch 190/1000\n - 1s - loss: 0.2190 - acc: 0.9759 - val_loss: 0.3213 - val_acc: 0.9502\n","name":"stdout"},{"output_type":"stream","text":"Epoch 191/1000\n - 1s - loss: 0.2059 - acc: 0.9797 - val_loss: 0.3424 - val_acc: 0.9532\nEpoch 192/1000\n - 1s - loss: 0.2065 - acc: 0.9819 - val_loss: 0.3528 - val_acc: 0.9367\nEpoch 193/1000\n - 1s - loss: 0.2176 - acc: 0.9759 - val_loss: 0.3684 - val_acc: 0.9397\nEpoch 194/1000\n - 1s - loss: 0.2107 - acc: 0.9789 - val_loss: 0.3282 - val_acc: 0.9532\nEpoch 195/1000\n - 1s - loss: 0.2081 - acc: 0.9816 - val_loss: 0.3295 - val_acc: 0.9532\nEpoch 196/1000\n - 1s - loss: 0.2017 - acc: 0.9789 - val_loss: 0.3475 - val_acc: 0.9502\nEpoch 197/1000\n - 1s - loss: 0.1965 - acc: 0.9823 - val_loss: 0.3694 - val_acc: 0.9548\nEpoch 198/1000\n - 1s - loss: 0.2076 - acc: 0.9804 - val_loss: 0.3261 - val_acc: 0.9532\nEpoch 199/1000\n - 1s - loss: 0.2201 - acc: 0.9789 - val_loss: 0.3294 - val_acc: 0.9563\nEpoch 200/1000\n - 1s - loss: 0.2030 - acc: 0.9800 - val_loss: 0.3432 - val_acc: 0.9397\nEpoch 201/1000\n - 1s - loss: 0.1975 - acc: 0.9834 - val_loss: 0.3723 - val_acc: 0.9502\nEpoch 202/1000\n - 1s - loss: 0.2030 - acc: 0.9808 - val_loss: 0.3427 - val_acc: 0.9517\nEpoch 203/1000\n - 1s - loss: 0.2072 - acc: 0.9812 - val_loss: 0.3482 - val_acc: 0.9457\nEpoch 204/1000\n - 1s - loss: 0.2097 - acc: 0.9800 - val_loss: 0.3342 - val_acc: 0.9487\nEpoch 205/1000\n - 1s - loss: 0.1953 - acc: 0.9846 - val_loss: 0.3700 - val_acc: 0.9397\nEpoch 206/1000\n - 1s - loss: 0.1966 - acc: 0.9808 - val_loss: 0.3594 - val_acc: 0.9306\nEpoch 207/1000\n - 1s - loss: 0.2029 - acc: 0.9827 - val_loss: 0.3377 - val_acc: 0.9593\nEpoch 208/1000\n - 1s - loss: 0.1932 - acc: 0.9849 - val_loss: 0.4088 - val_acc: 0.9427\nEpoch 209/1000\n - 1s - loss: 0.2081 - acc: 0.9782 - val_loss: 0.3499 - val_acc: 0.9563\nEpoch 210/1000\n - 1s - loss: 0.1975 - acc: 0.9793 - val_loss: 0.3684 - val_acc: 0.9397\nEpoch 211/1000\n - 1s - loss: 0.2107 - acc: 0.9782 - val_loss: 0.3511 - val_acc: 0.9351\nEpoch 212/1000\n - 1s - loss: 0.1893 - acc: 0.9853 - val_loss: 0.3845 - val_acc: 0.9457\nEpoch 213/1000\n - 1s - loss: 0.2019 - acc: 0.9808 - val_loss: 0.3746 - val_acc: 0.9472\nEpoch 214/1000\n - 1s - loss: 0.1987 - acc: 0.9827 - val_loss: 0.4288 - val_acc: 0.9412\nEpoch 215/1000\n - 1s - loss: 0.2085 - acc: 0.9804 - val_loss: 0.3384 - val_acc: 0.9472\nEpoch 216/1000\n - 1s - loss: 0.2105 - acc: 0.9812 - val_loss: 0.3458 - val_acc: 0.9457\nEpoch 217/1000\n - 1s - loss: 0.1869 - acc: 0.9861 - val_loss: 0.3470 - val_acc: 0.9532\nEpoch 218/1000\n - 1s - loss: 0.1873 - acc: 0.9861 - val_loss: 0.3409 - val_acc: 0.9472\nEpoch 219/1000\n - 1s - loss: 0.1996 - acc: 0.9812 - val_loss: 0.3452 - val_acc: 0.9487\nEpoch 220/1000\n - 1s - loss: 0.1988 - acc: 0.9823 - val_loss: 0.3691 - val_acc: 0.9532\nEpoch 221/1000\n - 1s - loss: 0.1858 - acc: 0.9872 - val_loss: 0.3565 - val_acc: 0.9457\nEpoch 222/1000\n - 1s - loss: 0.1981 - acc: 0.9804 - val_loss: 0.3641 - val_acc: 0.9502\nEpoch 223/1000\n - 1s - loss: 0.1826 - acc: 0.9872 - val_loss: 0.3393 - val_acc: 0.9532\nEpoch 224/1000\n - 1s - loss: 0.1831 - acc: 0.9872 - val_loss: 0.3294 - val_acc: 0.9487\nEpoch 225/1000\n - 1s - loss: 0.1880 - acc: 0.9861 - val_loss: 0.3580 - val_acc: 0.9563\nEpoch 226/1000\n - 1s - loss: 0.2024 - acc: 0.9812 - val_loss: 0.3560 - val_acc: 0.9427\nEpoch 227/1000\n - 1s - loss: 0.1911 - acc: 0.9831 - val_loss: 0.3534 - val_acc: 0.9457\nEpoch 228/1000\n - 1s - loss: 0.1868 - acc: 0.9834 - val_loss: 0.3676 - val_acc: 0.9472\nEpoch 229/1000\n - 1s - loss: 0.1896 - acc: 0.9846 - val_loss: 0.3877 - val_acc: 0.9472\nEpoch 230/1000\n - 1s - loss: 0.1841 - acc: 0.9853 - val_loss: 0.3459 - val_acc: 0.9442\nEpoch 231/1000\n - 1s - loss: 0.1890 - acc: 0.9861 - val_loss: 0.3532 - val_acc: 0.9442\nEpoch 232/1000\n - 1s - loss: 0.1845 - acc: 0.9846 - val_loss: 0.4136 - val_acc: 0.9397\nEpoch 233/1000\n - 1s - loss: 0.1852 - acc: 0.9880 - val_loss: 0.3754 - val_acc: 0.9427\nEpoch 234/1000\n - 1s - loss: 0.2004 - acc: 0.9831 - val_loss: 0.3510 - val_acc: 0.9532\nEpoch 235/1000\n - 1s - loss: 0.1796 - acc: 0.9876 - val_loss: 0.4408 - val_acc: 0.9231\nEpoch 236/1000\n - 1s - loss: 0.2001 - acc: 0.9812 - val_loss: 0.3428 - val_acc: 0.9502\nEpoch 237/1000\n - 1s - loss: 0.1967 - acc: 0.9804 - val_loss: 0.3932 - val_acc: 0.9457\nEpoch 238/1000\n - 1s - loss: 0.1901 - acc: 0.9872 - val_loss: 0.3690 - val_acc: 0.9517\nEpoch 239/1000\n - 1s - loss: 0.1839 - acc: 0.9887 - val_loss: 0.3783 - val_acc: 0.9412\nEpoch 240/1000\n - 1s - loss: 0.1829 - acc: 0.9842 - val_loss: 0.4161 - val_acc: 0.9186\nEpoch 241/1000\n - 1s - loss: 0.1883 - acc: 0.9842 - val_loss: 0.3674 - val_acc: 0.9548\nEpoch 242/1000\n - 1s - loss: 0.1857 - acc: 0.9834 - val_loss: 0.3685 - val_acc: 0.9502\nEpoch 243/1000\n - 1s - loss: 0.1707 - acc: 0.9883 - val_loss: 0.3871 - val_acc: 0.9472\nEpoch 244/1000\n - 1s - loss: 0.1721 - acc: 0.9906 - val_loss: 0.4051 - val_acc: 0.9427\nEpoch 245/1000\n - 1s - loss: 0.1906 - acc: 0.9834 - val_loss: 0.3915 - val_acc: 0.9502\nEpoch 246/1000\n - 1s - loss: 0.1760 - acc: 0.9868 - val_loss: 0.3559 - val_acc: 0.9427\nEpoch 247/1000\n - 1s - loss: 0.1771 - acc: 0.9887 - val_loss: 0.3841 - val_acc: 0.9517\nEpoch 248/1000\n - 1s - loss: 0.1929 - acc: 0.9800 - val_loss: 0.4055 - val_acc: 0.9442\nEpoch 249/1000\n - 1s - loss: 0.1726 - acc: 0.9902 - val_loss: 0.3602 - val_acc: 0.9412\nEpoch 250/1000\n - 1s - loss: 0.1852 - acc: 0.9864 - val_loss: 0.3568 - val_acc: 0.9502\nEpoch 251/1000\n - 1s - loss: 0.2017 - acc: 0.9823 - val_loss: 0.3421 - val_acc: 0.9487\nEpoch 252/1000\n - 1s - loss: 0.1891 - acc: 0.9849 - val_loss: 0.3530 - val_acc: 0.9517\nEpoch 253/1000\n - 1s - loss: 0.1911 - acc: 0.9831 - val_loss: 0.3560 - val_acc: 0.9412\nEpoch 254/1000\n - 1s - loss: 0.1762 - acc: 0.9883 - val_loss: 0.3807 - val_acc: 0.9412\nEpoch 255/1000\n - 1s - loss: 0.1767 - acc: 0.9864 - val_loss: 0.3687 - val_acc: 0.9517\nEpoch 256/1000\n - 1s - loss: 0.1834 - acc: 0.9857 - val_loss: 0.3666 - val_acc: 0.9517\nEpoch 257/1000\n - 1s - loss: 0.1729 - acc: 0.9895 - val_loss: 0.3838 - val_acc: 0.9412\nEpoch 258/1000\n - 1s - loss: 0.1881 - acc: 0.9849 - val_loss: 0.3864 - val_acc: 0.9502\nEpoch 259/1000\n - 1s - loss: 0.1884 - acc: 0.9827 - val_loss: 0.3993 - val_acc: 0.9472\nEpoch 260/1000\n - 1s - loss: 0.1818 - acc: 0.9864 - val_loss: 0.3747 - val_acc: 0.9532\nEpoch 261/1000\n - 1s - loss: 0.1769 - acc: 0.9872 - val_loss: 0.4089 - val_acc: 0.9427\nEpoch 262/1000\n - 1s - loss: 0.1806 - acc: 0.9872 - val_loss: 0.3860 - val_acc: 0.9442\nEpoch 263/1000\n - 1s - loss: 0.1742 - acc: 0.9861 - val_loss: 0.4093 - val_acc: 0.9427\nEpoch 264/1000\n - 1s - loss: 0.1749 - acc: 0.9887 - val_loss: 0.4466 - val_acc: 0.9427\nEpoch 265/1000\n - 1s - loss: 0.1833 - acc: 0.9857 - val_loss: 0.4759 - val_acc: 0.9276\nEpoch 266/1000\n - 1s - loss: 0.1753 - acc: 0.9880 - val_loss: 0.3829 - val_acc: 0.9472\nEpoch 267/1000\n - 1s - loss: 0.1925 - acc: 0.9827 - val_loss: 0.3684 - val_acc: 0.9457\nEpoch 268/1000\n - 1s - loss: 0.1762 - acc: 0.9887 - val_loss: 0.3934 - val_acc: 0.9351\nEpoch 269/1000\n - 1s - loss: 0.1699 - acc: 0.9902 - val_loss: 0.3866 - val_acc: 0.9472\nEpoch 270/1000\n - 1s - loss: 0.1806 - acc: 0.9883 - val_loss: 0.3873 - val_acc: 0.9367\nEpoch 271/1000\n - 1s - loss: 0.1883 - acc: 0.9812 - val_loss: 0.3669 - val_acc: 0.9427\nEpoch 272/1000\n - 1s - loss: 0.1830 - acc: 0.9853 - val_loss: 0.3711 - val_acc: 0.9412\nEpoch 273/1000\n - 1s - loss: 0.1806 - acc: 0.9864 - val_loss: 0.4141 - val_acc: 0.9397\nEpoch 274/1000\n - 1s - loss: 0.1867 - acc: 0.9868 - val_loss: 0.3956 - val_acc: 0.9427\nEpoch 275/1000\n - 1s - loss: 0.1932 - acc: 0.9819 - val_loss: 0.4030 - val_acc: 0.9502\nEpoch 276/1000\n - 1s - loss: 0.1806 - acc: 0.9880 - val_loss: 0.3754 - val_acc: 0.9487\nEpoch 277/1000\n - 1s - loss: 0.1717 - acc: 0.9876 - val_loss: 0.3545 - val_acc: 0.9487\nEpoch 278/1000\n - 1s - loss: 0.1771 - acc: 0.9883 - val_loss: 0.3474 - val_acc: 0.9532\nEpoch 279/1000\n - 1s - loss: 0.1824 - acc: 0.9842 - val_loss: 0.3611 - val_acc: 0.9442\nEpoch 280/1000\n - 1s - loss: 0.1768 - acc: 0.9868 - val_loss: 0.3743 - val_acc: 0.9487\nEpoch 281/1000\n - 1s - loss: 0.1799 - acc: 0.9872 - val_loss: 0.3696 - val_acc: 0.9502\nEpoch 282/1000\n - 1s - loss: 0.1722 - acc: 0.9887 - val_loss: 0.3759 - val_acc: 0.9427\nEpoch 283/1000\n - 1s - loss: 0.1786 - acc: 0.9864 - val_loss: 0.4365 - val_acc: 0.9110\nEpoch 284/1000\n - 1s - loss: 0.1778 - acc: 0.9861 - val_loss: 0.4224 - val_acc: 0.9442\nEpoch 285/1000\n","name":"stdout"},{"output_type":"stream","text":" - 1s - loss: 0.1667 - acc: 0.9887 - val_loss: 0.3976 - val_acc: 0.9336\nEpoch 286/1000\n - 1s - loss: 0.1676 - acc: 0.9876 - val_loss: 0.3972 - val_acc: 0.9457\nEpoch 287/1000\n - 1s - loss: 0.1643 - acc: 0.9910 - val_loss: 0.4228 - val_acc: 0.9427\nEpoch 288/1000\n - 1s - loss: 0.1693 - acc: 0.9906 - val_loss: 0.3934 - val_acc: 0.9457\nEpoch 289/1000\n - 1s - loss: 0.1798 - acc: 0.9891 - val_loss: 0.4712 - val_acc: 0.9321\nEpoch 290/1000\n - 1s - loss: 0.1706 - acc: 0.9902 - val_loss: 0.3557 - val_acc: 0.9472\nEpoch 291/1000\n - 1s - loss: 0.1671 - acc: 0.9883 - val_loss: 0.3558 - val_acc: 0.9472\nEpoch 292/1000\n - 1s - loss: 0.1595 - acc: 0.9921 - val_loss: 0.3605 - val_acc: 0.9442\nEpoch 293/1000\n - 1s - loss: 0.1740 - acc: 0.9857 - val_loss: 0.4331 - val_acc: 0.9427\nEpoch 294/1000\n - 1s - loss: 0.1676 - acc: 0.9913 - val_loss: 0.4143 - val_acc: 0.9412\nEpoch 295/1000\n - 1s - loss: 0.1594 - acc: 0.9921 - val_loss: 0.4038 - val_acc: 0.9517\nEpoch 296/1000\n - 1s - loss: 0.1794 - acc: 0.9868 - val_loss: 0.3694 - val_acc: 0.9397\nEpoch 297/1000\n - 1s - loss: 0.1647 - acc: 0.9895 - val_loss: 0.3533 - val_acc: 0.9548\nEpoch 298/1000\n - 1s - loss: 0.1944 - acc: 0.9789 - val_loss: 0.3959 - val_acc: 0.9487\nEpoch 299/1000\n - 1s - loss: 0.1763 - acc: 0.9872 - val_loss: 0.3497 - val_acc: 0.9532\nEpoch 300/1000\n - 1s - loss: 0.1825 - acc: 0.9861 - val_loss: 0.3609 - val_acc: 0.9517\nEpoch 301/1000\n - 1s - loss: 0.1601 - acc: 0.9932 - val_loss: 0.4242 - val_acc: 0.9276\nEpoch 302/1000\n - 1s - loss: 0.1767 - acc: 0.9864 - val_loss: 0.4180 - val_acc: 0.9427\nEpoch 303/1000\n - 1s - loss: 0.1659 - acc: 0.9891 - val_loss: 0.3850 - val_acc: 0.9472\nEpoch 304/1000\n - 1s - loss: 0.1673 - acc: 0.9887 - val_loss: 0.3890 - val_acc: 0.9532\nEpoch 305/1000\n - 1s - loss: 0.1870 - acc: 0.9849 - val_loss: 0.3809 - val_acc: 0.9336\nEpoch 306/1000\n - 1s - loss: 0.1888 - acc: 0.9793 - val_loss: 0.3833 - val_acc: 0.9457\nEpoch 307/1000\n - 1s - loss: 0.1623 - acc: 0.9910 - val_loss: 0.4493 - val_acc: 0.9321\nEpoch 308/1000\n - 1s - loss: 0.1825 - acc: 0.9853 - val_loss: 0.3857 - val_acc: 0.9457\nEpoch 309/1000\n - 1s - loss: 0.1748 - acc: 0.9880 - val_loss: 0.3690 - val_acc: 0.9457\nEpoch 310/1000\n - 1s - loss: 0.1742 - acc: 0.9876 - val_loss: 0.3708 - val_acc: 0.9487\nEpoch 311/1000\n - 1s - loss: 0.1838 - acc: 0.9853 - val_loss: 0.3918 - val_acc: 0.9517\nEpoch 312/1000\n - 1s - loss: 0.1673 - acc: 0.9898 - val_loss: 0.3948 - val_acc: 0.9487\nEpoch 313/1000\n - 1s - loss: 0.1635 - acc: 0.9917 - val_loss: 0.4576 - val_acc: 0.9457\nEpoch 314/1000\n - 1s - loss: 0.1749 - acc: 0.9887 - val_loss: 0.3874 - val_acc: 0.9442\nEpoch 315/1000\n - 1s - loss: 0.1736 - acc: 0.9876 - val_loss: 0.3981 - val_acc: 0.9457\nEpoch 316/1000\n - 1s - loss: 0.1610 - acc: 0.9902 - val_loss: 0.3653 - val_acc: 0.9412\nEpoch 317/1000\n - 1s - loss: 0.1642 - acc: 0.9910 - val_loss: 0.3648 - val_acc: 0.9397\nEpoch 318/1000\n - 1s - loss: 0.1690 - acc: 0.9868 - val_loss: 0.3942 - val_acc: 0.9442\nEpoch 319/1000\n - 1s - loss: 0.1635 - acc: 0.9895 - val_loss: 0.4125 - val_acc: 0.9382\nEpoch 320/1000\n - 1s - loss: 0.1744 - acc: 0.9883 - val_loss: 0.3805 - val_acc: 0.9321\nEpoch 321/1000\n - 1s - loss: 0.1787 - acc: 0.9868 - val_loss: 0.4041 - val_acc: 0.9397\nEpoch 322/1000\n - 1s - loss: 0.1566 - acc: 0.9921 - val_loss: 0.3742 - val_acc: 0.9442\nEpoch 323/1000\n - 1s - loss: 0.1598 - acc: 0.9883 - val_loss: 0.3815 - val_acc: 0.9336\nEpoch 324/1000\n - 1s - loss: 0.1762 - acc: 0.9864 - val_loss: 0.3817 - val_acc: 0.9306\nEpoch 325/1000\n - 1s - loss: 0.1781 - acc: 0.9868 - val_loss: 0.3571 - val_acc: 0.9397\nEpoch 326/1000\n - 1s - loss: 0.1858 - acc: 0.9853 - val_loss: 0.3756 - val_acc: 0.9412\nEpoch 327/1000\n - 1s - loss: 0.1680 - acc: 0.9887 - val_loss: 0.3674 - val_acc: 0.9457\nEpoch 328/1000\n - 1s - loss: 0.1732 - acc: 0.9861 - val_loss: 0.3797 - val_acc: 0.9442\nEpoch 329/1000\n - 1s - loss: 0.1834 - acc: 0.9846 - val_loss: 0.4516 - val_acc: 0.9261\nEpoch 330/1000\n - 1s - loss: 0.1726 - acc: 0.9887 - val_loss: 0.3847 - val_acc: 0.9397\nEpoch 331/1000\n - 1s - loss: 0.1598 - acc: 0.9910 - val_loss: 0.3942 - val_acc: 0.9412\nEpoch 332/1000\n - 1s - loss: 0.1726 - acc: 0.9898 - val_loss: 0.3814 - val_acc: 0.9412\nEpoch 333/1000\n - 1s - loss: 0.1634 - acc: 0.9898 - val_loss: 0.3721 - val_acc: 0.9487\nEpoch 334/1000\n - 1s - loss: 0.1658 - acc: 0.9895 - val_loss: 0.3759 - val_acc: 0.9367\nEpoch 335/1000\n - 1s - loss: 0.1687 - acc: 0.9868 - val_loss: 0.3852 - val_acc: 0.9442\nEpoch 336/1000\n - 1s - loss: 0.1652 - acc: 0.9880 - val_loss: 0.4679 - val_acc: 0.9412\nEpoch 337/1000\n - 1s - loss: 0.1721 - acc: 0.9872 - val_loss: 0.3818 - val_acc: 0.9457\nEpoch 338/1000\n - 1s - loss: 0.1643 - acc: 0.9895 - val_loss: 0.3624 - val_acc: 0.9487\nEpoch 339/1000\n - 1s - loss: 0.1637 - acc: 0.9883 - val_loss: 0.3762 - val_acc: 0.9487\nEpoch 340/1000\n - 1s - loss: 0.1618 - acc: 0.9913 - val_loss: 0.3808 - val_acc: 0.9397\nEpoch 341/1000\n - 1s - loss: 0.1506 - acc: 0.9925 - val_loss: 0.3893 - val_acc: 0.9457\nEpoch 342/1000\n - 1s - loss: 0.1534 - acc: 0.9906 - val_loss: 0.3828 - val_acc: 0.9412\nEpoch 343/1000\n - 1s - loss: 0.1573 - acc: 0.9906 - val_loss: 0.4143 - val_acc: 0.9472\nEpoch 344/1000\n - 1s - loss: 0.1663 - acc: 0.9898 - val_loss: 0.3591 - val_acc: 0.9442\nEpoch 345/1000\n - 1s - loss: 0.1678 - acc: 0.9872 - val_loss: 0.3525 - val_acc: 0.9487\nEpoch 346/1000\n - 1s - loss: 0.1509 - acc: 0.9921 - val_loss: 0.3701 - val_acc: 0.9442\nEpoch 347/1000\n - 1s - loss: 0.1590 - acc: 0.9902 - val_loss: 0.3739 - val_acc: 0.9427\nEpoch 348/1000\n - 1s - loss: 0.1485 - acc: 0.9917 - val_loss: 0.3583 - val_acc: 0.9427\nEpoch 349/1000\n - 1s - loss: 0.1607 - acc: 0.9898 - val_loss: 0.3728 - val_acc: 0.9487\nEpoch 350/1000\n - 1s - loss: 0.1524 - acc: 0.9925 - val_loss: 0.4060 - val_acc: 0.9442\nEpoch 351/1000\n - 1s - loss: 0.1756 - acc: 0.9842 - val_loss: 0.4710 - val_acc: 0.9306\nEpoch 352/1000\n - 1s - loss: 0.1607 - acc: 0.9906 - val_loss: 0.3870 - val_acc: 0.9382\nEpoch 353/1000\n - 1s - loss: 0.1613 - acc: 0.9868 - val_loss: 0.3701 - val_acc: 0.9457\nEpoch 354/1000\n - 1s - loss: 0.1703 - acc: 0.9876 - val_loss: 0.3798 - val_acc: 0.9442\nEpoch 355/1000\n - 1s - loss: 0.1565 - acc: 0.9895 - val_loss: 0.6192 - val_acc: 0.9095\nEpoch 356/1000\n - 1s - loss: 0.1685 - acc: 0.9880 - val_loss: 0.4004 - val_acc: 0.9487\nEpoch 357/1000\n - 1s - loss: 0.1579 - acc: 0.9891 - val_loss: 0.4116 - val_acc: 0.9472\nEpoch 358/1000\n - 1s - loss: 0.1630 - acc: 0.9895 - val_loss: 0.3709 - val_acc: 0.9397\nEpoch 359/1000\n - 1s - loss: 0.1638 - acc: 0.9887 - val_loss: 0.4453 - val_acc: 0.9367\nEpoch 360/1000\n - 1s - loss: 0.1649 - acc: 0.9895 - val_loss: 0.3623 - val_acc: 0.9457\nEpoch 361/1000\n - 1s - loss: 0.1439 - acc: 0.9932 - val_loss: 0.3722 - val_acc: 0.9412\nEpoch 362/1000\n - 1s - loss: 0.1478 - acc: 0.9921 - val_loss: 0.3522 - val_acc: 0.9487\nEpoch 363/1000\n - 1s - loss: 0.1480 - acc: 0.9917 - val_loss: 0.3898 - val_acc: 0.9472\nEpoch 364/1000\n - 1s - loss: 0.1498 - acc: 0.9910 - val_loss: 0.3567 - val_acc: 0.9502\nEpoch 365/1000\n - 1s - loss: 0.1520 - acc: 0.9925 - val_loss: 0.3856 - val_acc: 0.9457\nEpoch 366/1000\n - 1s - loss: 0.1457 - acc: 0.9940 - val_loss: 0.3744 - val_acc: 0.9472\nEpoch 367/1000\n - 1s - loss: 0.1543 - acc: 0.9895 - val_loss: 0.3843 - val_acc: 0.9532\nEpoch 368/1000\n - 1s - loss: 0.1548 - acc: 0.9910 - val_loss: 0.3737 - val_acc: 0.9412\nEpoch 369/1000\n - 1s - loss: 0.1611 - acc: 0.9883 - val_loss: 0.3647 - val_acc: 0.9487\nEpoch 370/1000\n - 1s - loss: 0.1632 - acc: 0.9868 - val_loss: 0.3801 - val_acc: 0.9427\nEpoch 371/1000\n - 1s - loss: 0.1596 - acc: 0.9880 - val_loss: 0.4004 - val_acc: 0.9442\nEpoch 372/1000\n - 1s - loss: 0.1622 - acc: 0.9898 - val_loss: 0.3802 - val_acc: 0.9397\nEpoch 373/1000\n - 1s - loss: 0.1673 - acc: 0.9868 - val_loss: 0.4086 - val_acc: 0.9487\nEpoch 374/1000\n - 1s - loss: 0.1554 - acc: 0.9921 - val_loss: 0.3610 - val_acc: 0.9502\nEpoch 375/1000\n - 1s - loss: 0.1498 - acc: 0.9917 - val_loss: 0.3794 - val_acc: 0.9351\nEpoch 376/1000\n - 1s - loss: 0.1492 - acc: 0.9940 - val_loss: 0.3776 - val_acc: 0.9397\nEpoch 377/1000\n - 1s - loss: 0.1754 - acc: 0.9864 - val_loss: 0.3849 - val_acc: 0.9457\nEpoch 378/1000\n - 1s - loss: 0.1683 - acc: 0.9876 - val_loss: 0.3774 - val_acc: 0.9517\nEpoch 379/1000\n - 1s - loss: 0.1639 - acc: 0.9895 - val_loss: 0.3421 - val_acc: 0.9502\n","name":"stdout"},{"output_type":"stream","text":"Epoch 380/1000\n - 1s - loss: 0.1431 - acc: 0.9936 - val_loss: 0.4081 - val_acc: 0.9382\nEpoch 381/1000\n - 1s - loss: 0.1498 - acc: 0.9906 - val_loss: 0.3817 - val_acc: 0.9487\nEpoch 382/1000\n - 1s - loss: 0.1518 - acc: 0.9913 - val_loss: 0.3701 - val_acc: 0.9457\nEpoch 383/1000\n - 1s - loss: 0.1536 - acc: 0.9917 - val_loss: 0.3682 - val_acc: 0.9442\nEpoch 384/1000\n - 1s - loss: 0.1516 - acc: 0.9921 - val_loss: 0.3611 - val_acc: 0.9442\nEpoch 385/1000\n - 1s - loss: 0.1379 - acc: 0.9962 - val_loss: 0.4083 - val_acc: 0.9442\nEpoch 386/1000\n - 1s - loss: 0.1775 - acc: 0.9861 - val_loss: 0.3922 - val_acc: 0.9487\nEpoch 387/1000\n - 1s - loss: 0.1545 - acc: 0.9895 - val_loss: 0.4297 - val_acc: 0.9367\nEpoch 388/1000\n - 1s - loss: 0.1517 - acc: 0.9913 - val_loss: 0.4198 - val_acc: 0.9412\nEpoch 389/1000\n - 1s - loss: 0.1520 - acc: 0.9925 - val_loss: 0.4014 - val_acc: 0.9427\nEpoch 390/1000\n - 1s - loss: 0.1600 - acc: 0.9887 - val_loss: 0.4097 - val_acc: 0.9321\nEpoch 391/1000\n - 1s - loss: 0.1555 - acc: 0.9895 - val_loss: 0.3917 - val_acc: 0.9442\nEpoch 392/1000\n - 1s - loss: 0.1567 - acc: 0.9910 - val_loss: 0.3725 - val_acc: 0.9457\nEpoch 393/1000\n - 1s - loss: 0.1522 - acc: 0.9902 - val_loss: 0.3832 - val_acc: 0.9472\nEpoch 394/1000\n - 1s - loss: 0.1489 - acc: 0.9932 - val_loss: 0.3761 - val_acc: 0.9457\nEpoch 395/1000\n - 1s - loss: 0.1461 - acc: 0.9906 - val_loss: 0.3837 - val_acc: 0.9427\nEpoch 396/1000\n - 1s - loss: 0.1558 - acc: 0.9902 - val_loss: 0.4425 - val_acc: 0.9442\nEpoch 397/1000\n - 1s - loss: 0.1539 - acc: 0.9895 - val_loss: 0.3861 - val_acc: 0.9487\nEpoch 398/1000\n - 1s - loss: 0.1573 - acc: 0.9906 - val_loss: 0.3809 - val_acc: 0.9412\nEpoch 399/1000\n - 1s - loss: 0.1597 - acc: 0.9891 - val_loss: 0.3719 - val_acc: 0.9472\nEpoch 400/1000\n - 1s - loss: 0.1497 - acc: 0.9925 - val_loss: 0.3873 - val_acc: 0.9472\nEpoch 401/1000\n - 1s - loss: 0.1447 - acc: 0.9913 - val_loss: 0.3522 - val_acc: 0.9442\nEpoch 402/1000\n - 1s - loss: 0.1554 - acc: 0.9917 - val_loss: 0.4417 - val_acc: 0.9442\nEpoch 403/1000\n - 1s - loss: 0.1422 - acc: 0.9955 - val_loss: 0.3587 - val_acc: 0.9487\nEpoch 404/1000\n - 1s - loss: 0.1546 - acc: 0.9898 - val_loss: 0.4012 - val_acc: 0.9548\nEpoch 405/1000\n - 1s - loss: 0.1462 - acc: 0.9921 - val_loss: 0.3964 - val_acc: 0.9502\nEpoch 406/1000\n - 1s - loss: 0.1637 - acc: 0.9864 - val_loss: 0.4029 - val_acc: 0.9427\nEpoch 407/1000\n - 1s - loss: 0.1438 - acc: 0.9936 - val_loss: 0.3797 - val_acc: 0.9442\nEpoch 408/1000\n - 1s - loss: 0.1573 - acc: 0.9887 - val_loss: 0.4124 - val_acc: 0.9502\nEpoch 409/1000\n - 1s - loss: 0.1616 - acc: 0.9891 - val_loss: 0.3723 - val_acc: 0.9517\nEpoch 410/1000\n - 1s - loss: 0.1623 - acc: 0.9876 - val_loss: 0.5594 - val_acc: 0.9351\nEpoch 411/1000\n - 1s - loss: 0.1785 - acc: 0.9861 - val_loss: 0.4244 - val_acc: 0.9502\nEpoch 412/1000\n - 1s - loss: 0.1578 - acc: 0.9906 - val_loss: 0.4067 - val_acc: 0.9397\nEpoch 413/1000\n - 1s - loss: 0.1559 - acc: 0.9887 - val_loss: 0.4035 - val_acc: 0.9487\nEpoch 414/1000\n - 1s - loss: 0.1495 - acc: 0.9910 - val_loss: 0.4272 - val_acc: 0.9397\nEpoch 415/1000\n - 1s - loss: 0.1475 - acc: 0.9917 - val_loss: 0.3823 - val_acc: 0.9502\nEpoch 416/1000\n - 1s - loss: 0.1340 - acc: 0.9955 - val_loss: 0.4097 - val_acc: 0.9457\nEpoch 417/1000\n - 1s - loss: 0.1765 - acc: 0.9842 - val_loss: 0.4134 - val_acc: 0.9487\nEpoch 418/1000\n - 1s - loss: 0.1696 - acc: 0.9887 - val_loss: 0.3937 - val_acc: 0.9457\nEpoch 419/1000\n - 1s - loss: 0.1457 - acc: 0.9936 - val_loss: 0.3769 - val_acc: 0.9397\nEpoch 420/1000\n - 1s - loss: 0.1373 - acc: 0.9936 - val_loss: 0.3923 - val_acc: 0.9397\nEpoch 421/1000\n - 1s - loss: 0.1572 - acc: 0.9895 - val_loss: 0.4341 - val_acc: 0.9442\nEpoch 422/1000\n - 1s - loss: 0.1478 - acc: 0.9928 - val_loss: 0.5211 - val_acc: 0.9367\nEpoch 423/1000\n - 1s - loss: 0.1490 - acc: 0.9906 - val_loss: 0.3805 - val_acc: 0.9457\nEpoch 424/1000\n - 1s - loss: 0.1493 - acc: 0.9902 - val_loss: 0.3535 - val_acc: 0.9517\nEpoch 425/1000\n - 1s - loss: 0.1536 - acc: 0.9898 - val_loss: 0.3975 - val_acc: 0.9457\nEpoch 426/1000\n - 1s - loss: 0.1551 - acc: 0.9910 - val_loss: 0.4051 - val_acc: 0.9472\nEpoch 427/1000\n - 1s - loss: 0.1579 - acc: 0.9898 - val_loss: 0.3873 - val_acc: 0.9472\nEpoch 428/1000\n - 1s - loss: 0.1609 - acc: 0.9864 - val_loss: 0.4180 - val_acc: 0.9487\nEpoch 429/1000\n - 1s - loss: 0.1585 - acc: 0.9913 - val_loss: 0.3854 - val_acc: 0.9532\nEpoch 430/1000\n - 1s - loss: 0.1382 - acc: 0.9955 - val_loss: 0.3606 - val_acc: 0.9427\nEpoch 431/1000\n - 1s - loss: 0.1584 - acc: 0.9891 - val_loss: 0.3737 - val_acc: 0.9427\nEpoch 432/1000\n - 1s - loss: 0.1450 - acc: 0.9925 - val_loss: 0.3528 - val_acc: 0.9457\nEpoch 433/1000\n - 1s - loss: 0.1452 - acc: 0.9925 - val_loss: 0.3716 - val_acc: 0.9442\nEpoch 434/1000\n - 1s - loss: 0.1545 - acc: 0.9902 - val_loss: 0.3856 - val_acc: 0.9532\nEpoch 435/1000\n - 1s - loss: 0.1438 - acc: 0.9928 - val_loss: 0.4255 - val_acc: 0.9487\nEpoch 436/1000\n - 1s - loss: 0.1508 - acc: 0.9902 - val_loss: 0.3831 - val_acc: 0.9442\nEpoch 437/1000\n - 1s - loss: 0.1529 - acc: 0.9902 - val_loss: 0.3944 - val_acc: 0.9502\nEpoch 438/1000\n - 1s - loss: 0.1491 - acc: 0.9910 - val_loss: 0.3981 - val_acc: 0.9397\nEpoch 439/1000\n - 1s - loss: 0.1460 - acc: 0.9917 - val_loss: 0.3863 - val_acc: 0.9442\nEpoch 440/1000\n - 1s - loss: 0.1441 - acc: 0.9925 - val_loss: 0.3847 - val_acc: 0.9472\nEpoch 441/1000\n - 1s - loss: 0.1469 - acc: 0.9898 - val_loss: 0.4166 - val_acc: 0.9487\nEpoch 442/1000\n - 1s - loss: 0.1433 - acc: 0.9932 - val_loss: 0.4030 - val_acc: 0.9502\nEpoch 443/1000\n - 1s - loss: 0.1522 - acc: 0.9917 - val_loss: 0.4154 - val_acc: 0.9457\nEpoch 444/1000\n - 1s - loss: 0.1392 - acc: 0.9925 - val_loss: 0.3715 - val_acc: 0.9517\nEpoch 445/1000\n - 1s - loss: 0.1515 - acc: 0.9876 - val_loss: 0.3645 - val_acc: 0.9412\nEpoch 446/1000\n - 1s - loss: 0.1517 - acc: 0.9910 - val_loss: 0.3762 - val_acc: 0.9548\nEpoch 447/1000\n - 1s - loss: 0.1499 - acc: 0.9898 - val_loss: 0.3591 - val_acc: 0.9517\nEpoch 448/1000\n - 1s - loss: 0.1503 - acc: 0.9895 - val_loss: 0.3685 - val_acc: 0.9487\nEpoch 449/1000\n - 1s - loss: 0.1496 - acc: 0.9906 - val_loss: 0.3818 - val_acc: 0.9502\nEpoch 450/1000\n - 1s - loss: 0.1570 - acc: 0.9883 - val_loss: 0.3474 - val_acc: 0.9487\nEpoch 451/1000\n - 1s - loss: 0.1525 - acc: 0.9895 - val_loss: 0.3793 - val_acc: 0.9563\nEpoch 452/1000\n - 1s - loss: 0.1614 - acc: 0.9887 - val_loss: 0.4293 - val_acc: 0.9487\nEpoch 453/1000\n - 1s - loss: 0.1595 - acc: 0.9868 - val_loss: 0.3814 - val_acc: 0.9502\nEpoch 454/1000\n - 1s - loss: 0.1370 - acc: 0.9944 - val_loss: 0.3990 - val_acc: 0.9457\nEpoch 455/1000\n - 1s - loss: 0.1330 - acc: 0.9959 - val_loss: 0.3710 - val_acc: 0.9472\nEpoch 456/1000\n - 1s - loss: 0.1405 - acc: 0.9921 - val_loss: 0.3749 - val_acc: 0.9517\nEpoch 457/1000\n - 1s - loss: 0.1430 - acc: 0.9921 - val_loss: 0.3631 - val_acc: 0.9487\nEpoch 458/1000\n - 1s - loss: 0.1551 - acc: 0.9887 - val_loss: 0.3733 - val_acc: 0.9412\nEpoch 459/1000\n - 1s - loss: 0.1443 - acc: 0.9936 - val_loss: 0.3571 - val_acc: 0.9442\nEpoch 460/1000\n - 1s - loss: 0.1385 - acc: 0.9932 - val_loss: 0.3547 - val_acc: 0.9457\nEpoch 461/1000\n - 1s - loss: 0.1399 - acc: 0.9928 - val_loss: 0.3832 - val_acc: 0.9487\nEpoch 462/1000\n - 1s - loss: 0.1469 - acc: 0.9913 - val_loss: 0.3790 - val_acc: 0.9457\nEpoch 463/1000\n - 1s - loss: 0.1419 - acc: 0.9925 - val_loss: 0.4383 - val_acc: 0.9427\nEpoch 464/1000\n - 1s - loss: 0.1454 - acc: 0.9887 - val_loss: 0.3882 - val_acc: 0.9457\nEpoch 465/1000\n - 1s - loss: 0.1339 - acc: 0.9932 - val_loss: 0.3587 - val_acc: 0.9427\nEpoch 466/1000\n - 1s - loss: 0.1794 - acc: 0.9831 - val_loss: 0.4303 - val_acc: 0.9427\nEpoch 467/1000\n - 1s - loss: 0.1300 - acc: 0.9966 - val_loss: 0.3655 - val_acc: 0.9457\nEpoch 468/1000\n - 1s - loss: 0.1398 - acc: 0.9910 - val_loss: 0.3758 - val_acc: 0.9472\nEpoch 469/1000\n - 1s - loss: 0.1510 - acc: 0.9910 - val_loss: 0.4026 - val_acc: 0.9548\nEpoch 470/1000\n - 1s - loss: 0.1433 - acc: 0.9902 - val_loss: 0.3884 - val_acc: 0.9457\nEpoch 471/1000\n - 1s - loss: 0.1394 - acc: 0.9932 - val_loss: 0.3883 - val_acc: 0.9502\nEpoch 472/1000\n - 1s - loss: 0.1365 - acc: 0.9936 - val_loss: 0.4040 - val_acc: 0.9457\nEpoch 473/1000\n - 1s - loss: 0.1340 - acc: 0.9932 - val_loss: 0.4381 - val_acc: 0.9517\nEpoch 474/1000\n","name":"stdout"},{"output_type":"stream","text":" - 1s - loss: 0.1367 - acc: 0.9936 - val_loss: 0.3947 - val_acc: 0.9502\nEpoch 475/1000\n - 1s - loss: 0.1455 - acc: 0.9902 - val_loss: 0.3847 - val_acc: 0.9472\nEpoch 476/1000\n - 1s - loss: 0.1456 - acc: 0.9913 - val_loss: 0.3608 - val_acc: 0.9487\nEpoch 477/1000\n - 1s - loss: 0.1468 - acc: 0.9910 - val_loss: 0.3437 - val_acc: 0.9442\nEpoch 478/1000\n - 1s - loss: 0.1472 - acc: 0.9925 - val_loss: 0.3911 - val_acc: 0.9457\nEpoch 479/1000\n - 1s - loss: 0.1502 - acc: 0.9898 - val_loss: 0.3917 - val_acc: 0.9457\nEpoch 480/1000\n - 1s - loss: 0.1377 - acc: 0.9936 - val_loss: 0.3730 - val_acc: 0.9472\nEpoch 481/1000\n - 1s - loss: 0.1536 - acc: 0.9876 - val_loss: 0.3970 - val_acc: 0.9487\nEpoch 482/1000\n - 1s - loss: 0.1642 - acc: 0.9861 - val_loss: 0.4153 - val_acc: 0.9548\nEpoch 483/1000\n - 1s - loss: 0.1568 - acc: 0.9883 - val_loss: 0.3703 - val_acc: 0.9502\nEpoch 484/1000\n - 1s - loss: 0.1411 - acc: 0.9925 - val_loss: 0.3941 - val_acc: 0.9502\nEpoch 485/1000\n - 1s - loss: 0.1350 - acc: 0.9932 - val_loss: 0.3778 - val_acc: 0.9517\nEpoch 486/1000\n - 1s - loss: 0.1470 - acc: 0.9917 - val_loss: 0.3535 - val_acc: 0.9457\nEpoch 487/1000\n - 1s - loss: 0.1494 - acc: 0.9887 - val_loss: 0.4455 - val_acc: 0.9412\nEpoch 488/1000\n - 1s - loss: 0.1420 - acc: 0.9910 - val_loss: 0.4148 - val_acc: 0.9457\nEpoch 489/1000\n - 1s - loss: 0.1387 - acc: 0.9910 - val_loss: 0.3721 - val_acc: 0.9457\nEpoch 490/1000\n - 1s - loss: 0.1357 - acc: 0.9944 - val_loss: 0.3925 - val_acc: 0.9427\nEpoch 491/1000\n - 1s - loss: 0.1340 - acc: 0.9932 - val_loss: 0.3950 - val_acc: 0.9472\nEpoch 492/1000\n - 1s - loss: 0.1406 - acc: 0.9951 - val_loss: 0.4040 - val_acc: 0.9487\nEpoch 493/1000\n - 1s - loss: 0.1266 - acc: 0.9951 - val_loss: 0.3764 - val_acc: 0.9382\nEpoch 494/1000\n - 1s - loss: 0.1315 - acc: 0.9928 - val_loss: 0.4006 - val_acc: 0.9457\nEpoch 495/1000\n - 1s - loss: 0.1460 - acc: 0.9880 - val_loss: 0.4300 - val_acc: 0.9487\nEpoch 496/1000\n - 1s - loss: 0.1331 - acc: 0.9940 - val_loss: 0.3793 - val_acc: 0.9517\nEpoch 497/1000\n - 1s - loss: 0.1468 - acc: 0.9887 - val_loss: 0.3843 - val_acc: 0.9472\nEpoch 498/1000\n - 1s - loss: 0.1382 - acc: 0.9940 - val_loss: 0.3790 - val_acc: 0.9382\nEpoch 499/1000\n - 1s - loss: 0.1368 - acc: 0.9913 - val_loss: 0.4940 - val_acc: 0.9351\nEpoch 500/1000\n - 1s - loss: 0.1492 - acc: 0.9895 - val_loss: 0.4746 - val_acc: 0.9351\nEpoch 501/1000\n - 1s - loss: 0.1453 - acc: 0.9925 - val_loss: 0.4007 - val_acc: 0.9442\nEpoch 502/1000\n - 1s - loss: 0.1370 - acc: 0.9917 - val_loss: 0.3914 - val_acc: 0.9397\nEpoch 503/1000\n - 1s - loss: 0.1559 - acc: 0.9891 - val_loss: 0.3824 - val_acc: 0.9427\nEpoch 504/1000\n - 1s - loss: 0.1428 - acc: 0.9910 - val_loss: 0.3890 - val_acc: 0.9472\nEpoch 505/1000\n - 1s - loss: 0.1425 - acc: 0.9928 - val_loss: 0.3716 - val_acc: 0.9487\nEpoch 506/1000\n - 1s - loss: 0.1330 - acc: 0.9936 - val_loss: 0.3786 - val_acc: 0.9472\nEpoch 507/1000\n - 1s - loss: 0.1383 - acc: 0.9910 - val_loss: 0.3726 - val_acc: 0.9502\nEpoch 508/1000\n - 1s - loss: 0.1376 - acc: 0.9913 - val_loss: 0.4705 - val_acc: 0.9442\nEpoch 509/1000\n - 1s - loss: 0.1310 - acc: 0.9940 - val_loss: 0.3705 - val_acc: 0.9442\nEpoch 510/1000\n - 1s - loss: 0.1407 - acc: 0.9928 - val_loss: 0.3786 - val_acc: 0.9457\nEpoch 511/1000\n - 1s - loss: 0.1351 - acc: 0.9932 - val_loss: 0.4411 - val_acc: 0.9276\nEpoch 512/1000\n - 1s - loss: 0.1478 - acc: 0.9895 - val_loss: 0.4420 - val_acc: 0.9472\nEpoch 513/1000\n - 1s - loss: 0.1331 - acc: 0.9940 - val_loss: 0.3883 - val_acc: 0.9367\nEpoch 514/1000\n - 1s - loss: 0.1497 - acc: 0.9891 - val_loss: 0.4190 - val_acc: 0.9442\nEpoch 515/1000\n - 1s - loss: 0.1415 - acc: 0.9921 - val_loss: 0.3791 - val_acc: 0.9472\nEpoch 516/1000\n - 1s - loss: 0.1286 - acc: 0.9932 - val_loss: 0.3640 - val_acc: 0.9457\nEpoch 517/1000\n - 1s - loss: 0.1429 - acc: 0.9910 - val_loss: 0.4637 - val_acc: 0.9412\nEpoch 518/1000\n - 1s - loss: 0.1448 - acc: 0.9891 - val_loss: 0.3705 - val_acc: 0.9487\nEpoch 519/1000\n - 1s - loss: 0.1407 - acc: 0.9910 - val_loss: 0.3909 - val_acc: 0.9487\nEpoch 520/1000\n - 1s - loss: 0.1614 - acc: 0.9853 - val_loss: 0.3704 - val_acc: 0.9457\nEpoch 521/1000\n - 1s - loss: 0.1361 - acc: 0.9940 - val_loss: 0.4034 - val_acc: 0.9457\nEpoch 522/1000\n - 1s - loss: 0.1448 - acc: 0.9925 - val_loss: 0.3689 - val_acc: 0.9442\nEpoch 523/1000\n - 1s - loss: 0.1438 - acc: 0.9913 - val_loss: 0.4141 - val_acc: 0.9472\nEpoch 524/1000\n - 1s - loss: 0.1366 - acc: 0.9925 - val_loss: 0.3673 - val_acc: 0.9487\nEpoch 525/1000\n - 1s - loss: 0.1332 - acc: 0.9917 - val_loss: 0.4638 - val_acc: 0.9367\nEpoch 526/1000\n - 1s - loss: 0.1493 - acc: 0.9891 - val_loss: 0.3871 - val_acc: 0.9472\nEpoch 527/1000\n - 1s - loss: 0.1460 - acc: 0.9883 - val_loss: 0.3751 - val_acc: 0.9442\nEpoch 528/1000\n - 1s - loss: 0.1414 - acc: 0.9913 - val_loss: 0.3961 - val_acc: 0.9397\nEpoch 529/1000\n - 1s - loss: 0.1500 - acc: 0.9887 - val_loss: 0.4037 - val_acc: 0.9412\nEpoch 530/1000\n - 1s - loss: 0.1356 - acc: 0.9936 - val_loss: 0.4124 - val_acc: 0.9427\nEpoch 531/1000\n - 1s - loss: 0.1287 - acc: 0.9940 - val_loss: 0.3858 - val_acc: 0.9457\nEpoch 532/1000\n - 1s - loss: 0.1356 - acc: 0.9917 - val_loss: 0.3851 - val_acc: 0.9457\nEpoch 533/1000\n - 1s - loss: 0.1312 - acc: 0.9928 - val_loss: 0.3785 - val_acc: 0.9412\nEpoch 534/1000\n - 1s - loss: 0.1359 - acc: 0.9917 - val_loss: 0.3908 - val_acc: 0.9517\nEpoch 535/1000\n - 1s - loss: 0.1567 - acc: 0.9883 - val_loss: 0.3691 - val_acc: 0.9412\nEpoch 536/1000\n - 1s - loss: 0.1406 - acc: 0.9921 - val_loss: 0.3670 - val_acc: 0.9367\nEpoch 537/1000\n - 1s - loss: 0.1642 - acc: 0.9853 - val_loss: 0.3749 - val_acc: 0.9442\nEpoch 538/1000\n - 1s - loss: 0.1426 - acc: 0.9898 - val_loss: 0.3885 - val_acc: 0.9487\nEpoch 539/1000\n - 1s - loss: 0.1446 - acc: 0.9891 - val_loss: 0.3547 - val_acc: 0.9532\nEpoch 540/1000\n - 1s - loss: 0.1349 - acc: 0.9906 - val_loss: 0.3791 - val_acc: 0.9487\nEpoch 541/1000\n - 1s - loss: 0.1241 - acc: 0.9959 - val_loss: 0.3904 - val_acc: 0.9487\nEpoch 542/1000\n - 1s - loss: 0.1454 - acc: 0.9887 - val_loss: 0.4388 - val_acc: 0.9502\nEpoch 543/1000\n - 1s - loss: 0.1425 - acc: 0.9928 - val_loss: 0.4567 - val_acc: 0.9442\nEpoch 544/1000\n - 1s - loss: 0.1369 - acc: 0.9932 - val_loss: 0.3861 - val_acc: 0.9517\nEpoch 545/1000\n - 1s - loss: 0.1297 - acc: 0.9944 - val_loss: 0.4056 - val_acc: 0.9442\nEpoch 546/1000\n - 1s - loss: 0.1405 - acc: 0.9913 - val_loss: 0.3697 - val_acc: 0.9472\nEpoch 547/1000\n - 1s - loss: 0.1453 - acc: 0.9902 - val_loss: 0.3845 - val_acc: 0.9487\nEpoch 548/1000\n - 1s - loss: 0.1440 - acc: 0.9928 - val_loss: 0.3872 - val_acc: 0.9532\nEpoch 549/1000\n - 1s - loss: 0.1330 - acc: 0.9902 - val_loss: 0.4423 - val_acc: 0.9457\nEpoch 550/1000\n - 1s - loss: 0.1300 - acc: 0.9940 - val_loss: 0.3551 - val_acc: 0.9487\nEpoch 551/1000\n - 1s - loss: 0.1398 - acc: 0.9910 - val_loss: 0.3782 - val_acc: 0.9442\nEpoch 552/1000\n - 1s - loss: 0.1420 - acc: 0.9902 - val_loss: 0.3846 - val_acc: 0.9487\nEpoch 553/1000\n - 1s - loss: 0.1482 - acc: 0.9895 - val_loss: 0.3891 - val_acc: 0.9397\nEpoch 554/1000\n - 1s - loss: 0.1317 - acc: 0.9940 - val_loss: 0.3969 - val_acc: 0.9457\nEpoch 555/1000\n - 1s - loss: 0.1373 - acc: 0.9913 - val_loss: 0.4232 - val_acc: 0.9487\nEpoch 556/1000\n - 1s - loss: 0.1546 - acc: 0.9868 - val_loss: 0.3754 - val_acc: 0.9548\nEpoch 557/1000\n - 1s - loss: 0.1363 - acc: 0.9913 - val_loss: 0.3714 - val_acc: 0.9457\nEpoch 558/1000\n - 1s - loss: 0.1332 - acc: 0.9913 - val_loss: 0.4083 - val_acc: 0.9532\nEpoch 559/1000\n - 1s - loss: 0.1396 - acc: 0.9898 - val_loss: 0.3907 - val_acc: 0.9457\nEpoch 560/1000\n - 1s - loss: 0.1280 - acc: 0.9917 - val_loss: 0.3489 - val_acc: 0.9563\nEpoch 561/1000\n - 1s - loss: 0.1360 - acc: 0.9906 - val_loss: 0.3475 - val_acc: 0.9563\nEpoch 562/1000\n - 1s - loss: 0.1252 - acc: 0.9947 - val_loss: 0.4709 - val_acc: 0.9427\nEpoch 563/1000\n - 1s - loss: 0.1491 - acc: 0.9906 - val_loss: 0.3858 - val_acc: 0.9487\nEpoch 564/1000\n - 1s - loss: 0.1197 - acc: 0.9947 - val_loss: 0.4053 - val_acc: 0.9457\nEpoch 565/1000\n - 1s - loss: 0.1243 - acc: 0.9944 - val_loss: 0.3928 - val_acc: 0.9427\nEpoch 566/1000\n - 1s - loss: 0.1357 - acc: 0.9944 - val_loss: 0.4097 - val_acc: 0.9472\nEpoch 567/1000\n - 1s - loss: 0.1421 - acc: 0.9906 - val_loss: 0.3614 - val_acc: 0.9487\nEpoch 568/1000\n - 1s - loss: 0.1398 - acc: 0.9910 - val_loss: 0.3827 - val_acc: 0.9532\n","name":"stdout"},{"output_type":"stream","text":"Epoch 569/1000\n - 1s - loss: 0.1281 - acc: 0.9932 - val_loss: 0.3784 - val_acc: 0.9472\nEpoch 570/1000\n - 1s - loss: 0.1298 - acc: 0.9936 - val_loss: 0.3874 - val_acc: 0.9502\nEpoch 571/1000\n - 1s - loss: 0.1307 - acc: 0.9932 - val_loss: 0.4090 - val_acc: 0.9457\nEpoch 572/1000\n - 1s - loss: 0.1378 - acc: 0.9910 - val_loss: 0.3655 - val_acc: 0.9442\nEpoch 573/1000\n - 1s - loss: 0.1301 - acc: 0.9925 - val_loss: 0.4036 - val_acc: 0.9487\nEpoch 574/1000\n - 1s - loss: 0.1377 - acc: 0.9921 - val_loss: 0.3696 - val_acc: 0.9442\nEpoch 575/1000\n - 1s - loss: 0.1271 - acc: 0.9940 - val_loss: 0.3853 - val_acc: 0.9472\nEpoch 576/1000\n - 1s - loss: 0.1326 - acc: 0.9928 - val_loss: 0.3683 - val_acc: 0.9517\nEpoch 577/1000\n - 1s - loss: 0.1289 - acc: 0.9928 - val_loss: 0.3944 - val_acc: 0.9487\nEpoch 578/1000\n - 1s - loss: 0.1352 - acc: 0.9917 - val_loss: 0.3802 - val_acc: 0.9442\nEpoch 579/1000\n - 1s - loss: 0.1258 - acc: 0.9944 - val_loss: 0.3625 - val_acc: 0.9397\nEpoch 580/1000\n - 1s - loss: 0.1344 - acc: 0.9921 - val_loss: 0.4000 - val_acc: 0.9517\nEpoch 581/1000\n - 1s - loss: 0.1341 - acc: 0.9917 - val_loss: 0.3662 - val_acc: 0.9472\nEpoch 582/1000\n - 1s - loss: 0.1462 - acc: 0.9906 - val_loss: 0.4651 - val_acc: 0.9397\nEpoch 583/1000\n - 1s - loss: 0.1352 - acc: 0.9921 - val_loss: 0.3895 - val_acc: 0.9487\nEpoch 584/1000\n - 1s - loss: 0.1334 - acc: 0.9940 - val_loss: 0.3812 - val_acc: 0.9472\nEpoch 585/1000\n - 1s - loss: 0.1505 - acc: 0.9902 - val_loss: 0.4321 - val_acc: 0.9472\nEpoch 586/1000\n - 1s - loss: 0.1268 - acc: 0.9928 - val_loss: 0.4172 - val_acc: 0.9502\nEpoch 587/1000\n - 1s - loss: 0.1493 - acc: 0.9876 - val_loss: 0.3847 - val_acc: 0.9442\nEpoch 588/1000\n - 1s - loss: 0.1328 - acc: 0.9932 - val_loss: 0.4689 - val_acc: 0.9306\nEpoch 589/1000\n - 1s - loss: 0.1422 - acc: 0.9910 - val_loss: 0.4153 - val_acc: 0.9382\nEpoch 590/1000\n - 1s - loss: 0.1354 - acc: 0.9910 - val_loss: 0.3949 - val_acc: 0.9472\nEpoch 591/1000\n - 1s - loss: 0.1352 - acc: 0.9917 - val_loss: 0.3691 - val_acc: 0.9517\nEpoch 592/1000\n - 1s - loss: 0.1358 - acc: 0.9917 - val_loss: 0.3959 - val_acc: 0.9532\nEpoch 593/1000\n - 1s - loss: 0.1242 - acc: 0.9944 - val_loss: 0.3940 - val_acc: 0.9457\nEpoch 594/1000\n - 1s - loss: 0.1403 - acc: 0.9917 - val_loss: 0.4348 - val_acc: 0.9487\nEpoch 595/1000\n - 1s - loss: 0.1388 - acc: 0.9910 - val_loss: 0.3779 - val_acc: 0.9412\nEpoch 596/1000\n - 1s - loss: 0.1276 - acc: 0.9940 - val_loss: 0.3985 - val_acc: 0.9502\nEpoch 597/1000\n - 1s - loss: 0.1268 - acc: 0.9932 - val_loss: 0.4102 - val_acc: 0.9382\nEpoch 598/1000\n - 1s - loss: 0.1287 - acc: 0.9947 - val_loss: 0.3505 - val_acc: 0.9487\nEpoch 599/1000\n - 1s - loss: 0.1407 - acc: 0.9921 - val_loss: 0.3644 - val_acc: 0.9517\nEpoch 600/1000\n - 1s - loss: 0.1388 - acc: 0.9913 - val_loss: 0.3775 - val_acc: 0.9472\nEpoch 601/1000\n - 1s - loss: 0.1473 - acc: 0.9895 - val_loss: 0.3503 - val_acc: 0.9472\nEpoch 602/1000\n - 1s - loss: 0.1356 - acc: 0.9910 - val_loss: 0.4050 - val_acc: 0.9457\nEpoch 603/1000\n - 1s - loss: 0.1306 - acc: 0.9917 - val_loss: 0.3656 - val_acc: 0.9472\nEpoch 604/1000\n - 1s - loss: 0.1390 - acc: 0.9910 - val_loss: 0.3465 - val_acc: 0.9487\nEpoch 605/1000\n - 1s - loss: 0.1268 - acc: 0.9951 - val_loss: 0.3795 - val_acc: 0.9457\nEpoch 606/1000\n - 1s - loss: 0.1253 - acc: 0.9936 - val_loss: 0.3906 - val_acc: 0.9548\nEpoch 607/1000\n - 1s - loss: 0.1216 - acc: 0.9940 - val_loss: 0.4038 - val_acc: 0.9457\nEpoch 608/1000\n - 1s - loss: 0.1196 - acc: 0.9936 - val_loss: 0.3803 - val_acc: 0.9502\nEpoch 609/1000\n - 1s - loss: 0.1394 - acc: 0.9895 - val_loss: 0.3854 - val_acc: 0.9457\nEpoch 610/1000\n - 1s - loss: 0.1310 - acc: 0.9921 - val_loss: 0.4206 - val_acc: 0.9382\nEpoch 611/1000\n - 1s - loss: 0.1314 - acc: 0.9928 - val_loss: 0.4119 - val_acc: 0.9487\nEpoch 612/1000\n - 1s - loss: 0.1372 - acc: 0.9913 - val_loss: 0.3912 - val_acc: 0.9517\nEpoch 613/1000\n - 1s - loss: 0.1318 - acc: 0.9921 - val_loss: 0.3595 - val_acc: 0.9442\nEpoch 614/1000\n - 1s - loss: 0.1337 - acc: 0.9906 - val_loss: 0.3660 - val_acc: 0.9427\nEpoch 615/1000\n - 1s - loss: 0.1197 - acc: 0.9944 - val_loss: 0.4568 - val_acc: 0.9336\nEpoch 616/1000\n - 1s - loss: 0.1358 - acc: 0.9921 - val_loss: 0.3862 - val_acc: 0.9457\nEpoch 617/1000\n - 1s - loss: 0.1412 - acc: 0.9898 - val_loss: 0.3618 - val_acc: 0.9472\nEpoch 618/1000\n - 1s - loss: 0.1383 - acc: 0.9883 - val_loss: 0.3681 - val_acc: 0.9397\nEpoch 619/1000\n - 1s - loss: 0.1354 - acc: 0.9913 - val_loss: 0.3578 - val_acc: 0.9427\nEpoch 620/1000\n - 1s - loss: 0.1495 - acc: 0.9876 - val_loss: 0.4004 - val_acc: 0.9487\nEpoch 621/1000\n - 1s - loss: 0.1366 - acc: 0.9910 - val_loss: 0.3586 - val_acc: 0.9442\nEpoch 622/1000\n - 1s - loss: 0.1346 - acc: 0.9932 - val_loss: 0.3813 - val_acc: 0.9487\nEpoch 623/1000\n - 1s - loss: 0.1358 - acc: 0.9910 - val_loss: 0.3709 - val_acc: 0.9487\nEpoch 624/1000\n - 1s - loss: 0.1238 - acc: 0.9940 - val_loss: 0.4095 - val_acc: 0.9457\nEpoch 625/1000\n - 1s - loss: 0.1262 - acc: 0.9947 - val_loss: 0.3585 - val_acc: 0.9487\nEpoch 626/1000\n - 1s - loss: 0.1289 - acc: 0.9917 - val_loss: 0.3740 - val_acc: 0.9472\nEpoch 627/1000\n - 1s - loss: 0.1429 - acc: 0.9891 - val_loss: 0.3474 - val_acc: 0.9563\nEpoch 628/1000\n - 1s - loss: 0.1244 - acc: 0.9944 - val_loss: 0.3792 - val_acc: 0.9487\nEpoch 629/1000\n - 1s - loss: 0.1349 - acc: 0.9910 - val_loss: 0.3682 - val_acc: 0.9472\nEpoch 630/1000\n - 1s - loss: 0.1463 - acc: 0.9872 - val_loss: 0.4486 - val_acc: 0.9397\nEpoch 631/1000\n - 1s - loss: 0.1389 - acc: 0.9925 - val_loss: 0.3700 - val_acc: 0.9487\nEpoch 632/1000\n - 1s - loss: 0.1222 - acc: 0.9936 - val_loss: 0.3519 - val_acc: 0.9517\nEpoch 633/1000\n - 1s - loss: 0.1184 - acc: 0.9944 - val_loss: 0.3938 - val_acc: 0.9412\nEpoch 634/1000\n - 1s - loss: 0.1394 - acc: 0.9913 - val_loss: 0.3891 - val_acc: 0.9472\nEpoch 635/1000\n - 1s - loss: 0.1301 - acc: 0.9921 - val_loss: 0.3497 - val_acc: 0.9472\nEpoch 636/1000\n - 1s - loss: 0.1297 - acc: 0.9917 - val_loss: 0.4162 - val_acc: 0.9382\nEpoch 637/1000\n - 1s - loss: 0.1379 - acc: 0.9902 - val_loss: 0.3736 - val_acc: 0.9517\nEpoch 638/1000\n - 1s - loss: 0.1282 - acc: 0.9932 - val_loss: 0.3581 - val_acc: 0.9457\nEpoch 639/1000\n - 1s - loss: 0.1289 - acc: 0.9928 - val_loss: 0.3628 - val_acc: 0.9548\nEpoch 640/1000\n - 1s - loss: 0.1273 - acc: 0.9932 - val_loss: 0.3769 - val_acc: 0.9517\nEpoch 641/1000\n - 1s - loss: 0.1422 - acc: 0.9883 - val_loss: 0.3739 - val_acc: 0.9397\nEpoch 642/1000\n - 1s - loss: 0.1325 - acc: 0.9913 - val_loss: 0.3672 - val_acc: 0.9517\nEpoch 643/1000\n - 1s - loss: 0.1149 - acc: 0.9974 - val_loss: 0.3509 - val_acc: 0.9397\nEpoch 644/1000\n - 1s - loss: 0.1307 - acc: 0.9921 - val_loss: 0.3514 - val_acc: 0.9457\nEpoch 645/1000\n - 1s - loss: 0.1180 - acc: 0.9944 - val_loss: 0.3656 - val_acc: 0.9502\nEpoch 646/1000\n - 1s - loss: 0.1367 - acc: 0.9891 - val_loss: 0.3729 - val_acc: 0.9517\nEpoch 647/1000\n - 1s - loss: 0.1266 - acc: 0.9940 - val_loss: 0.3454 - val_acc: 0.9502\nEpoch 648/1000\n - 1s - loss: 0.1342 - acc: 0.9895 - val_loss: 0.3382 - val_acc: 0.9502\nEpoch 649/1000\n - 1s - loss: 0.1484 - acc: 0.9880 - val_loss: 0.3543 - val_acc: 0.9457\nEpoch 650/1000\n - 1s - loss: 0.1125 - acc: 0.9955 - val_loss: 0.3488 - val_acc: 0.9502\nEpoch 651/1000\n - 1s - loss: 0.1245 - acc: 0.9932 - val_loss: 0.4441 - val_acc: 0.9412\nEpoch 652/1000\n - 1s - loss: 0.1336 - acc: 0.9895 - val_loss: 0.4544 - val_acc: 0.9246\nEpoch 653/1000\n - 1s - loss: 0.1164 - acc: 0.9959 - val_loss: 0.3435 - val_acc: 0.9457\nEpoch 654/1000\n - 1s - loss: 0.1195 - acc: 0.9940 - val_loss: 0.3710 - val_acc: 0.9517\nEpoch 655/1000\n - 1s - loss: 0.1219 - acc: 0.9947 - val_loss: 0.4499 - val_acc: 0.9291\nEpoch 656/1000\n - 1s - loss: 0.1336 - acc: 0.9921 - val_loss: 0.3673 - val_acc: 0.9517\nEpoch 657/1000\n - 1s - loss: 0.1336 - acc: 0.9910 - val_loss: 0.3493 - val_acc: 0.9532\nEpoch 658/1000\n - 1s - loss: 0.1338 - acc: 0.9917 - val_loss: 0.3511 - val_acc: 0.9578\nEpoch 659/1000\n - 1s - loss: 0.1434 - acc: 0.9876 - val_loss: 0.3500 - val_acc: 0.9563\nEpoch 660/1000\n - 1s - loss: 0.1520 - acc: 0.9880 - val_loss: 0.3548 - val_acc: 0.9532\nEpoch 661/1000\n - 1s - loss: 0.1177 - acc: 0.9944 - val_loss: 0.3834 - val_acc: 0.9487\nEpoch 662/1000\n - 1s - loss: 0.1194 - acc: 0.9951 - val_loss: 0.3609 - val_acc: 0.9472\nEpoch 663/1000\n","name":"stdout"},{"output_type":"stream","text":" - 1s - loss: 0.1206 - acc: 0.9921 - val_loss: 0.3681 - val_acc: 0.9502\nEpoch 664/1000\n - 1s - loss: 0.1392 - acc: 0.9913 - val_loss: 0.3795 - val_acc: 0.9382\nEpoch 665/1000\n - 1s - loss: 0.1360 - acc: 0.9925 - val_loss: 0.3854 - val_acc: 0.9502\nEpoch 666/1000\n - 1s - loss: 0.1299 - acc: 0.9913 - val_loss: 0.3784 - val_acc: 0.9517\nEpoch 667/1000\n - 1s - loss: 0.1333 - acc: 0.9921 - val_loss: 0.3580 - val_acc: 0.9487\nEpoch 668/1000\n - 1s - loss: 0.1419 - acc: 0.9876 - val_loss: 0.3706 - val_acc: 0.9457\nEpoch 669/1000\n - 1s - loss: 0.1149 - acc: 0.9944 - val_loss: 0.3610 - val_acc: 0.9472\nEpoch 670/1000\n - 1s - loss: 0.1337 - acc: 0.9917 - val_loss: 0.3688 - val_acc: 0.9472\nEpoch 671/1000\n - 1s - loss: 0.1143 - acc: 0.9962 - val_loss: 0.3697 - val_acc: 0.9517\nEpoch 672/1000\n - 1s - loss: 0.1232 - acc: 0.9928 - val_loss: 0.3584 - val_acc: 0.9502\nEpoch 673/1000\n - 1s - loss: 0.1277 - acc: 0.9921 - val_loss: 0.3794 - val_acc: 0.9397\nEpoch 674/1000\n - 1s - loss: 0.1484 - acc: 0.9861 - val_loss: 0.3832 - val_acc: 0.9472\nEpoch 675/1000\n - 1s - loss: 0.1447 - acc: 0.9876 - val_loss: 0.3764 - val_acc: 0.9502\nEpoch 676/1000\n - 1s - loss: 0.1405 - acc: 0.9891 - val_loss: 0.4014 - val_acc: 0.9487\nEpoch 677/1000\n - 1s - loss: 0.1453 - acc: 0.9891 - val_loss: 0.3766 - val_acc: 0.9532\nEpoch 678/1000\n - 1s - loss: 0.1201 - acc: 0.9955 - val_loss: 0.3523 - val_acc: 0.9487\nEpoch 679/1000\n - 1s - loss: 0.1285 - acc: 0.9921 - val_loss: 0.3695 - val_acc: 0.9427\nEpoch 680/1000\n - 1s - loss: 0.1405 - acc: 0.9906 - val_loss: 0.3420 - val_acc: 0.9502\nEpoch 681/1000\n - 1s - loss: 0.1355 - acc: 0.9895 - val_loss: 0.3330 - val_acc: 0.9578\nEpoch 682/1000\n - 1s - loss: 0.1313 - acc: 0.9921 - val_loss: 0.3607 - val_acc: 0.9487\nEpoch 683/1000\n - 1s - loss: 0.1349 - acc: 0.9917 - val_loss: 0.4274 - val_acc: 0.9502\nEpoch 684/1000\n - 1s - loss: 0.1313 - acc: 0.9925 - val_loss: 0.4121 - val_acc: 0.9548\nEpoch 685/1000\n - 1s - loss: 0.1344 - acc: 0.9917 - val_loss: 0.3659 - val_acc: 0.9532\nEpoch 686/1000\n - 1s - loss: 0.1404 - acc: 0.9906 - val_loss: 0.4678 - val_acc: 0.9382\nEpoch 687/1000\n - 1s - loss: 0.1434 - acc: 0.9887 - val_loss: 0.3960 - val_acc: 0.9517\nEpoch 688/1000\n - 1s - loss: 0.1294 - acc: 0.9917 - val_loss: 0.3850 - val_acc: 0.9487\nEpoch 689/1000\n - 1s - loss: 0.1272 - acc: 0.9936 - val_loss: 0.3726 - val_acc: 0.9427\nEpoch 690/1000\n - 1s - loss: 0.1469 - acc: 0.9880 - val_loss: 0.3777 - val_acc: 0.9472\nEpoch 691/1000\n - 1s - loss: 0.1482 - acc: 0.9887 - val_loss: 0.4064 - val_acc: 0.9487\nEpoch 692/1000\n - 1s - loss: 0.1282 - acc: 0.9932 - val_loss: 0.3447 - val_acc: 0.9502\nEpoch 693/1000\n - 1s - loss: 0.1240 - acc: 0.9936 - val_loss: 0.3491 - val_acc: 0.9457\nEpoch 694/1000\n - 1s - loss: 0.1193 - acc: 0.9940 - val_loss: 0.3726 - val_acc: 0.9502\nEpoch 695/1000\n - 1s - loss: 0.1294 - acc: 0.9925 - val_loss: 0.3576 - val_acc: 0.9502\nEpoch 696/1000\n - 1s - loss: 0.1508 - acc: 0.9872 - val_loss: 0.4088 - val_acc: 0.9517\nEpoch 697/1000\n - 1s - loss: 0.1188 - acc: 0.9959 - val_loss: 0.3592 - val_acc: 0.9487\nEpoch 698/1000\n - 1s - loss: 0.1137 - acc: 0.9932 - val_loss: 0.3593 - val_acc: 0.9502\nEpoch 699/1000\n - 1s - loss: 0.1208 - acc: 0.9944 - val_loss: 0.3920 - val_acc: 0.9517\nEpoch 700/1000\n - 1s - loss: 0.1388 - acc: 0.9895 - val_loss: 0.4107 - val_acc: 0.9442\nEpoch 701/1000\n - 1s - loss: 0.1381 - acc: 0.9913 - val_loss: 0.3777 - val_acc: 0.9532\nEpoch 702/1000\n - 1s - loss: 0.1276 - acc: 0.9925 - val_loss: 0.3935 - val_acc: 0.9502\nEpoch 703/1000\n - 1s - loss: 0.1339 - acc: 0.9913 - val_loss: 0.3644 - val_acc: 0.9517\nEpoch 704/1000\n - 1s - loss: 0.1258 - acc: 0.9932 - val_loss: 0.3748 - val_acc: 0.9487\nEpoch 705/1000\n - 1s - loss: 0.1443 - acc: 0.9895 - val_loss: 0.3561 - val_acc: 0.9457\nEpoch 706/1000\n - 1s - loss: 0.1245 - acc: 0.9928 - val_loss: 0.4150 - val_acc: 0.9382\nEpoch 707/1000\n - 1s - loss: 0.1124 - acc: 0.9951 - val_loss: 0.3580 - val_acc: 0.9502\nEpoch 708/1000\n - 1s - loss: 0.1223 - acc: 0.9917 - val_loss: 0.4023 - val_acc: 0.9563\nEpoch 709/1000\n - 1s - loss: 0.1216 - acc: 0.9925 - val_loss: 0.3807 - val_acc: 0.9442\nEpoch 710/1000\n - 1s - loss: 0.1280 - acc: 0.9925 - val_loss: 0.3939 - val_acc: 0.9548\nEpoch 711/1000\n - 1s - loss: 0.1156 - acc: 0.9932 - val_loss: 0.4081 - val_acc: 0.9382\nEpoch 712/1000\n - 1s - loss: 0.1461 - acc: 0.9857 - val_loss: 0.4164 - val_acc: 0.9442\nEpoch 713/1000\n - 1s - loss: 0.1231 - acc: 0.9928 - val_loss: 0.3825 - val_acc: 0.9442\nEpoch 714/1000\n - 1s - loss: 0.1380 - acc: 0.9902 - val_loss: 0.4536 - val_acc: 0.9472\nEpoch 715/1000\n - 1s - loss: 0.1234 - acc: 0.9925 - val_loss: 0.3586 - val_acc: 0.9427\nEpoch 716/1000\n - 1s - loss: 0.1353 - acc: 0.9902 - val_loss: 0.3492 - val_acc: 0.9517\nEpoch 717/1000\n - 1s - loss: 0.1407 - acc: 0.9887 - val_loss: 0.3735 - val_acc: 0.9517\nEpoch 718/1000\n - 1s - loss: 0.1451 - acc: 0.9883 - val_loss: 0.4642 - val_acc: 0.9382\nEpoch 719/1000\n - 1s - loss: 0.1264 - acc: 0.9932 - val_loss: 0.3837 - val_acc: 0.9517\nEpoch 720/1000\n - 1s - loss: 0.1341 - acc: 0.9910 - val_loss: 0.4130 - val_acc: 0.9442\nEpoch 721/1000\n - 1s - loss: 0.1499 - acc: 0.9872 - val_loss: 0.3692 - val_acc: 0.9532\nEpoch 722/1000\n - 1s - loss: 0.1277 - acc: 0.9936 - val_loss: 0.3697 - val_acc: 0.9457\nEpoch 723/1000\n - 1s - loss: 0.1206 - acc: 0.9955 - val_loss: 0.3787 - val_acc: 0.9442\nEpoch 724/1000\n - 1s - loss: 0.1219 - acc: 0.9944 - val_loss: 0.3769 - val_acc: 0.9502\nEpoch 725/1000\n - 1s - loss: 0.1148 - acc: 0.9947 - val_loss: 0.4038 - val_acc: 0.9517\nEpoch 726/1000\n - 1s - loss: 0.1309 - acc: 0.9913 - val_loss: 0.3672 - val_acc: 0.9457\nEpoch 727/1000\n - 1s - loss: 0.1265 - acc: 0.9940 - val_loss: 0.3578 - val_acc: 0.9487\nEpoch 728/1000\n - 1s - loss: 0.1154 - acc: 0.9936 - val_loss: 0.5335 - val_acc: 0.9261\nEpoch 729/1000\n - 1s - loss: 0.1538 - acc: 0.9880 - val_loss: 0.3362 - val_acc: 0.9457\nEpoch 730/1000\n - 1s - loss: 0.1282 - acc: 0.9913 - val_loss: 0.3969 - val_acc: 0.9427\nEpoch 731/1000\n - 1s - loss: 0.1293 - acc: 0.9906 - val_loss: 0.4380 - val_acc: 0.9502\nEpoch 732/1000\n - 1s - loss: 0.1465 - acc: 0.9883 - val_loss: 0.3641 - val_acc: 0.9502\nEpoch 733/1000\n - 1s - loss: 0.1177 - acc: 0.9932 - val_loss: 0.3901 - val_acc: 0.9457\nEpoch 734/1000\n - 1s - loss: 0.1293 - acc: 0.9910 - val_loss: 0.3721 - val_acc: 0.9397\nEpoch 735/1000\n - 1s - loss: 0.1181 - acc: 0.9940 - val_loss: 0.4249 - val_acc: 0.9532\nEpoch 736/1000\n - 1s - loss: 0.1249 - acc: 0.9921 - val_loss: 0.4104 - val_acc: 0.9382\nEpoch 737/1000\n - 1s - loss: 0.1253 - acc: 0.9902 - val_loss: 0.3688 - val_acc: 0.9457\nEpoch 738/1000\n - 1s - loss: 0.1247 - acc: 0.9928 - val_loss: 0.3704 - val_acc: 0.9487\nEpoch 739/1000\n - 1s - loss: 0.1254 - acc: 0.9917 - val_loss: 0.4813 - val_acc: 0.9367\nEpoch 740/1000\n - 1s - loss: 0.1188 - acc: 0.9944 - val_loss: 0.3706 - val_acc: 0.9442\nEpoch 741/1000\n - 1s - loss: 0.1160 - acc: 0.9955 - val_loss: 0.3496 - val_acc: 0.9502\nEpoch 742/1000\n - 1s - loss: 0.1144 - acc: 0.9947 - val_loss: 0.4240 - val_acc: 0.9487\nEpoch 743/1000\n - 1s - loss: 0.1363 - acc: 0.9895 - val_loss: 0.4272 - val_acc: 0.9502\nEpoch 744/1000\n - 1s - loss: 0.1174 - acc: 0.9936 - val_loss: 0.3875 - val_acc: 0.9442\nEpoch 745/1000\n - 1s - loss: 0.1266 - acc: 0.9940 - val_loss: 0.3419 - val_acc: 0.9472\nEpoch 746/1000\n - 1s - loss: 0.1260 - acc: 0.9925 - val_loss: 0.4607 - val_acc: 0.9336\nEpoch 747/1000\n - 1s - loss: 0.1391 - acc: 0.9898 - val_loss: 0.4240 - val_acc: 0.9502\nEpoch 748/1000\n - 1s - loss: 0.1246 - acc: 0.9936 - val_loss: 0.3454 - val_acc: 0.9548\nEpoch 749/1000\n - 1s - loss: 0.1352 - acc: 0.9898 - val_loss: 0.3637 - val_acc: 0.9487\nEpoch 750/1000\n - 1s - loss: 0.1258 - acc: 0.9936 - val_loss: 0.3685 - val_acc: 0.9487\nEpoch 751/1000\n - 1s - loss: 0.1307 - acc: 0.9902 - val_loss: 0.3553 - val_acc: 0.9472\nEpoch 752/1000\n - 1s - loss: 0.1225 - acc: 0.9932 - val_loss: 0.3950 - val_acc: 0.9517\nEpoch 753/1000\n - 1s - loss: 0.1237 - acc: 0.9936 - val_loss: 0.3853 - val_acc: 0.9517\nEpoch 754/1000\n - 1s - loss: 0.1273 - acc: 0.9917 - val_loss: 0.5273 - val_acc: 0.9291\nEpoch 755/1000\n - 1s - loss: 0.1302 - acc: 0.9913 - val_loss: 0.3390 - val_acc: 0.9532\nEpoch 756/1000\n - 1s - loss: 0.1370 - acc: 0.9895 - val_loss: 0.3871 - val_acc: 0.9457\nEpoch 757/1000\n - 1s - loss: 0.1087 - acc: 0.9944 - val_loss: 0.3358 - val_acc: 0.9563\n","name":"stdout"},{"output_type":"stream","text":"Epoch 758/1000\n - 1s - loss: 0.1215 - acc: 0.9928 - val_loss: 0.3288 - val_acc: 0.9532\nEpoch 759/1000\n - 1s - loss: 0.1358 - acc: 0.9898 - val_loss: 0.3519 - val_acc: 0.9472\nEpoch 760/1000\n - 1s - loss: 0.1218 - acc: 0.9932 - val_loss: 0.3816 - val_acc: 0.9487\nEpoch 761/1000\n - 1s - loss: 0.1211 - acc: 0.9944 - val_loss: 0.4065 - val_acc: 0.9457\nEpoch 762/1000\n - 1s - loss: 0.1356 - acc: 0.9891 - val_loss: 0.4465 - val_acc: 0.9321\nEpoch 763/1000\n - 1s - loss: 0.1158 - acc: 0.9944 - val_loss: 0.3837 - val_acc: 0.9532\nEpoch 764/1000\n - 1s - loss: 0.1105 - acc: 0.9959 - val_loss: 0.3499 - val_acc: 0.9502\nEpoch 765/1000\n - 1s - loss: 0.1200 - acc: 0.9917 - val_loss: 0.3773 - val_acc: 0.9412\nEpoch 766/1000\n - 1s - loss: 0.1214 - acc: 0.9917 - val_loss: 0.3575 - val_acc: 0.9487\nEpoch 767/1000\n - 1s - loss: 0.1330 - acc: 0.9906 - val_loss: 0.3480 - val_acc: 0.9517\nEpoch 768/1000\n - 1s - loss: 0.1324 - acc: 0.9921 - val_loss: 0.3814 - val_acc: 0.9457\nEpoch 769/1000\n - 1s - loss: 0.1378 - acc: 0.9883 - val_loss: 0.3552 - val_acc: 0.9502\nEpoch 770/1000\n - 1s - loss: 0.1302 - acc: 0.9910 - val_loss: 0.3640 - val_acc: 0.9487\nEpoch 771/1000\n - 1s - loss: 0.1204 - acc: 0.9944 - val_loss: 0.3467 - val_acc: 0.9532\nEpoch 772/1000\n - 1s - loss: 0.1242 - acc: 0.9917 - val_loss: 0.3903 - val_acc: 0.9517\nEpoch 773/1000\n - 1s - loss: 0.1165 - acc: 0.9944 - val_loss: 0.3484 - val_acc: 0.9517\nEpoch 774/1000\n - 1s - loss: 0.1316 - acc: 0.9913 - val_loss: 0.3469 - val_acc: 0.9517\nEpoch 775/1000\n - 1s - loss: 0.1341 - acc: 0.9887 - val_loss: 0.3595 - val_acc: 0.9487\nEpoch 776/1000\n - 1s - loss: 0.1329 - acc: 0.9913 - val_loss: 0.3604 - val_acc: 0.9472\nEpoch 777/1000\n - 1s - loss: 0.1194 - acc: 0.9936 - val_loss: 0.3516 - val_acc: 0.9517\nEpoch 778/1000\n - 1s - loss: 0.1123 - acc: 0.9944 - val_loss: 0.3537 - val_acc: 0.9517\nEpoch 779/1000\n - 1s - loss: 0.1204 - acc: 0.9932 - val_loss: 0.3657 - val_acc: 0.9487\nEpoch 780/1000\n - 1s - loss: 0.1310 - acc: 0.9906 - val_loss: 0.3383 - val_acc: 0.9502\nEpoch 781/1000\n - 1s - loss: 0.1424 - acc: 0.9880 - val_loss: 0.3919 - val_acc: 0.9502\nEpoch 782/1000\n - 1s - loss: 0.1279 - acc: 0.9917 - val_loss: 0.3504 - val_acc: 0.9517\nEpoch 783/1000\n - 1s - loss: 0.1347 - acc: 0.9906 - val_loss: 0.3710 - val_acc: 0.9442\nEpoch 784/1000\n - 1s - loss: 0.1278 - acc: 0.9921 - val_loss: 0.3831 - val_acc: 0.9532\nEpoch 785/1000\n - 1s - loss: 0.1241 - acc: 0.9913 - val_loss: 0.3591 - val_acc: 0.9548\nEpoch 786/1000\n - 1s - loss: 0.1150 - acc: 0.9944 - val_loss: 0.3719 - val_acc: 0.9382\nEpoch 787/1000\n - 1s - loss: 0.1173 - acc: 0.9947 - val_loss: 0.3628 - val_acc: 0.9472\nEpoch 788/1000\n - 1s - loss: 0.1130 - acc: 0.9940 - val_loss: 0.3573 - val_acc: 0.9457\nEpoch 789/1000\n - 1s - loss: 0.1259 - acc: 0.9902 - val_loss: 0.3625 - val_acc: 0.9487\nEpoch 790/1000\n - 1s - loss: 0.1385 - acc: 0.9883 - val_loss: 0.3789 - val_acc: 0.9563\nEpoch 791/1000\n - 1s - loss: 0.1242 - acc: 0.9921 - val_loss: 0.3443 - val_acc: 0.9412\nEpoch 792/1000\n - 1s - loss: 0.1092 - acc: 0.9951 - val_loss: 0.3990 - val_acc: 0.9487\nEpoch 793/1000\n - 1s - loss: 0.1135 - acc: 0.9936 - val_loss: 0.3798 - val_acc: 0.9351\nEpoch 794/1000\n - 1s - loss: 0.1227 - acc: 0.9925 - val_loss: 0.3675 - val_acc: 0.9487\nEpoch 795/1000\n - 1s - loss: 0.1305 - acc: 0.9898 - val_loss: 0.3655 - val_acc: 0.9442\nEpoch 796/1000\n - 1s - loss: 0.1294 - acc: 0.9921 - val_loss: 0.3512 - val_acc: 0.9517\nEpoch 797/1000\n - 1s - loss: 0.1200 - acc: 0.9944 - val_loss: 0.3999 - val_acc: 0.9412\nEpoch 798/1000\n - 1s - loss: 0.1304 - acc: 0.9902 - val_loss: 0.3323 - val_acc: 0.9532\nEpoch 799/1000\n - 1s - loss: 0.1212 - acc: 0.9928 - val_loss: 0.3700 - val_acc: 0.9487\nEpoch 800/1000\n - 1s - loss: 0.1447 - acc: 0.9864 - val_loss: 0.3644 - val_acc: 0.9517\nEpoch 801/1000\n - 1s - loss: 0.1175 - acc: 0.9944 - val_loss: 0.3890 - val_acc: 0.9532\nEpoch 802/1000\n - 1s - loss: 0.1151 - acc: 0.9944 - val_loss: 0.3369 - val_acc: 0.9578\nEpoch 803/1000\n - 1s - loss: 0.1145 - acc: 0.9944 - val_loss: 0.3404 - val_acc: 0.9457\nEpoch 804/1000\n - 1s - loss: 0.1316 - acc: 0.9917 - val_loss: 0.4298 - val_acc: 0.9472\nEpoch 805/1000\n - 1s - loss: 0.1261 - acc: 0.9936 - val_loss: 0.3641 - val_acc: 0.9517\nEpoch 806/1000\n - 1s - loss: 0.1142 - acc: 0.9955 - val_loss: 0.3438 - val_acc: 0.9472\nEpoch 807/1000\n - 1s - loss: 0.1250 - acc: 0.9925 - val_loss: 0.3941 - val_acc: 0.9517\nEpoch 808/1000\n - 1s - loss: 0.1270 - acc: 0.9925 - val_loss: 0.3812 - val_acc: 0.9457\nEpoch 809/1000\n - 1s - loss: 0.1328 - acc: 0.9921 - val_loss: 0.4059 - val_acc: 0.9382\nEpoch 810/1000\n - 1s - loss: 0.1486 - acc: 0.9861 - val_loss: 0.4133 - val_acc: 0.9487\nEpoch 811/1000\n - 1s - loss: 0.1305 - acc: 0.9921 - val_loss: 0.3859 - val_acc: 0.9442\nEpoch 812/1000\n - 1s - loss: 0.1265 - acc: 0.9906 - val_loss: 0.3655 - val_acc: 0.9517\nEpoch 813/1000\n - 1s - loss: 0.1225 - acc: 0.9925 - val_loss: 0.3795 - val_acc: 0.9472\nEpoch 814/1000\n - 1s - loss: 0.1223 - acc: 0.9902 - val_loss: 0.4295 - val_acc: 0.9321\nEpoch 815/1000\n - 1s - loss: 0.1198 - acc: 0.9940 - val_loss: 0.3908 - val_acc: 0.9472\nEpoch 816/1000\n - 1s - loss: 0.1266 - acc: 0.9910 - val_loss: 0.3493 - val_acc: 0.9532\nEpoch 817/1000\n - 1s - loss: 0.1227 - acc: 0.9928 - val_loss: 0.3526 - val_acc: 0.9502\nEpoch 818/1000\n - 1s - loss: 0.1381 - acc: 0.9898 - val_loss: 0.4140 - val_acc: 0.9457\nEpoch 819/1000\n - 1s - loss: 0.1277 - acc: 0.9917 - val_loss: 0.3607 - val_acc: 0.9532\nEpoch 820/1000\n - 1s - loss: 0.1270 - acc: 0.9913 - val_loss: 0.3510 - val_acc: 0.9548\nEpoch 821/1000\n - 1s - loss: 0.1339 - acc: 0.9913 - val_loss: 0.3792 - val_acc: 0.9487\nEpoch 822/1000\n - 1s - loss: 0.1154 - acc: 0.9947 - val_loss: 0.3364 - val_acc: 0.9487\nEpoch 823/1000\n - 1s - loss: 0.1190 - acc: 0.9925 - val_loss: 0.3415 - val_acc: 0.9472\nEpoch 824/1000\n - 1s - loss: 0.1163 - acc: 0.9940 - val_loss: 0.3478 - val_acc: 0.9517\nEpoch 825/1000\n - 1s - loss: 0.1182 - acc: 0.9936 - val_loss: 0.3857 - val_acc: 0.9457\nEpoch 826/1000\n - 1s - loss: 0.1161 - acc: 0.9940 - val_loss: 0.3593 - val_acc: 0.9457\nEpoch 827/1000\n - 1s - loss: 0.1219 - acc: 0.9925 - val_loss: 0.4398 - val_acc: 0.9306\nEpoch 828/1000\n - 1s - loss: 0.1267 - acc: 0.9902 - val_loss: 0.3576 - val_acc: 0.9578\nEpoch 829/1000\n - 1s - loss: 0.1527 - acc: 0.9842 - val_loss: 0.3632 - val_acc: 0.9442\nEpoch 830/1000\n - 1s - loss: 0.1485 - acc: 0.9857 - val_loss: 0.3519 - val_acc: 0.9517\nEpoch 831/1000\n - 1s - loss: 0.1240 - acc: 0.9917 - val_loss: 0.3445 - val_acc: 0.9532\nEpoch 832/1000\n - 1s - loss: 0.1086 - acc: 0.9955 - val_loss: 0.3433 - val_acc: 0.9532\nEpoch 833/1000\n - 1s - loss: 0.1144 - acc: 0.9940 - val_loss: 0.4526 - val_acc: 0.9472\nEpoch 834/1000\n - 1s - loss: 0.1404 - acc: 0.9876 - val_loss: 0.3605 - val_acc: 0.9442\nEpoch 835/1000\n - 1s - loss: 0.1132 - acc: 0.9940 - val_loss: 0.3836 - val_acc: 0.9457\nEpoch 836/1000\n - 1s - loss: 0.1067 - acc: 0.9955 - val_loss: 0.3462 - val_acc: 0.9593\nEpoch 837/1000\n - 1s - loss: 0.1146 - acc: 0.9936 - val_loss: 0.3957 - val_acc: 0.9412\nEpoch 838/1000\n - 1s - loss: 0.1217 - acc: 0.9936 - val_loss: 0.3388 - val_acc: 0.9563\nEpoch 839/1000\n - 1s - loss: 0.1226 - acc: 0.9910 - val_loss: 0.3553 - val_acc: 0.9442\nEpoch 840/1000\n - 1s - loss: 0.1066 - acc: 0.9940 - val_loss: 0.3926 - val_acc: 0.9336\nEpoch 841/1000\n - 1s - loss: 0.1179 - acc: 0.9925 - val_loss: 0.3807 - val_acc: 0.9427\nEpoch 842/1000\n - 1s - loss: 0.1281 - acc: 0.9917 - val_loss: 0.4764 - val_acc: 0.9442\nEpoch 843/1000\n - 1s - loss: 0.1182 - acc: 0.9925 - val_loss: 0.4415 - val_acc: 0.9472\nEpoch 844/1000\n - 1s - loss: 0.1130 - acc: 0.9928 - val_loss: 0.3413 - val_acc: 0.9472\nEpoch 845/1000\n - 1s - loss: 0.1135 - acc: 0.9936 - val_loss: 0.3620 - val_acc: 0.9517\nEpoch 846/1000\n - 1s - loss: 0.1126 - acc: 0.9932 - val_loss: 0.3887 - val_acc: 0.9487\nEpoch 847/1000\n - 1s - loss: 0.1148 - acc: 0.9947 - val_loss: 0.3619 - val_acc: 0.9487\nEpoch 848/1000\n - 1s - loss: 0.1267 - acc: 0.9910 - val_loss: 0.4022 - val_acc: 0.9502\nEpoch 849/1000\n - 1s - loss: 0.1218 - acc: 0.9921 - val_loss: 0.3552 - val_acc: 0.9578\nEpoch 850/1000\n - 1s - loss: 0.1262 - acc: 0.9913 - val_loss: 0.3633 - val_acc: 0.9427\nEpoch 851/1000\n - 1s - loss: 0.1218 - acc: 0.9932 - val_loss: 0.3862 - val_acc: 0.9442\nEpoch 852/1000\n","name":"stdout"},{"output_type":"stream","text":" - 1s - loss: 0.1121 - acc: 0.9940 - val_loss: 0.4056 - val_acc: 0.9442\nEpoch 853/1000\n - 1s - loss: 0.1306 - acc: 0.9906 - val_loss: 0.4865 - val_acc: 0.9231\nEpoch 854/1000\n - 1s - loss: 0.1199 - acc: 0.9917 - val_loss: 0.5097 - val_acc: 0.9351\nEpoch 855/1000\n - 1s - loss: 0.1166 - acc: 0.9936 - val_loss: 0.3535 - val_acc: 0.9593\nEpoch 856/1000\n - 1s - loss: 0.1381 - acc: 0.9902 - val_loss: 0.3444 - val_acc: 0.9517\nEpoch 857/1000\n - 1s - loss: 0.1192 - acc: 0.9928 - val_loss: 0.3668 - val_acc: 0.9548\nEpoch 858/1000\n - 1s - loss: 0.1147 - acc: 0.9944 - val_loss: 0.3668 - val_acc: 0.9532\nEpoch 859/1000\n - 1s - loss: 0.1228 - acc: 0.9913 - val_loss: 0.3537 - val_acc: 0.9502\nEpoch 860/1000\n - 1s - loss: 0.1164 - acc: 0.9921 - val_loss: 0.3537 - val_acc: 0.9457\nEpoch 861/1000\n - 1s - loss: 0.1123 - acc: 0.9947 - val_loss: 0.3720 - val_acc: 0.9457\nEpoch 862/1000\n - 1s - loss: 0.1013 - acc: 0.9955 - val_loss: 0.3675 - val_acc: 0.9457\nEpoch 863/1000\n - 1s - loss: 0.1194 - acc: 0.9902 - val_loss: 0.4039 - val_acc: 0.9442\nEpoch 864/1000\n - 1s - loss: 0.1074 - acc: 0.9951 - val_loss: 0.3652 - val_acc: 0.9427\nEpoch 865/1000\n - 1s - loss: 0.1187 - acc: 0.9925 - val_loss: 0.4204 - val_acc: 0.9367\nEpoch 866/1000\n - 1s - loss: 0.1262 - acc: 0.9902 - val_loss: 0.3868 - val_acc: 0.9351\nEpoch 867/1000\n - 1s - loss: 0.1156 - acc: 0.9947 - val_loss: 0.4102 - val_acc: 0.9427\nEpoch 868/1000\n - 1s - loss: 0.1071 - acc: 0.9947 - val_loss: 0.3943 - val_acc: 0.9457\nEpoch 869/1000\n - 1s - loss: 0.1133 - acc: 0.9936 - val_loss: 0.3737 - val_acc: 0.9487\nEpoch 870/1000\n - 1s - loss: 0.1384 - acc: 0.9891 - val_loss: 0.4152 - val_acc: 0.9502\nEpoch 871/1000\n - 1s - loss: 0.1242 - acc: 0.9917 - val_loss: 0.3584 - val_acc: 0.9487\nEpoch 872/1000\n - 1s - loss: 0.1035 - acc: 0.9962 - val_loss: 0.3867 - val_acc: 0.9517\nEpoch 873/1000\n - 1s - loss: 0.1089 - acc: 0.9936 - val_loss: 0.3717 - val_acc: 0.9412\nEpoch 874/1000\n - 1s - loss: 0.1124 - acc: 0.9940 - val_loss: 0.3576 - val_acc: 0.9502\nEpoch 875/1000\n - 1s - loss: 0.0978 - acc: 0.9959 - val_loss: 0.4071 - val_acc: 0.9351\nEpoch 876/1000\n - 1s - loss: 0.1326 - acc: 0.9898 - val_loss: 0.3773 - val_acc: 0.9487\nEpoch 877/1000\n - 1s - loss: 0.1206 - acc: 0.9925 - val_loss: 0.3645 - val_acc: 0.9517\nEpoch 878/1000\n - 1s - loss: 0.1100 - acc: 0.9932 - val_loss: 0.3490 - val_acc: 0.9517\nEpoch 879/1000\n - 1s - loss: 0.1204 - acc: 0.9913 - val_loss: 0.3474 - val_acc: 0.9502\nEpoch 880/1000\n - 1s - loss: 0.1256 - acc: 0.9906 - val_loss: 0.3352 - val_acc: 0.9487\nEpoch 881/1000\n - 1s - loss: 0.1039 - acc: 0.9966 - val_loss: 0.3558 - val_acc: 0.9457\nEpoch 882/1000\n - 1s - loss: 0.1149 - acc: 0.9936 - val_loss: 0.3587 - val_acc: 0.9487\nEpoch 883/1000\n - 1s - loss: 0.1261 - acc: 0.9910 - val_loss: 0.3828 - val_acc: 0.9487\nEpoch 884/1000\n - 1s - loss: 0.1210 - acc: 0.9917 - val_loss: 0.3704 - val_acc: 0.9517\nEpoch 885/1000\n - 1s - loss: 0.1282 - acc: 0.9906 - val_loss: 0.3504 - val_acc: 0.9548\nEpoch 886/1000\n - 1s - loss: 0.1248 - acc: 0.9921 - val_loss: 0.4166 - val_acc: 0.9532\nEpoch 887/1000\n - 1s - loss: 0.1181 - acc: 0.9940 - val_loss: 0.3482 - val_acc: 0.9563\nEpoch 888/1000\n - 1s - loss: 0.1162 - acc: 0.9925 - val_loss: 0.3366 - val_acc: 0.9563\nEpoch 889/1000\n - 1s - loss: 0.1116 - acc: 0.9913 - val_loss: 0.3479 - val_acc: 0.9532\nEpoch 890/1000\n - 1s - loss: 0.1186 - acc: 0.9928 - val_loss: 0.3705 - val_acc: 0.9502\nEpoch 891/1000\n - 1s - loss: 0.1236 - acc: 0.9913 - val_loss: 0.3839 - val_acc: 0.9502\nEpoch 892/1000\n - 1s - loss: 0.1321 - acc: 0.9913 - val_loss: 0.3542 - val_acc: 0.9487\nEpoch 893/1000\n - 1s - loss: 0.1137 - acc: 0.9936 - val_loss: 0.4340 - val_acc: 0.9321\nEpoch 894/1000\n - 1s - loss: 0.1161 - acc: 0.9921 - val_loss: 0.3454 - val_acc: 0.9517\nEpoch 895/1000\n - 1s - loss: 0.1236 - acc: 0.9917 - val_loss: 0.3799 - val_acc: 0.9532\nEpoch 896/1000\n - 1s - loss: 0.1159 - acc: 0.9917 - val_loss: 0.3716 - val_acc: 0.9457\nEpoch 897/1000\n - 1s - loss: 0.1164 - acc: 0.9928 - val_loss: 0.3943 - val_acc: 0.9412\nEpoch 898/1000\n - 1s - loss: 0.1309 - acc: 0.9902 - val_loss: 0.3611 - val_acc: 0.9517\nEpoch 899/1000\n - 1s - loss: 0.1254 - acc: 0.9917 - val_loss: 0.3435 - val_acc: 0.9517\nEpoch 900/1000\n - 1s - loss: 0.1316 - acc: 0.9891 - val_loss: 0.4183 - val_acc: 0.9472\nEpoch 901/1000\n - 1s - loss: 0.1199 - acc: 0.9925 - val_loss: 0.3395 - val_acc: 0.9563\nEpoch 902/1000\n - 1s - loss: 0.1060 - acc: 0.9951 - val_loss: 0.3491 - val_acc: 0.9517\nEpoch 903/1000\n - 1s - loss: 0.1189 - acc: 0.9925 - val_loss: 0.4038 - val_acc: 0.9487\nEpoch 904/1000\n - 1s - loss: 0.1213 - acc: 0.9921 - val_loss: 0.3819 - val_acc: 0.9442\nEpoch 905/1000\n - 1s - loss: 0.1379 - acc: 0.9887 - val_loss: 0.3773 - val_acc: 0.9532\nEpoch 906/1000\n - 1s - loss: 0.0983 - acc: 0.9966 - val_loss: 0.3515 - val_acc: 0.9532\nEpoch 907/1000\n - 1s - loss: 0.1258 - acc: 0.9898 - val_loss: 0.3486 - val_acc: 0.9532\nEpoch 908/1000\n - 1s - loss: 0.1325 - acc: 0.9910 - val_loss: 0.4298 - val_acc: 0.9427\nEpoch 909/1000\n - 1s - loss: 0.1187 - acc: 0.9913 - val_loss: 0.3571 - val_acc: 0.9442\nEpoch 910/1000\n - 1s - loss: 0.1189 - acc: 0.9928 - val_loss: 0.3923 - val_acc: 0.9442\nEpoch 911/1000\n - 1s - loss: 0.1099 - acc: 0.9947 - val_loss: 0.4087 - val_acc: 0.9487\nEpoch 912/1000\n - 1s - loss: 0.1045 - acc: 0.9947 - val_loss: 0.3475 - val_acc: 0.9517\nEpoch 913/1000\n - 1s - loss: 0.1101 - acc: 0.9932 - val_loss: 0.3557 - val_acc: 0.9472\nEpoch 914/1000\n - 1s - loss: 0.1251 - acc: 0.9898 - val_loss: 0.3481 - val_acc: 0.9548\nEpoch 915/1000\n - 1s - loss: 0.1150 - acc: 0.9940 - val_loss: 0.3462 - val_acc: 0.9563\nEpoch 916/1000\n - 1s - loss: 0.1205 - acc: 0.9906 - val_loss: 0.3659 - val_acc: 0.9548\nEpoch 917/1000\n - 1s - loss: 0.1242 - acc: 0.9910 - val_loss: 0.4148 - val_acc: 0.9321\nEpoch 918/1000\n - 1s - loss: 0.1283 - acc: 0.9906 - val_loss: 0.3664 - val_acc: 0.9517\nEpoch 919/1000\n - 1s - loss: 0.1193 - acc: 0.9917 - val_loss: 0.3633 - val_acc: 0.9517\nEpoch 920/1000\n - 1s - loss: 0.1235 - acc: 0.9917 - val_loss: 0.3761 - val_acc: 0.9532\nEpoch 921/1000\n - 1s - loss: 0.1362 - acc: 0.9887 - val_loss: 0.3558 - val_acc: 0.9578\nEpoch 922/1000\n - 1s - loss: 0.1321 - acc: 0.9887 - val_loss: 0.4189 - val_acc: 0.9412\nEpoch 923/1000\n - 1s - loss: 0.1289 - acc: 0.9913 - val_loss: 0.3552 - val_acc: 0.9517\nEpoch 924/1000\n - 1s - loss: 0.1075 - acc: 0.9951 - val_loss: 0.3958 - val_acc: 0.9397\nEpoch 925/1000\n - 1s - loss: 0.1152 - acc: 0.9932 - val_loss: 0.3985 - val_acc: 0.9427\nEpoch 926/1000\n - 1s - loss: 0.1154 - acc: 0.9928 - val_loss: 0.4100 - val_acc: 0.9532\nEpoch 927/1000\n - 1s - loss: 0.1428 - acc: 0.9895 - val_loss: 0.3536 - val_acc: 0.9532\nEpoch 928/1000\n - 1s - loss: 0.1070 - acc: 0.9944 - val_loss: 0.3541 - val_acc: 0.9487\nEpoch 929/1000\n - 1s - loss: 0.1105 - acc: 0.9928 - val_loss: 0.3986 - val_acc: 0.9457\nEpoch 930/1000\n - 1s - loss: 0.1067 - acc: 0.9936 - val_loss: 0.3748 - val_acc: 0.9532\nEpoch 931/1000\n - 1s - loss: 0.1102 - acc: 0.9940 - val_loss: 0.3946 - val_acc: 0.9412\nEpoch 932/1000\n - 1s - loss: 0.1225 - acc: 0.9906 - val_loss: 0.3997 - val_acc: 0.9457\nEpoch 933/1000\n - 1s - loss: 0.1195 - acc: 0.9910 - val_loss: 0.3629 - val_acc: 0.9472\nEpoch 934/1000\n - 1s - loss: 0.1078 - acc: 0.9955 - val_loss: 0.3578 - val_acc: 0.9487\nEpoch 935/1000\n - 1s - loss: 0.1397 - acc: 0.9891 - val_loss: 0.3373 - val_acc: 0.9487\nEpoch 936/1000\n - 1s - loss: 0.1203 - acc: 0.9921 - val_loss: 0.3943 - val_acc: 0.9412\nEpoch 937/1000\n - 1s - loss: 0.1083 - acc: 0.9940 - val_loss: 0.3572 - val_acc: 0.9502\nEpoch 938/1000\n - 1s - loss: 0.0979 - acc: 0.9966 - val_loss: 0.3539 - val_acc: 0.9517\nEpoch 939/1000\n - 1s - loss: 0.1098 - acc: 0.9913 - val_loss: 0.3886 - val_acc: 0.9563\nEpoch 940/1000\n - 1s - loss: 0.1128 - acc: 0.9936 - val_loss: 0.4338 - val_acc: 0.9472\nEpoch 941/1000\n - 1s - loss: 0.1173 - acc: 0.9925 - val_loss: 0.3438 - val_acc: 0.9532\nEpoch 942/1000\n - 1s - loss: 0.1453 - acc: 0.9853 - val_loss: 0.3823 - val_acc: 0.9457\nEpoch 943/1000\n - 1s - loss: 0.1188 - acc: 0.9932 - val_loss: 0.3360 - val_acc: 0.9548\nEpoch 944/1000\n - 1s - loss: 0.1177 - acc: 0.9917 - val_loss: 0.3798 - val_acc: 0.9442\nEpoch 945/1000\n - 1s - loss: 0.1266 - acc: 0.9917 - val_loss: 0.3686 - val_acc: 0.9517\nEpoch 946/1000\n - 1s - loss: 0.1106 - acc: 0.9928 - val_loss: 0.3654 - val_acc: 0.9487\n","name":"stdout"},{"output_type":"stream","text":"Epoch 947/1000\n - 1s - loss: 0.1147 - acc: 0.9936 - val_loss: 0.3666 - val_acc: 0.9548\nEpoch 948/1000\n - 1s - loss: 0.1025 - acc: 0.9951 - val_loss: 0.3455 - val_acc: 0.9502\nEpoch 949/1000\n - 1s - loss: 0.1225 - acc: 0.9917 - val_loss: 0.3435 - val_acc: 0.9532\nEpoch 950/1000\n - 1s - loss: 0.1185 - acc: 0.9928 - val_loss: 0.4475 - val_acc: 0.9382\nEpoch 951/1000\n - 1s - loss: 0.1113 - acc: 0.9940 - val_loss: 0.3443 - val_acc: 0.9457\nEpoch 952/1000\n - 1s - loss: 0.1311 - acc: 0.9868 - val_loss: 0.4048 - val_acc: 0.9472\nEpoch 953/1000\n - 1s - loss: 0.1109 - acc: 0.9932 - val_loss: 0.3813 - val_acc: 0.9502\nEpoch 954/1000\n - 1s - loss: 0.1060 - acc: 0.9955 - val_loss: 0.3838 - val_acc: 0.9487\nEpoch 955/1000\n - 1s - loss: 0.1197 - acc: 0.9921 - val_loss: 0.3698 - val_acc: 0.9472\nEpoch 956/1000\n - 1s - loss: 0.1017 - acc: 0.9955 - val_loss: 0.4357 - val_acc: 0.9351\nEpoch 957/1000\n - 1s - loss: 0.1124 - acc: 0.9940 - val_loss: 0.3455 - val_acc: 0.9532\nEpoch 958/1000\n - 1s - loss: 0.1235 - acc: 0.9902 - val_loss: 0.3673 - val_acc: 0.9442\nEpoch 959/1000\n - 1s - loss: 0.1180 - acc: 0.9921 - val_loss: 0.4300 - val_acc: 0.9336\nEpoch 960/1000\n - 1s - loss: 0.1132 - acc: 0.9959 - val_loss: 0.3625 - val_acc: 0.9457\nEpoch 961/1000\n - 1s - loss: 0.1124 - acc: 0.9947 - val_loss: 0.3671 - val_acc: 0.9502\nEpoch 962/1000\n - 1s - loss: 0.1204 - acc: 0.9906 - val_loss: 0.3809 - val_acc: 0.9532\nEpoch 963/1000\n - 1s - loss: 0.1203 - acc: 0.9928 - val_loss: 0.3447 - val_acc: 0.9457\nEpoch 964/1000\n - 1s - loss: 0.1249 - acc: 0.9902 - val_loss: 0.3658 - val_acc: 0.9532\nEpoch 965/1000\n - 1s - loss: 0.1173 - acc: 0.9925 - val_loss: 0.3636 - val_acc: 0.9517\nEpoch 966/1000\n - 1s - loss: 0.1198 - acc: 0.9917 - val_loss: 0.3652 - val_acc: 0.9502\nEpoch 967/1000\n - 1s - loss: 0.1029 - acc: 0.9940 - val_loss: 0.3319 - val_acc: 0.9548\nEpoch 968/1000\n - 1s - loss: 0.1106 - acc: 0.9932 - val_loss: 0.3758 - val_acc: 0.9517\nEpoch 969/1000\n - 1s - loss: 0.1117 - acc: 0.9947 - val_loss: 0.3404 - val_acc: 0.9472\nEpoch 970/1000\n - 1s - loss: 0.1241 - acc: 0.9913 - val_loss: 0.3761 - val_acc: 0.9472\nEpoch 971/1000\n - 1s - loss: 0.1380 - acc: 0.9868 - val_loss: 0.3747 - val_acc: 0.9502\nEpoch 972/1000\n - 1s - loss: 0.1339 - acc: 0.9895 - val_loss: 0.3584 - val_acc: 0.9487\nEpoch 973/1000\n - 1s - loss: 0.1083 - acc: 0.9959 - val_loss: 0.3733 - val_acc: 0.9563\nEpoch 974/1000\n - 1s - loss: 0.1172 - acc: 0.9917 - val_loss: 0.3379 - val_acc: 0.9487\nEpoch 975/1000\n - 1s - loss: 0.1079 - acc: 0.9944 - val_loss: 0.3546 - val_acc: 0.9548\nEpoch 976/1000\n - 1s - loss: 0.1114 - acc: 0.9940 - val_loss: 0.3815 - val_acc: 0.9457\nEpoch 977/1000\n - 1s - loss: 0.1372 - acc: 0.9880 - val_loss: 0.3611 - val_acc: 0.9502\nEpoch 978/1000\n - 1s - loss: 0.1089 - acc: 0.9928 - val_loss: 0.3827 - val_acc: 0.9472\nEpoch 979/1000\n - 1s - loss: 0.1143 - acc: 0.9936 - val_loss: 0.3676 - val_acc: 0.9442\nEpoch 980/1000\n - 1s - loss: 0.1048 - acc: 0.9940 - val_loss: 0.3720 - val_acc: 0.9427\nEpoch 981/1000\n - 1s - loss: 0.1178 - acc: 0.9917 - val_loss: 0.3385 - val_acc: 0.9457\nEpoch 982/1000\n - 1s - loss: 0.1157 - acc: 0.9936 - val_loss: 0.3486 - val_acc: 0.9532\nEpoch 983/1000\n - 1s - loss: 0.0987 - acc: 0.9970 - val_loss: 0.3470 - val_acc: 0.9563\nEpoch 984/1000\n - 1s - loss: 0.1084 - acc: 0.9940 - val_loss: 0.3518 - val_acc: 0.9548\nEpoch 985/1000\n - 1s - loss: 0.1057 - acc: 0.9928 - val_loss: 0.3947 - val_acc: 0.9502\nEpoch 986/1000\n - 1s - loss: 0.1147 - acc: 0.9921 - val_loss: 0.3877 - val_acc: 0.9532\nEpoch 987/1000\n - 1s - loss: 0.1141 - acc: 0.9936 - val_loss: 0.3596 - val_acc: 0.9502\nEpoch 988/1000\n - 1s - loss: 0.1130 - acc: 0.9947 - val_loss: 0.3844 - val_acc: 0.9548\nEpoch 989/1000\n - 1s - loss: 0.1160 - acc: 0.9917 - val_loss: 0.3838 - val_acc: 0.9532\nEpoch 990/1000\n - 1s - loss: 0.1299 - acc: 0.9883 - val_loss: 0.4214 - val_acc: 0.9472\nEpoch 991/1000\n - 1s - loss: 0.1268 - acc: 0.9910 - val_loss: 0.3737 - val_acc: 0.9472\nEpoch 992/1000\n - 1s - loss: 0.0972 - acc: 0.9955 - val_loss: 0.3584 - val_acc: 0.9457\nEpoch 993/1000\n - 1s - loss: 0.1013 - acc: 0.9940 - val_loss: 0.3713 - val_acc: 0.9427\nEpoch 994/1000\n - 1s - loss: 0.1091 - acc: 0.9936 - val_loss: 0.3546 - val_acc: 0.9427\nEpoch 995/1000\n - 1s - loss: 0.1186 - acc: 0.9902 - val_loss: 0.4083 - val_acc: 0.9351\nEpoch 996/1000\n - 1s - loss: 0.1124 - acc: 0.9932 - val_loss: 0.3385 - val_acc: 0.9502\nEpoch 997/1000\n - 1s - loss: 0.1237 - acc: 0.9906 - val_loss: 0.3971 - val_acc: 0.9548\nEpoch 998/1000\n - 1s - loss: 0.1153 - acc: 0.9925 - val_loss: 0.3602 - val_acc: 0.9502\nEpoch 999/1000\n - 1s - loss: 0.1199 - acc: 0.9932 - val_loss: 0.3620 - val_acc: 0.9502\nEpoch 1000/1000\n - 1s - loss: 0.1187 - acc: 0.9928 - val_loss: 0.4156 - val_acc: 0.9427\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"(eval_loss, eval_accuracy) = model.evaluate(validation_data, validation_labels, batch_size= batch_size, verbose=1)\n\nprint(\"Validation Accuracy: {:.4f}%\".format(eval_accuracy * 100))\nprint(\"Validation Loss: {}\".format(eval_loss))","execution_count":32,"outputs":[{"output_type":"stream","text":"663/663 [==============================] - 0s 100us/step\nValidation Accuracy: 94.2685%\nValidation Loss: 0.4155804994059544\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"filename = test_generator.filenames\ntruth = test_generator.classes\nlabel = test_generator.class_indices\nindexlabel = dict((value, key) for key, value in label.items())\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\npreds = model.predict(test_data)\n\npredictions = [i.argmax() for i in preds]\ny_true = [i.argmax() for i in test_labels]\ncm = confusion_matrix(y_pred=predictions, y_true=y_true)\n\nprint('Test Accuracy: {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))","execution_count":33,"outputs":[{"output_type":"stream","text":"Test Accuracy: 0.9475218658892128\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams[\"axes.grid\"] = False\nplt.rcParams.update({'font.size': 20})\n\nlabels = []\n\nlabel = test_generator.class_indices\nindexlabel = dict((value, key) for key, value in label.items())\n\nfor k,v in indexlabel.items():\n    labels.append(v)\n\nfrom sklearn.metrics import confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    accuracy = np.trace(cm) / float(np.sum(cm))\n    misclass = 1 - accuracy\n    if normalize:\n        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion Matrix')\n\n    print(cm)\n#     fig = plt.figure()\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n#     plt.title(title)\n#     plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() / 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n\n\nplt.figure(figsize=(10,10))\nplot_confusion_matrix(cm, classes=labels, title=' ')","execution_count":34,"outputs":[{"output_type":"stream","text":"Confusion Matrix\n[[167   1]\n [ 17 158]]\n","name":"stdout"},{"output_type":"display_data","data":{"text/plain":"<Figure size 720x720 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import confusion_matrix, classification_report\ny_pred=predictions\ny_pred_probabilities=y_pred\n\n# y_pred = np.argmax(y_pred,axis = 1) \ny_actual = y_true\n\nclassnames=[]\nfor classname in test_generator.class_indices:\n    classnames.append(classname)\n\nconfusion_mtx = confusion_matrix(y_actual, y_pred) \nprint(confusion_mtx)\ntarget_names = classnames\nprint(classification_report(y_actual, y_pred, target_names=target_names))","execution_count":35,"outputs":[{"output_type":"stream","text":"[[167   1]\n [ 17 158]]\n              precision    recall  f1-score   support\n\n          DR       0.91      0.99      0.95       168\n       No_DR       0.99      0.90      0.95       175\n\n    accuracy                           0.95       343\n   macro avg       0.95      0.95      0.95       343\nweighted avg       0.95      0.95      0.95       343\n\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"total=sum(sum(cm))\n\nsensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\nprint('Sensitivity : ', sensitivity )\n\nSpecificity = cm[1,1]/(cm[1,1]+cm[0,1])\nprint('Specificity : ', Specificity )","execution_count":36,"outputs":[{"output_type":"stream","text":"Sensitivity :  0.907608695652174\nSpecificity :  0.9937106918238994\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred_class = model.predict(test_data, verbose=1)\n\ny_pred_class = [np.argmax(r) for r in y_pred_class]\ntest_y = [np.argmax(r) for r in test_labels]\n\n\nfrom sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n\n# Precision\nprint('Precision = ', precision_score(test_y, y_pred_class, average='weighted'))\n# (None, 'micro', 'macro', 'weighted', 'samples')\n\n# Recall\nprint('Recall = ', recall_score(test_y, y_pred_class, average='weighted'))\n\n# f1_score\nprint('f1_score = ', f1_score(test_y, y_pred_class, average='weighted'))","execution_count":37,"outputs":[{"output_type":"stream","text":"343/343 [==============================] - 0s 104us/step\nPrecision =  0.9515382855357074\nRecall =  0.9475218658892128\nf1_score =  0.9474575894593005\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelBinarizer\n\ndef multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n    label_binarizer = LabelBinarizer()\n    label_binarizer.fit(y_test)\n\n    truth = label_binarizer.transform(y_test)\n    pred = label_binarizer.transform(y_pred)\n    return roc_auc_score(truth, pred, average=average)\n# roc_auc_score\nprint('roc_auc_score = ', multiclass_roc_auc_score(test_y, y_pred_class))","execution_count":38,"outputs":[{"output_type":"stream","text":"roc_auc_score =  0.948452380952381\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score, classification_report\n\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import KFold, train_test_split\nfrom sklearn.model_selection import cross_val_score\n\n\nk_fold = KFold(n_splits=10, shuffle=True, random_state=5)","execution_count":39,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_test = np.asarray(test_labels)\ny_test = np.argmax(y_test, axis=1)\n\ny_train = np.asarray(train_labels)\ny_train = np.argmax(y_train, axis=1)","execution_count":40,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"**BaggingClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":41,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9717620481927711\nTest accuracy 0.9591836734693877\nAdaBoost Classifier test accuracies 0.9592\n              precision    recall  f1-score   support\n\n           0       0.95      0.96      0.96       168\n           1       0.97      0.95      0.96       175\n\n    accuracy                           0.96       343\n   macro avg       0.96      0.96      0.96       343\nweighted avg       0.96      0.96      0.96       343\n\n0.9591836734693877\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**BaggingClassifier - KFold:10**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\nscoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"BaggingClassifier - Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":42,"outputs":[{"output_type":"stream","text":"Scores Mean: 93.2689 and (STDEV 0.0323)\nBest result for fold 0\nBest accuracy is 1.0\nScores of all folds: [1.         0.97142857 0.91428571 0.94117647 0.88235294 0.91176471\n 0.91176471 0.94117647 0.94117647 0.91176471]\nBaggingClassifier - Test Accuracy on all folds: 0.93 (+/- 0.06)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**AdaBoostClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 300 )\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":43,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9996234939759037\nTest accuracy 0.9329446064139941\nAdaBoost Classifier test accuracies 0.9329\n              precision    recall  f1-score   support\n\n           0       0.92      0.94      0.93       168\n           1       0.94      0.93      0.93       175\n\n    accuracy                           0.93       343\n   macro avg       0.93      0.93      0.93       343\nweighted avg       0.93      0.93      0.93       343\n\n0.9329446064139941\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**AdaBoostClassifier - KFold:10**"},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"(AdaBoost Classifier) Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":44,"outputs":[{"output_type":"stream","text":"Scores Mean: 91.8151 and (STDEV 0.0572)\nBest result for fold 1\nBest accuracy is 0.9714285714285714\nScores of all folds: [0.91428571 0.97142857 0.94285714 0.88235294 0.76470588 0.94117647\n 0.97058824 0.94117647 0.91176471 0.94117647]\n(AdaBoost Classifier) Test Accuracy on all folds: 0.92 (+/- 0.11)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**XGBClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = xgb.XGBClassifier()\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('XGB Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":45,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9789156626506024\nTest accuracy 0.9591836734693877\nXGB Classifier test accuracies 0.9592\n              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96       168\n           1       0.97      0.95      0.96       175\n\n    accuracy                           0.96       343\n   macro avg       0.96      0.96      0.96       343\nweighted avg       0.96      0.96      0.96       343\n\n0.9591836734693877\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**XGBClassifier - KFold: 10**"},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"XGB - Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":46,"outputs":[{"output_type":"stream","text":"Scores Mean: 94.4370 and (STDEV 0.0515)\nBest result for fold 0\nBest accuracy is 1.0\nScores of all folds: [1.         1.         0.91428571 0.91176471 0.82352941 0.97058824\n 0.97058824 0.91176471 0.97058824 0.97058824]\nXGB - Test Accuracy on all folds: 0.94 (+/- 0.10)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**DecisionTreeClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = DecisionTreeClassifier()\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('DecisionTree Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":47,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9996234939759037\nTest accuracy 0.8979591836734694\nDecisionTree Classifier test accuracies 0.8980\n              precision    recall  f1-score   support\n\n           0       0.88      0.92      0.90       168\n           1       0.92      0.87      0.90       175\n\n    accuracy                           0.90       343\n   macro avg       0.90      0.90      0.90       343\nweighted avg       0.90      0.90      0.90       343\n\n0.8979591836734694\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**DecisionTreeClassifier - KFold: 10**"},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"DecisionTree - Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":48,"outputs":[{"output_type":"stream","text":"Scores Mean: 89.7731 and (STDEV 0.0404)\nBest result for fold 1\nBest accuracy is 0.9428571428571428\nScores of all folds: [0.91428571 0.94285714 0.91428571 0.88235294 0.79411765 0.88235294\n 0.94117647 0.91176471 0.88235294 0.91176471]\nDecisionTree - Test Accuracy on all folds: 0.90 (+/- 0.08)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**RandomForestClassifier**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=5)\nclf.fit(train_data, y_train)\nprint(\"Train accuracy\", clf.score(train_data, y_train))\nprint(\"Test accuracy\", clf.score(test_data, y_test))\n\ny_test_pred = clf.predict(test_data)\nclf_test = accuracy_score(y_test, y_test_pred)\nprint('RandomForest Classifier test accuracies %.4f' % (clf_test))\n\nprint(classification_report(y_test, y_test_pred))\n\n# print(confusion_matrix(test_labels, y_test_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":49,"outputs":[{"output_type":"stream","text":"Train accuracy 0.9890813253012049\nTest accuracy 0.9329446064139941\nRandomForest Classifier test accuracies 0.9329\n              precision    recall  f1-score   support\n\n           0       0.91      0.95      0.93       168\n           1       0.95      0.91      0.93       175\n\n    accuracy                           0.93       343\n   macro avg       0.93      0.93      0.93       343\nweighted avg       0.93      0.93      0.93       343\n\n0.9329446064139941\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**RandomForestClassifier - KFold: 10**"},{"metadata":{"trusted":true},"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=5)\nscoring = 'accuracy'\nscores = cross_val_score(clf, test_data, test_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"(RandomForest) Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":50,"outputs":[{"output_type":"stream","text":"Scores Mean: 90.3697 and (STDEV 0.0418)\nBest result for fold 6\nBest accuracy is 0.9705882352941176\nScores of all folds: [0.94285714 0.88571429 0.91428571 0.91176471 0.82352941 0.91176471\n 0.97058824 0.94117647 0.88235294 0.85294118]\n(RandomForest) Test Accuracy on all folds: 0.90 (+/- 0.08)\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**LightGBM**"},{"metadata":{"trusted":true},"cell_type":"code","source":"import lightgbm as lgb\n\nlgbm=lgb.LGBMClassifier(n_estimators=1000, class_weight=\"balanced\", reg_alpha=0.1, reg_lambda=0.1, learning_rate=0.001, num_leaves=400,\n                        random_state=523, boosting='dart')\n\nlgbm_scores=cross_val_score(lgbm,train_data, y_train, cv=10)\nprint(lgbm_scores)\nprint(\"Train accuracy mean and std %.2f\" %np.mean(lgbm_scores),\"+/- %.2f\"%np.std(lgbm_scores))","execution_count":51,"outputs":[{"output_type":"stream","text":"[0.93258427 0.92883895 0.94360902 0.94736842 0.94716981 0.9245283\n 0.96981132 0.92830189 0.92830189 0.73584906]\nTrain accuracy mean and std 0.92 +/- 0.06\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm.fit(train_data, y_train)\ny_pred=lgbm.predict(test_data)\nprint(classification_report(y_test, y_pred))\nprint(accuracy_score(y_test, y_test_pred))","execution_count":56,"outputs":[{"output_type":"stream","text":"              precision    recall  f1-score   support\n\n           0       0.95      0.97      0.96       168\n           1       0.97      0.95      0.96       175\n\n    accuracy                           0.96       343\n   macro avg       0.96      0.96      0.96       343\nweighted avg       0.96      0.96      0.96       343\n\n0.9329446064139941\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"**LightGBM - KFold: 10**"},{"metadata":{"trusted":true},"cell_type":"code","source":"lgbm_scores=cross_val_score(lgbm,test_data, y_test, cv=10)\nprint(lgbm_scores)\nprint(\"(LighGBM) Test accuracy on all folds mean and std %.2f\" %np.mean(lgbm_scores),\"+/- %.2f\"%np.std(lgbm_scores))","execution_count":53,"outputs":[{"output_type":"stream","text":"[0.91428571 1.         0.85714286 0.91428571 0.97142857 0.94117647\n 0.94117647 0.94117647 0.87878788 0.90909091]\n(LighGBM) Test accuracy on all folds mean and std 0.93 +/- 0.04\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"scoring = 'accuracy'\nscores = cross_val_score(lgbm, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n\nprint (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\nprint (\"Best result for fold %s\" % np.argmax(scores))\nprint (\"Best accuracy is\", (scores[np.argmax(scores)]))\nprint (\"Scores of all folds:\", scores)\nprint(\"(LighGBM) Test Accuracy on all folds: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))","execution_count":54,"outputs":[{"output_type":"stream","text":"Scores Mean: 92.9916 and (STDEV 0.0577)\nBest result for fold 8\nBest accuracy is 1.0\nScores of all folds: [0.94285714 0.97142857 0.91428571 0.85294118 0.82352941 0.88235294\n 0.97058824 0.94117647 1.         1.        ]\n(LighGBM) Test Accuracy on all folds: 0.93 (+/- 0.12)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"plt.rcParams.update({'font.size': 12})\n\nimport seaborn\nplt.style.use('seaborn-white')\n\nplt.figure()\nN = epochs\nplt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\nplt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss/Accuracy\")\nplt.legend(loc=\"center right\")","execution_count":55,"outputs":[{"output_type":"execute_result","execution_count":55,"data":{"text/plain":"<matplotlib.legend.Legend at 0x7f06ad91b400>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.5"}},"nbformat":4,"nbformat_minor":1}