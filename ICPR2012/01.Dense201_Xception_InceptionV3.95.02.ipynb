{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "np.random.seed(777)\n",
    "import math\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import h5py\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.optimizers import Adam, SGD, RMSprop\n",
    "from keras.models import Sequential\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Activation, merge, Dense, Flatten, Dropout, concatenate\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import BatchNormalization, add, GlobalAveragePooling2D\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score\n",
    "from keras.regularizers import l2\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications.mobilenet import MobileNet\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications import DenseNet121\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "from keras.layers import Input, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, Lambda,Concatenate\n",
    "from keras.layers import SeparableConv2D, AveragePooling2D, MaxPooling2D, Dropout, GlobalMaxPooling2D, GlobalAveragePooling2D, Add\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "test_dir = \"data/test/\"\n",
    "\n",
    "os.mkdir(\"extracted_features\")\n",
    "extracted_features_dir = \"extracted_features/\"\n",
    "model_name = \"Dense201_Xception_Inceptionv3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.10.0\n",
      "dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "img_height, img_width = 128, 128\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for root,dirs,files in os.walk(train_dir):\n",
    "#     print (root, len(files))\n",
    "\n",
    "# print(\"*\"*30)\n",
    "# for root,dirs,files in os.walk(test_dir):\n",
    "#     print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    # Zero-center by imagenet mean pixel\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 319152 images belonging to 6 classes.\n",
      "Found 79784 images belonging to 6 classes.\n",
      "Found 13578 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    preprocessing_function = preprocess_input,\n",
    "    validation_split= 0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'training',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'validation',\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 319152\n",
      "nb_validation_samples: 79784\n",
      "nb_test_samples: 13578\n",
      "\n",
      "predict_size_train: 624\n",
      "predict_size_validation: 156\n",
      "predict_size_test: 27\n",
      "\n",
      " num_classes: 6\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "nb_test_samples = len(test_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)\n",
    "\n",
    "print(\"\\n num_classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.backend.tensorflow_backend import get_session\n",
    "# from keras.backend.tensorflow_backend import clear_session\n",
    "# from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "# def reset_keras_tf_session():\n",
    "#     \"\"\"\n",
    "#     this function clears the gpu memory and set the \n",
    "#     tf session to not use the whole gpu\n",
    "#     \"\"\"\n",
    "#     sess = get_session()\n",
    "#     clear_session()\n",
    "#     sess.close()\n",
    "#     sess = get_session()\n",
    "\n",
    "# #     config = tf.ConfigProto()\n",
    "# #     config.gpu_options.allow_growth = True\n",
    "# #     set_session(tf.Session(config=config))\n",
    "\n",
    "\n",
    "# reset_keras_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications import DenseNet201\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "\n",
    "input_tensor = Input(shape = input_shape)  \n",
    "\n",
    "base_model1=DenseNet201(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "base_model2=Xception(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "base_model3=InceptionV3(input_shape= input_shape,weights='imagenet', include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "x1 = base_model1.output\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "x3 = base_model3.output\n",
    "x3 = GlobalAveragePooling2D()(x3)\n",
    "\n",
    "merge = concatenate([x1, x2, x3])\n",
    "predictions = Dense(num_classes, activation='softmax')(merge)\n",
    "\n",
    "model = Model(inputs=input_tensor,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_1\n",
      "1 zero_padding2d_1\n",
      "2 conv1/conv\n",
      "3 conv1/bn\n",
      "4 conv1/relu\n",
      "5 zero_padding2d_2\n",
      "6 pool1\n",
      "7 conv2_block1_0_bn\n",
      "8 conv2_block1_0_relu\n",
      "9 conv2_block1_1_conv\n",
      "10 conv2_block1_1_bn\n",
      "11 conv2_block1_1_relu\n",
      "12 conv2_block1_2_conv\n",
      "13 conv2_block1_concat\n",
      "14 conv2_block2_0_bn\n",
      "15 conv2_block2_0_relu\n",
      "16 conv2_block2_1_conv\n",
      "17 conv2_block2_1_bn\n",
      "18 conv2_block2_1_relu\n",
      "19 conv2_block2_2_conv\n",
      "20 conv2_block2_concat\n",
      "21 conv2_block3_0_bn\n",
      "22 conv2_block3_0_relu\n",
      "23 conv2_block3_1_conv\n",
      "24 conv2_block3_1_bn\n",
      "25 conv2_block3_1_relu\n",
      "26 conv2_block3_2_conv\n",
      "27 conv2_block3_concat\n",
      "28 conv2_block4_0_bn\n",
      "29 conv2_block4_0_relu\n",
      "30 conv2_block4_1_conv\n",
      "31 conv2_block4_1_bn\n",
      "32 conv2_block4_1_relu\n",
      "33 conv2_block4_2_conv\n",
      "34 conv2_block4_concat\n",
      "35 conv2_block5_0_bn\n",
      "36 conv2_block5_0_relu\n",
      "37 conv2_block5_1_conv\n",
      "38 conv2_block5_1_bn\n",
      "39 conv2_block5_1_relu\n",
      "40 conv2_block5_2_conv\n",
      "41 conv2_block5_concat\n",
      "42 conv2_block6_0_bn\n",
      "43 conv2_block6_0_relu\n",
      "44 conv2_block6_1_conv\n",
      "45 conv2_block6_1_bn\n",
      "46 conv2_block6_1_relu\n",
      "47 conv2_block6_2_conv\n",
      "48 conv2_block6_concat\n",
      "49 pool2_bn\n",
      "50 pool2_relu\n",
      "51 pool2_conv\n",
      "52 pool2_pool\n",
      "53 conv3_block1_0_bn\n",
      "54 conv3_block1_0_relu\n",
      "55 conv3_block1_1_conv\n",
      "56 conv3_block1_1_bn\n",
      "57 conv3_block1_1_relu\n",
      "58 conv3_block1_2_conv\n",
      "59 conv3_block1_concat\n",
      "60 conv3_block2_0_bn\n",
      "61 conv3_block2_0_relu\n",
      "62 conv3_block2_1_conv\n",
      "63 conv3_block2_1_bn\n",
      "64 conv3_block2_1_relu\n",
      "65 conv3_block2_2_conv\n",
      "66 conv3_block2_concat\n",
      "67 conv3_block3_0_bn\n",
      "68 conv3_block3_0_relu\n",
      "69 conv3_block3_1_conv\n",
      "70 conv3_block3_1_bn\n",
      "71 conv3_block3_1_relu\n",
      "72 conv3_block3_2_conv\n",
      "73 conv3_block3_concat\n",
      "74 conv3_block4_0_bn\n",
      "75 conv3_block4_0_relu\n",
      "76 conv3_block4_1_conv\n",
      "77 conv3_block4_1_bn\n",
      "78 conv3_block4_1_relu\n",
      "79 conv3_block4_2_conv\n",
      "80 conv3_block4_concat\n",
      "81 conv3_block5_0_bn\n",
      "82 conv3_block5_0_relu\n",
      "83 conv3_block5_1_conv\n",
      "84 conv3_block5_1_bn\n",
      "85 conv3_block5_1_relu\n",
      "86 conv3_block5_2_conv\n",
      "87 conv3_block5_concat\n",
      "88 conv3_block6_0_bn\n",
      "89 conv3_block6_0_relu\n",
      "90 conv3_block6_1_conv\n",
      "91 conv3_block6_1_bn\n",
      "92 conv3_block6_1_relu\n",
      "93 conv3_block6_2_conv\n",
      "94 conv3_block6_concat\n",
      "95 conv3_block7_0_bn\n",
      "96 conv3_block7_0_relu\n",
      "97 conv3_block7_1_conv\n",
      "98 conv3_block7_1_bn\n",
      "99 conv3_block7_1_relu\n",
      "100 conv3_block7_2_conv\n",
      "101 conv3_block7_concat\n",
      "102 conv3_block8_0_bn\n",
      "103 conv3_block8_0_relu\n",
      "104 conv3_block8_1_conv\n",
      "105 conv3_block8_1_bn\n",
      "106 conv3_block8_1_relu\n",
      "107 conv3_block8_2_conv\n",
      "108 conv3_block8_concat\n",
      "109 conv3_block9_0_bn\n",
      "110 conv3_block9_0_relu\n",
      "111 conv3_block9_1_conv\n",
      "112 conv3_block9_1_bn\n",
      "113 conv3_block9_1_relu\n",
      "114 conv3_block9_2_conv\n",
      "115 conv3_block9_concat\n",
      "116 conv3_block10_0_bn\n",
      "117 conv3_block10_0_relu\n",
      "118 conv3_block10_1_conv\n",
      "119 conv3_block10_1_bn\n",
      "120 conv3_block10_1_relu\n",
      "121 conv3_block10_2_conv\n",
      "122 conv3_block10_concat\n",
      "123 conv3_block11_0_bn\n",
      "124 conv3_block11_0_relu\n",
      "125 conv3_block11_1_conv\n",
      "126 conv3_block11_1_bn\n",
      "127 conv3_block11_1_relu\n",
      "128 conv3_block11_2_conv\n",
      "129 conv3_block11_concat\n",
      "130 conv3_block12_0_bn\n",
      "131 conv3_block12_0_relu\n",
      "132 conv3_block12_1_conv\n",
      "133 conv3_block12_1_bn\n",
      "134 conv3_block12_1_relu\n",
      "135 conv3_block12_2_conv\n",
      "136 conv3_block12_concat\n",
      "137 pool3_bn\n",
      "138 pool3_relu\n",
      "139 pool3_conv\n",
      "140 pool3_pool\n",
      "141 conv4_block1_0_bn\n",
      "142 conv4_block1_0_relu\n",
      "143 conv4_block1_1_conv\n",
      "144 conv4_block1_1_bn\n",
      "145 conv4_block1_1_relu\n",
      "146 conv4_block1_2_conv\n",
      "147 conv4_block1_concat\n",
      "148 conv4_block2_0_bn\n",
      "149 conv4_block2_0_relu\n",
      "150 conv4_block2_1_conv\n",
      "151 conv4_block2_1_bn\n",
      "152 conv4_block2_1_relu\n",
      "153 conv4_block2_2_conv\n",
      "154 conv4_block2_concat\n",
      "155 conv4_block3_0_bn\n",
      "156 conv4_block3_0_relu\n",
      "157 conv4_block3_1_conv\n",
      "158 conv4_block3_1_bn\n",
      "159 conv4_block3_1_relu\n",
      "160 conv4_block3_2_conv\n",
      "161 conv4_block3_concat\n",
      "162 conv4_block4_0_bn\n",
      "163 conv4_block4_0_relu\n",
      "164 conv4_block4_1_conv\n",
      "165 conv4_block4_1_bn\n",
      "166 conv4_block4_1_relu\n",
      "167 conv4_block4_2_conv\n",
      "168 conv4_block4_concat\n",
      "169 conv4_block5_0_bn\n",
      "170 conv4_block5_0_relu\n",
      "171 conv4_block5_1_conv\n",
      "172 conv4_block5_1_bn\n",
      "173 conv4_block5_1_relu\n",
      "174 conv4_block5_2_conv\n",
      "175 conv4_block5_concat\n",
      "176 conv4_block6_0_bn\n",
      "177 conv4_block6_0_relu\n",
      "178 conv4_block6_1_conv\n",
      "179 conv4_block6_1_bn\n",
      "180 conv4_block6_1_relu\n",
      "181 conv4_block6_2_conv\n",
      "182 conv4_block6_concat\n",
      "183 conv4_block7_0_bn\n",
      "184 conv4_block7_0_relu\n",
      "185 conv4_block7_1_conv\n",
      "186 conv4_block7_1_bn\n",
      "187 conv4_block7_1_relu\n",
      "188 conv4_block7_2_conv\n",
      "189 conv4_block7_concat\n",
      "190 conv4_block8_0_bn\n",
      "191 conv4_block8_0_relu\n",
      "192 conv4_block8_1_conv\n",
      "193 conv4_block8_1_bn\n",
      "194 conv4_block8_1_relu\n",
      "195 conv4_block8_2_conv\n",
      "196 conv4_block8_concat\n",
      "197 conv4_block9_0_bn\n",
      "198 conv4_block9_0_relu\n",
      "199 conv4_block9_1_conv\n",
      "200 conv4_block9_1_bn\n",
      "201 conv4_block9_1_relu\n",
      "202 conv4_block9_2_conv\n",
      "203 conv4_block9_concat\n",
      "204 conv4_block10_0_bn\n",
      "205 conv4_block10_0_relu\n",
      "206 conv4_block10_1_conv\n",
      "207 conv4_block10_1_bn\n",
      "208 conv4_block10_1_relu\n",
      "209 conv4_block10_2_conv\n",
      "210 conv4_block10_concat\n",
      "211 conv4_block11_0_bn\n",
      "212 conv4_block11_0_relu\n",
      "213 conv4_block11_1_conv\n",
      "214 conv4_block11_1_bn\n",
      "215 conv4_block11_1_relu\n",
      "216 conv4_block11_2_conv\n",
      "217 conv4_block11_concat\n",
      "218 conv4_block12_0_bn\n",
      "219 conv4_block12_0_relu\n",
      "220 conv4_block12_1_conv\n",
      "221 conv4_block12_1_bn\n",
      "222 conv4_block12_1_relu\n",
      "223 conv4_block12_2_conv\n",
      "224 conv4_block12_concat\n",
      "225 conv4_block13_0_bn\n",
      "226 conv4_block13_0_relu\n",
      "227 conv4_block13_1_conv\n",
      "228 conv4_block13_1_bn\n",
      "229 conv4_block13_1_relu\n",
      "230 conv4_block13_2_conv\n",
      "231 conv4_block13_concat\n",
      "232 conv4_block14_0_bn\n",
      "233 conv4_block14_0_relu\n",
      "234 conv4_block14_1_conv\n",
      "235 conv4_block14_1_bn\n",
      "236 conv4_block14_1_relu\n",
      "237 conv4_block14_2_conv\n",
      "238 conv4_block14_concat\n",
      "239 conv4_block15_0_bn\n",
      "240 conv4_block15_0_relu\n",
      "241 conv4_block15_1_conv\n",
      "242 conv4_block15_1_bn\n",
      "243 conv4_block15_1_relu\n",
      "244 conv4_block15_2_conv\n",
      "245 conv4_block15_concat\n",
      "246 conv4_block16_0_bn\n",
      "247 conv4_block16_0_relu\n",
      "248 conv4_block16_1_conv\n",
      "249 conv4_block16_1_bn\n",
      "250 conv4_block16_1_relu\n",
      "251 conv4_block16_2_conv\n",
      "252 conv4_block16_concat\n",
      "253 conv4_block17_0_bn\n",
      "254 conv4_block17_0_relu\n",
      "255 conv4_block17_1_conv\n",
      "256 conv4_block17_1_bn\n",
      "257 conv4_block17_1_relu\n",
      "258 conv4_block17_2_conv\n",
      "259 conv4_block17_concat\n",
      "260 conv4_block18_0_bn\n",
      "261 conv4_block18_0_relu\n",
      "262 conv4_block18_1_conv\n",
      "263 conv4_block18_1_bn\n",
      "264 conv4_block18_1_relu\n",
      "265 conv4_block18_2_conv\n",
      "266 conv4_block18_concat\n",
      "267 conv4_block19_0_bn\n",
      "268 conv4_block19_0_relu\n",
      "269 conv4_block19_1_conv\n",
      "270 conv4_block19_1_bn\n",
      "271 conv4_block19_1_relu\n",
      "272 conv4_block19_2_conv\n",
      "273 conv4_block19_concat\n",
      "274 conv4_block20_0_bn\n",
      "275 conv4_block20_0_relu\n",
      "276 conv4_block20_1_conv\n",
      "277 conv4_block20_1_bn\n",
      "278 conv4_block20_1_relu\n",
      "279 conv4_block20_2_conv\n",
      "280 conv4_block20_concat\n",
      "281 conv4_block21_0_bn\n",
      "282 conv4_block21_0_relu\n",
      "283 conv4_block21_1_conv\n",
      "284 conv4_block21_1_bn\n",
      "285 conv4_block21_1_relu\n",
      "286 conv4_block21_2_conv\n",
      "287 conv4_block21_concat\n",
      "288 conv4_block22_0_bn\n",
      "289 conv4_block22_0_relu\n",
      "290 conv4_block22_1_conv\n",
      "291 conv4_block22_1_bn\n",
      "292 conv4_block22_1_relu\n",
      "293 conv4_block22_2_conv\n",
      "294 conv4_block22_concat\n",
      "295 conv4_block23_0_bn\n",
      "296 conv4_block23_0_relu\n",
      "297 conv4_block23_1_conv\n",
      "298 conv4_block23_1_bn\n",
      "299 conv4_block23_1_relu\n",
      "300 conv4_block23_2_conv\n",
      "301 conv4_block23_concat\n",
      "302 conv4_block24_0_bn\n",
      "303 conv4_block24_0_relu\n",
      "304 conv4_block24_1_conv\n",
      "305 conv4_block24_1_bn\n",
      "306 conv4_block24_1_relu\n",
      "307 conv4_block24_2_conv\n",
      "308 conv4_block24_concat\n",
      "309 conv4_block25_0_bn\n",
      "310 conv4_block25_0_relu\n",
      "311 conv4_block25_1_conv\n",
      "312 conv4_block25_1_bn\n",
      "313 conv4_block25_1_relu\n",
      "314 conv4_block25_2_conv\n",
      "315 conv4_block25_concat\n",
      "316 conv4_block26_0_bn\n",
      "317 conv4_block26_0_relu\n",
      "318 conv4_block26_1_conv\n",
      "319 conv4_block26_1_bn\n",
      "320 conv4_block26_1_relu\n",
      "321 conv4_block26_2_conv\n",
      "322 conv4_block26_concat\n",
      "323 conv4_block27_0_bn\n",
      "324 conv4_block27_0_relu\n",
      "325 conv4_block27_1_conv\n",
      "326 conv4_block27_1_bn\n",
      "327 conv4_block27_1_relu\n",
      "328 conv4_block27_2_conv\n",
      "329 conv4_block27_concat\n",
      "330 conv4_block28_0_bn\n",
      "331 conv4_block28_0_relu\n",
      "332 conv4_block28_1_conv\n",
      "333 conv4_block28_1_bn\n",
      "334 conv4_block28_1_relu\n",
      "335 conv4_block28_2_conv\n",
      "336 conv4_block28_concat\n",
      "337 conv4_block29_0_bn\n",
      "338 conv4_block29_0_relu\n",
      "339 conv4_block29_1_conv\n",
      "340 conv4_block29_1_bn\n",
      "341 conv4_block29_1_relu\n",
      "342 conv4_block29_2_conv\n",
      "343 conv4_block29_concat\n",
      "344 conv4_block30_0_bn\n",
      "345 conv4_block30_0_relu\n",
      "346 conv4_block30_1_conv\n",
      "347 conv4_block30_1_bn\n",
      "348 conv4_block30_1_relu\n",
      "349 conv4_block30_2_conv\n",
      "350 conv4_block30_concat\n",
      "351 conv4_block31_0_bn\n",
      "352 conv4_block31_0_relu\n",
      "353 conv4_block31_1_conv\n",
      "354 conv4_block31_1_bn\n",
      "355 conv4_block31_1_relu\n",
      "356 conv4_block31_2_conv\n",
      "357 conv4_block31_concat\n",
      "358 conv4_block32_0_bn\n",
      "359 conv4_block32_0_relu\n",
      "360 conv4_block32_1_conv\n",
      "361 conv4_block32_1_bn\n",
      "362 conv4_block32_1_relu\n",
      "363 conv4_block32_2_conv\n",
      "364 conv4_block32_concat\n",
      "365 conv4_block33_0_bn\n",
      "366 conv4_block33_0_relu\n",
      "367 conv4_block33_1_conv\n",
      "368 conv4_block33_1_bn\n",
      "369 conv4_block33_1_relu\n",
      "370 conv4_block33_2_conv\n",
      "371 conv4_block33_concat\n",
      "372 conv4_block34_0_bn\n",
      "373 conv4_block34_0_relu\n",
      "374 conv4_block34_1_conv\n",
      "375 conv4_block34_1_bn\n",
      "376 conv4_block34_1_relu\n",
      "377 conv4_block34_2_conv\n",
      "378 conv4_block34_concat\n",
      "379 conv4_block35_0_bn\n",
      "380 conv4_block35_0_relu\n",
      "381 conv4_block35_1_conv\n",
      "382 conv4_block35_1_bn\n",
      "383 conv4_block35_1_relu\n",
      "384 conv4_block35_2_conv\n",
      "385 conv4_block35_concat\n",
      "386 conv4_block36_0_bn\n",
      "387 conv4_block36_0_relu\n",
      "388 conv4_block36_1_conv\n",
      "389 conv4_block36_1_bn\n",
      "390 conv4_block36_1_relu\n",
      "391 conv4_block36_2_conv\n",
      "392 conv4_block36_concat\n",
      "393 conv4_block37_0_bn\n",
      "394 conv4_block37_0_relu\n",
      "395 conv4_block37_1_conv\n",
      "396 conv4_block37_1_bn\n",
      "397 conv4_block37_1_relu\n",
      "398 conv4_block37_2_conv\n",
      "399 conv4_block37_concat\n",
      "400 conv4_block38_0_bn\n",
      "401 conv4_block38_0_relu\n",
      "402 conv4_block38_1_conv\n",
      "403 conv4_block38_1_bn\n",
      "404 conv4_block38_1_relu\n",
      "405 conv4_block38_2_conv\n",
      "406 conv4_block38_concat\n",
      "407 conv4_block39_0_bn\n",
      "408 conv4_block39_0_relu\n",
      "409 conv4_block39_1_conv\n",
      "410 conv4_block39_1_bn\n",
      "411 conv4_block39_1_relu\n",
      "412 conv4_block39_2_conv\n",
      "413 conv4_block39_concat\n",
      "414 conv4_block40_0_bn\n",
      "415 conv4_block40_0_relu\n",
      "416 conv4_block40_1_conv\n",
      "417 conv4_block40_1_bn\n",
      "418 conv4_block40_1_relu\n",
      "419 conv4_block40_2_conv\n",
      "420 conv4_block40_concat\n",
      "421 conv4_block41_0_bn\n",
      "422 conv4_block41_0_relu\n",
      "423 conv4_block41_1_conv\n",
      "424 conv4_block41_1_bn\n",
      "425 conv4_block41_1_relu\n",
      "426 conv4_block41_2_conv\n",
      "427 conv4_block41_concat\n",
      "428 conv4_block42_0_bn\n",
      "429 conv4_block42_0_relu\n",
      "430 conv4_block42_1_conv\n",
      "431 conv4_block42_1_bn\n",
      "432 conv4_block42_1_relu\n",
      "433 conv4_block42_2_conv\n",
      "434 conv4_block42_concat\n",
      "435 conv4_block43_0_bn\n",
      "436 conv4_block43_0_relu\n",
      "437 conv4_block43_1_conv\n",
      "438 conv4_block43_1_bn\n",
      "439 conv4_block43_1_relu\n",
      "440 conv4_block43_2_conv\n",
      "441 conv4_block43_concat\n",
      "442 conv4_block44_0_bn\n",
      "443 conv4_block44_0_relu\n",
      "444 conv4_block44_1_conv\n",
      "445 conv4_block44_1_bn\n",
      "446 conv4_block44_1_relu\n",
      "447 conv4_block44_2_conv\n",
      "448 conv4_block44_concat\n",
      "449 conv4_block45_0_bn\n",
      "450 conv4_block45_0_relu\n",
      "451 conv4_block45_1_conv\n",
      "452 conv4_block45_1_bn\n",
      "453 conv4_block45_1_relu\n",
      "454 conv4_block45_2_conv\n",
      "455 conv4_block45_concat\n",
      "456 conv4_block46_0_bn\n",
      "457 conv4_block46_0_relu\n",
      "458 conv4_block46_1_conv\n",
      "459 conv4_block46_1_bn\n",
      "460 conv4_block46_1_relu\n",
      "461 conv4_block46_2_conv\n",
      "462 conv4_block46_concat\n",
      "463 conv4_block47_0_bn\n",
      "464 conv4_block47_0_relu\n",
      "465 conv4_block47_1_conv\n",
      "466 conv4_block47_1_bn\n",
      "467 conv4_block47_1_relu\n",
      "468 conv4_block47_2_conv\n",
      "469 conv4_block47_concat\n",
      "470 conv4_block48_0_bn\n",
      "471 conv4_block48_0_relu\n",
      "472 conv4_block48_1_conv\n",
      "473 conv4_block48_1_bn\n",
      "474 conv4_block48_1_relu\n",
      "475 conv4_block48_2_conv\n",
      "476 conv4_block48_concat\n",
      "477 pool4_bn\n",
      "478 pool4_relu\n",
      "479 pool4_conv\n",
      "480 pool4_pool\n",
      "481 conv5_block1_0_bn\n",
      "482 conv5_block1_0_relu\n",
      "483 conv5_block1_1_conv\n",
      "484 conv5_block1_1_bn\n",
      "485 conv5_block1_1_relu\n",
      "486 conv5_block1_2_conv\n",
      "487 conv5_block1_concat\n",
      "488 conv5_block2_0_bn\n",
      "489 conv5_block2_0_relu\n",
      "490 conv5_block2_1_conv\n",
      "491 conv5_block2_1_bn\n",
      "492 conv5_block2_1_relu\n",
      "493 conv5_block2_2_conv\n",
      "494 conv5_block2_concat\n",
      "495 conv5_block3_0_bn\n",
      "496 conv5_block3_0_relu\n",
      "497 conv5_block3_1_conv\n",
      "498 conv5_block3_1_bn\n",
      "499 conv5_block3_1_relu\n",
      "500 conv5_block3_2_conv\n",
      "501 conv5_block3_concat\n",
      "502 conv5_block4_0_bn\n",
      "503 conv5_block4_0_relu\n",
      "504 conv5_block4_1_conv\n",
      "505 conv5_block4_1_bn\n",
      "506 conv5_block4_1_relu\n",
      "507 conv5_block4_2_conv\n",
      "508 conv5_block4_concat\n",
      "509 conv5_block5_0_bn\n",
      "510 conv5_block5_0_relu\n",
      "511 conv5_block5_1_conv\n",
      "512 conv5_block5_1_bn\n",
      "513 conv5_block5_1_relu\n",
      "514 conv5_block5_2_conv\n",
      "515 conv5_block5_concat\n",
      "516 conv5_block6_0_bn\n",
      "517 conv5_block6_0_relu\n",
      "518 conv5_block6_1_conv\n",
      "519 conv5_block6_1_bn\n",
      "520 conv5_block6_1_relu\n",
      "521 conv5_block6_2_conv\n",
      "522 conv5_block6_concat\n",
      "523 conv5_block7_0_bn\n",
      "524 conv5_block7_0_relu\n",
      "525 conv5_block7_1_conv\n",
      "526 conv5_block7_1_bn\n",
      "527 conv5_block7_1_relu\n",
      "528 conv5_block7_2_conv\n",
      "529 conv5_block7_concat\n",
      "530 conv5_block8_0_bn\n",
      "531 conv5_block8_0_relu\n",
      "532 conv5_block8_1_conv\n",
      "533 conv5_block8_1_bn\n",
      "534 conv5_block8_1_relu\n",
      "535 conv5_block8_2_conv\n",
      "536 conv5_block8_concat\n",
      "537 conv5_block9_0_bn\n",
      "538 conv5_block9_0_relu\n",
      "539 conv5_block9_1_conv\n",
      "540 conv5_block9_1_bn\n",
      "541 conv5_block9_1_relu\n",
      "542 conv5_block9_2_conv\n",
      "543 conv5_block9_concat\n",
      "544 conv5_block10_0_bn\n",
      "545 conv5_block10_0_relu\n",
      "546 conv5_block10_1_conv\n",
      "547 conv5_block10_1_bn\n",
      "548 conv5_block10_1_relu\n",
      "549 conv5_block10_2_conv\n",
      "550 conv5_block10_concat\n",
      "551 conv5_block11_0_bn\n",
      "552 conv2d_5\n",
      "553 conv5_block11_0_relu\n",
      "554 batch_normalization_5\n",
      "555 conv5_block11_1_conv\n",
      "556 activation_1\n",
      "557 conv5_block11_1_bn\n",
      "558 conv2d_6\n",
      "559 conv5_block11_1_relu\n",
      "560 batch_normalization_6\n",
      "561 conv5_block11_2_conv\n",
      "562 activation_2\n",
      "563 conv5_block11_concat\n",
      "564 conv2d_7\n",
      "565 conv5_block12_0_bn\n",
      "566 batch_normalization_7\n",
      "567 conv5_block12_0_relu\n",
      "568 activation_3\n",
      "569 conv5_block12_1_conv\n",
      "570 max_pooling2d_1\n",
      "571 conv5_block12_1_bn\n",
      "572 conv2d_8\n",
      "573 conv5_block12_1_relu\n",
      "574 batch_normalization_8\n",
      "575 conv5_block12_2_conv\n",
      "576 activation_4\n",
      "577 conv5_block12_concat\n",
      "578 conv2d_9\n",
      "579 conv5_block13_0_bn\n",
      "580 batch_normalization_9\n",
      "581 conv5_block13_0_relu\n",
      "582 activation_5\n",
      "583 conv5_block13_1_conv\n",
      "584 max_pooling2d_2\n",
      "585 conv5_block13_1_bn\n",
      "586 conv2d_13\n",
      "587 conv5_block13_1_relu\n",
      "588 batch_normalization_13\n",
      "589 conv5_block13_2_conv\n",
      "590 activation_9\n",
      "591 conv5_block13_concat\n",
      "592 conv2d_11\n",
      "593 conv2d_14\n",
      "594 conv5_block14_0_bn\n",
      "595 batch_normalization_11\n",
      "596 batch_normalization_14\n",
      "597 conv5_block14_0_relu\n",
      "598 activation_7\n",
      "599 activation_10\n",
      "600 average_pooling2d_1\n",
      "601 conv5_block14_1_conv\n",
      "602 conv2d_10\n",
      "603 conv2d_12\n",
      "604 conv2d_15\n",
      "605 conv2d_16\n",
      "606 conv5_block14_1_bn\n",
      "607 batch_normalization_10\n",
      "608 batch_normalization_12\n",
      "609 batch_normalization_15\n",
      "610 batch_normalization_16\n",
      "611 conv5_block14_1_relu\n",
      "612 activation_6\n",
      "613 activation_8\n",
      "614 activation_11\n",
      "615 activation_12\n",
      "616 conv5_block14_2_conv\n",
      "617 mixed0\n",
      "618 conv5_block14_concat\n",
      "619 conv2d_20\n",
      "620 conv5_block15_0_bn\n",
      "621 batch_normalization_20\n",
      "622 conv5_block15_0_relu\n",
      "623 activation_16\n",
      "624 conv5_block15_1_conv\n",
      "625 conv2d_18\n",
      "626 conv2d_21\n",
      "627 conv5_block15_1_bn\n",
      "628 batch_normalization_18\n",
      "629 batch_normalization_21\n",
      "630 conv5_block15_1_relu\n",
      "631 activation_14\n",
      "632 activation_17\n",
      "633 average_pooling2d_2\n",
      "634 conv5_block15_2_conv\n",
      "635 block1_conv1\n",
      "636 conv2d_17\n",
      "637 conv2d_19\n",
      "638 conv2d_22\n",
      "639 conv2d_23\n",
      "640 conv5_block15_concat\n",
      "641 block1_conv1_bn\n",
      "642 batch_normalization_17\n",
      "643 batch_normalization_19\n",
      "644 batch_normalization_22\n",
      "645 batch_normalization_23\n",
      "646 conv5_block16_0_bn\n",
      "647 block1_conv1_act\n",
      "648 activation_13\n",
      "649 activation_15\n",
      "650 activation_18\n",
      "651 activation_19\n",
      "652 conv5_block16_0_relu\n",
      "653 block1_conv2\n",
      "654 mixed1\n",
      "655 conv5_block16_1_conv\n",
      "656 block1_conv2_bn\n",
      "657 conv2d_27\n",
      "658 conv5_block16_1_bn\n",
      "659 block1_conv2_act\n",
      "660 batch_normalization_27\n",
      "661 conv5_block16_1_relu\n",
      "662 block2_sepconv1\n",
      "663 activation_23\n",
      "664 conv5_block16_2_conv\n",
      "665 block2_sepconv1_bn\n",
      "666 conv2d_25\n",
      "667 conv2d_28\n",
      "668 conv5_block16_concat\n",
      "669 block2_sepconv2_act\n",
      "670 batch_normalization_25\n",
      "671 batch_normalization_28\n",
      "672 conv5_block17_0_bn\n",
      "673 block2_sepconv2\n",
      "674 activation_21\n",
      "675 activation_24\n",
      "676 average_pooling2d_3\n",
      "677 conv5_block17_0_relu\n",
      "678 block2_sepconv2_bn\n",
      "679 conv2d_1\n",
      "680 conv2d_24\n",
      "681 conv2d_26\n",
      "682 conv2d_29\n",
      "683 conv2d_30\n",
      "684 conv5_block17_1_conv\n",
      "685 block2_pool\n",
      "686 batch_normalization_1\n",
      "687 batch_normalization_24\n",
      "688 batch_normalization_26\n",
      "689 batch_normalization_29\n",
      "690 batch_normalization_30\n",
      "691 conv5_block17_1_bn\n",
      "692 add_1\n",
      "693 activation_20\n",
      "694 activation_22\n",
      "695 activation_25\n",
      "696 activation_26\n",
      "697 conv5_block17_1_relu\n",
      "698 block3_sepconv1_act\n",
      "699 mixed2\n",
      "700 conv5_block17_2_conv\n",
      "701 block3_sepconv1\n",
      "702 conv2d_32\n",
      "703 conv5_block17_concat\n",
      "704 block3_sepconv1_bn\n",
      "705 batch_normalization_32\n",
      "706 conv5_block18_0_bn\n",
      "707 block3_sepconv2_act\n",
      "708 activation_28\n",
      "709 conv5_block18_0_relu\n",
      "710 block3_sepconv2\n",
      "711 conv2d_33\n",
      "712 conv5_block18_1_conv\n",
      "713 block3_sepconv2_bn\n",
      "714 conv2d_2\n",
      "715 batch_normalization_33\n",
      "716 conv5_block18_1_bn\n",
      "717 block3_pool\n",
      "718 batch_normalization_2\n",
      "719 activation_29\n",
      "720 conv5_block18_1_relu\n",
      "721 add_2\n",
      "722 conv2d_31\n",
      "723 conv2d_34\n",
      "724 conv5_block18_2_conv\n",
      "725 block4_sepconv1_act\n",
      "726 batch_normalization_31\n",
      "727 batch_normalization_34\n",
      "728 conv5_block18_concat\n",
      "729 block4_sepconv1\n",
      "730 activation_27\n",
      "731 activation_30\n",
      "732 max_pooling2d_3\n",
      "733 conv5_block19_0_bn\n",
      "734 block4_sepconv1_bn\n",
      "735 mixed3\n",
      "736 conv5_block19_0_relu\n",
      "737 block4_sepconv2_act\n",
      "738 conv2d_39\n",
      "739 conv5_block19_1_conv\n",
      "740 block4_sepconv2\n",
      "741 batch_normalization_39\n",
      "742 conv5_block19_1_bn\n",
      "743 block4_sepconv2_bn\n",
      "744 conv2d_3\n",
      "745 activation_35\n",
      "746 conv5_block19_1_relu\n",
      "747 block4_pool\n",
      "748 batch_normalization_3\n",
      "749 conv2d_40\n",
      "750 conv5_block19_2_conv\n",
      "751 add_3\n",
      "752 batch_normalization_40\n",
      "753 conv5_block19_concat\n",
      "754 block5_sepconv1_act\n",
      "755 activation_36\n",
      "756 conv5_block20_0_bn\n",
      "757 block5_sepconv1\n",
      "758 conv2d_36\n",
      "759 conv2d_41\n",
      "760 conv5_block20_0_relu\n",
      "761 block5_sepconv1_bn\n",
      "762 batch_normalization_36\n",
      "763 batch_normalization_41\n",
      "764 conv5_block20_1_conv\n",
      "765 block5_sepconv2_act\n",
      "766 activation_32\n",
      "767 activation_37\n",
      "768 conv5_block20_1_bn\n",
      "769 block5_sepconv2\n",
      "770 conv2d_37\n",
      "771 conv2d_42\n",
      "772 conv5_block20_1_relu\n",
      "773 block5_sepconv2_bn\n",
      "774 batch_normalization_37\n",
      "775 batch_normalization_42\n",
      "776 conv5_block20_2_conv\n",
      "777 block5_sepconv3_act\n",
      "778 activation_33\n",
      "779 activation_38\n",
      "780 average_pooling2d_4\n",
      "781 conv5_block20_concat\n",
      "782 block5_sepconv3\n",
      "783 conv2d_35\n",
      "784 conv2d_38\n",
      "785 conv2d_43\n",
      "786 conv2d_44\n",
      "787 conv5_block21_0_bn\n",
      "788 block5_sepconv3_bn\n",
      "789 batch_normalization_35\n",
      "790 batch_normalization_38\n",
      "791 batch_normalization_43\n",
      "792 batch_normalization_44\n",
      "793 conv5_block21_0_relu\n",
      "794 add_4\n",
      "795 activation_31\n",
      "796 activation_34\n",
      "797 activation_39\n",
      "798 activation_40\n",
      "799 conv5_block21_1_conv\n",
      "800 block6_sepconv1_act\n",
      "801 mixed4\n",
      "802 conv5_block21_1_bn\n",
      "803 block6_sepconv1\n",
      "804 conv2d_49\n",
      "805 conv5_block21_1_relu\n",
      "806 block6_sepconv1_bn\n",
      "807 batch_normalization_49\n",
      "808 conv5_block21_2_conv\n",
      "809 block6_sepconv2_act\n",
      "810 activation_45\n",
      "811 conv5_block21_concat\n",
      "812 block6_sepconv2\n",
      "813 conv2d_50\n",
      "814 conv5_block22_0_bn\n",
      "815 block6_sepconv2_bn\n",
      "816 batch_normalization_50\n",
      "817 conv5_block22_0_relu\n",
      "818 block6_sepconv3_act\n",
      "819 activation_46\n",
      "820 conv5_block22_1_conv\n",
      "821 block6_sepconv3\n",
      "822 conv2d_46\n",
      "823 conv2d_51\n",
      "824 conv5_block22_1_bn\n",
      "825 block6_sepconv3_bn\n",
      "826 batch_normalization_46\n",
      "827 batch_normalization_51\n",
      "828 conv5_block22_1_relu\n",
      "829 add_5\n",
      "830 activation_42\n",
      "831 activation_47\n",
      "832 conv5_block22_2_conv\n",
      "833 block7_sepconv1_act\n",
      "834 conv2d_47\n",
      "835 conv2d_52\n",
      "836 conv5_block22_concat\n",
      "837 block7_sepconv1\n",
      "838 batch_normalization_47\n",
      "839 batch_normalization_52\n",
      "840 conv5_block23_0_bn\n",
      "841 block7_sepconv1_bn\n",
      "842 activation_43\n",
      "843 activation_48\n",
      "844 average_pooling2d_5\n",
      "845 conv5_block23_0_relu\n",
      "846 block7_sepconv2_act\n",
      "847 conv2d_45\n",
      "848 conv2d_48\n",
      "849 conv2d_53\n",
      "850 conv2d_54\n",
      "851 conv5_block23_1_conv\n",
      "852 block7_sepconv2\n",
      "853 batch_normalization_45\n",
      "854 batch_normalization_48\n",
      "855 batch_normalization_53\n",
      "856 batch_normalization_54\n",
      "857 conv5_block23_1_bn\n",
      "858 block7_sepconv2_bn\n",
      "859 activation_41\n",
      "860 activation_44\n",
      "861 activation_49\n",
      "862 activation_50\n",
      "863 conv5_block23_1_relu\n",
      "864 block7_sepconv3_act\n",
      "865 mixed5\n",
      "866 conv5_block23_2_conv\n",
      "867 block7_sepconv3\n",
      "868 conv2d_59\n",
      "869 conv5_block23_concat\n",
      "870 block7_sepconv3_bn\n",
      "871 batch_normalization_59\n",
      "872 conv5_block24_0_bn\n",
      "873 add_6\n",
      "874 activation_55\n",
      "875 conv5_block24_0_relu\n",
      "876 block8_sepconv1_act\n",
      "877 conv2d_60\n",
      "878 conv5_block24_1_conv\n",
      "879 block8_sepconv1\n",
      "880 batch_normalization_60\n",
      "881 conv5_block24_1_bn\n",
      "882 block8_sepconv1_bn\n",
      "883 activation_56\n",
      "884 conv5_block24_1_relu\n",
      "885 block8_sepconv2_act\n",
      "886 conv2d_56\n",
      "887 conv2d_61\n",
      "888 conv5_block24_2_conv\n",
      "889 block8_sepconv2\n",
      "890 batch_normalization_56\n",
      "891 batch_normalization_61\n",
      "892 conv5_block24_concat\n",
      "893 block8_sepconv2_bn\n",
      "894 activation_52\n",
      "895 activation_57\n",
      "896 conv5_block25_0_bn\n",
      "897 block8_sepconv3_act\n",
      "898 conv2d_57\n",
      "899 conv2d_62\n",
      "900 conv5_block25_0_relu\n",
      "901 block8_sepconv3\n",
      "902 batch_normalization_57\n",
      "903 batch_normalization_62\n",
      "904 conv5_block25_1_conv\n",
      "905 block8_sepconv3_bn\n",
      "906 activation_53\n",
      "907 activation_58\n",
      "908 average_pooling2d_6\n",
      "909 conv5_block25_1_bn\n",
      "910 add_7\n",
      "911 conv2d_55\n",
      "912 conv2d_58\n",
      "913 conv2d_63\n",
      "914 conv2d_64\n",
      "915 conv5_block25_1_relu\n",
      "916 block9_sepconv1_act\n",
      "917 batch_normalization_55\n",
      "918 batch_normalization_58\n",
      "919 batch_normalization_63\n",
      "920 batch_normalization_64\n",
      "921 conv5_block25_2_conv\n",
      "922 block9_sepconv1\n",
      "923 activation_51\n",
      "924 activation_54\n",
      "925 activation_59\n",
      "926 activation_60\n",
      "927 conv5_block25_concat\n",
      "928 block9_sepconv1_bn\n",
      "929 mixed6\n",
      "930 conv5_block26_0_bn\n",
      "931 block9_sepconv2_act\n",
      "932 conv2d_69\n",
      "933 conv5_block26_0_relu\n",
      "934 block9_sepconv2\n",
      "935 batch_normalization_69\n",
      "936 conv5_block26_1_conv\n",
      "937 block9_sepconv2_bn\n",
      "938 activation_65\n",
      "939 conv5_block26_1_bn\n",
      "940 block9_sepconv3_act\n",
      "941 conv2d_70\n",
      "942 conv5_block26_1_relu\n",
      "943 block9_sepconv3\n",
      "944 batch_normalization_70\n",
      "945 conv5_block26_2_conv\n",
      "946 block9_sepconv3_bn\n",
      "947 activation_66\n",
      "948 conv5_block26_concat\n",
      "949 add_8\n",
      "950 conv2d_66\n",
      "951 conv2d_71\n",
      "952 conv5_block27_0_bn\n",
      "953 block10_sepconv1_act\n",
      "954 batch_normalization_66\n",
      "955 batch_normalization_71\n",
      "956 conv5_block27_0_relu\n",
      "957 block10_sepconv1\n",
      "958 activation_62\n",
      "959 activation_67\n",
      "960 conv5_block27_1_conv\n",
      "961 block10_sepconv1_bn\n",
      "962 conv2d_67\n",
      "963 conv2d_72\n",
      "964 conv5_block27_1_bn\n",
      "965 block10_sepconv2_act\n",
      "966 batch_normalization_67\n",
      "967 batch_normalization_72\n",
      "968 conv5_block27_1_relu\n",
      "969 block10_sepconv2\n",
      "970 activation_63\n",
      "971 activation_68\n",
      "972 average_pooling2d_7\n",
      "973 conv5_block27_2_conv\n",
      "974 block10_sepconv2_bn\n",
      "975 conv2d_65\n",
      "976 conv2d_68\n",
      "977 conv2d_73\n",
      "978 conv2d_74\n",
      "979 conv5_block27_concat\n",
      "980 block10_sepconv3_act\n",
      "981 batch_normalization_65\n",
      "982 batch_normalization_68\n",
      "983 batch_normalization_73\n",
      "984 batch_normalization_74\n",
      "985 conv5_block28_0_bn\n",
      "986 block10_sepconv3\n",
      "987 activation_61\n",
      "988 activation_64\n",
      "989 activation_69\n",
      "990 activation_70\n",
      "991 conv5_block28_0_relu\n",
      "992 block10_sepconv3_bn\n",
      "993 mixed7\n",
      "994 conv5_block28_1_conv\n",
      "995 add_9\n",
      "996 conv2d_77\n",
      "997 conv5_block28_1_bn\n",
      "998 block11_sepconv1_act\n",
      "999 batch_normalization_77\n",
      "1000 conv5_block28_1_relu\n",
      "1001 block11_sepconv1\n",
      "1002 activation_73\n",
      "1003 conv5_block28_2_conv\n",
      "1004 block11_sepconv1_bn\n",
      "1005 conv2d_78\n",
      "1006 conv5_block28_concat\n",
      "1007 block11_sepconv2_act\n",
      "1008 batch_normalization_78\n",
      "1009 conv5_block29_0_bn\n",
      "1010 block11_sepconv2\n",
      "1011 activation_74\n",
      "1012 conv5_block29_0_relu\n",
      "1013 block11_sepconv2_bn\n",
      "1014 conv2d_75\n",
      "1015 conv2d_79\n",
      "1016 conv5_block29_1_conv\n",
      "1017 block11_sepconv3_act\n",
      "1018 batch_normalization_75\n",
      "1019 batch_normalization_79\n",
      "1020 conv5_block29_1_bn\n",
      "1021 block11_sepconv3\n",
      "1022 activation_71\n",
      "1023 activation_75\n",
      "1024 conv5_block29_1_relu\n",
      "1025 block11_sepconv3_bn\n",
      "1026 conv2d_76\n",
      "1027 conv2d_80\n",
      "1028 conv5_block29_2_conv\n",
      "1029 add_10\n",
      "1030 batch_normalization_76\n",
      "1031 batch_normalization_80\n",
      "1032 conv5_block29_concat\n",
      "1033 block12_sepconv1_act\n",
      "1034 activation_72\n",
      "1035 activation_76\n",
      "1036 max_pooling2d_4\n",
      "1037 conv5_block30_0_bn\n",
      "1038 block12_sepconv1\n",
      "1039 mixed8\n",
      "1040 conv5_block30_0_relu\n",
      "1041 block12_sepconv1_bn\n",
      "1042 conv2d_85\n",
      "1043 conv5_block30_1_conv\n",
      "1044 block12_sepconv2_act\n",
      "1045 batch_normalization_85\n",
      "1046 conv5_block30_1_bn\n",
      "1047 block12_sepconv2\n",
      "1048 activation_81\n",
      "1049 conv5_block30_1_relu\n",
      "1050 block12_sepconv2_bn\n",
      "1051 conv2d_82\n",
      "1052 conv2d_86\n",
      "1053 conv5_block30_2_conv\n",
      "1054 block12_sepconv3_act\n",
      "1055 batch_normalization_82\n",
      "1056 batch_normalization_86\n",
      "1057 conv5_block30_concat\n",
      "1058 block12_sepconv3\n",
      "1059 activation_78\n",
      "1060 activation_82\n",
      "1061 conv5_block31_0_bn\n",
      "1062 block12_sepconv3_bn\n",
      "1063 conv2d_83\n",
      "1064 conv2d_84\n",
      "1065 conv2d_87\n",
      "1066 conv2d_88\n",
      "1067 average_pooling2d_8\n",
      "1068 conv5_block31_0_relu\n",
      "1069 add_11\n",
      "1070 conv2d_81\n",
      "1071 batch_normalization_83\n",
      "1072 batch_normalization_84\n",
      "1073 batch_normalization_87\n",
      "1074 batch_normalization_88\n",
      "1075 conv2d_89\n",
      "1076 conv5_block31_1_conv\n",
      "1077 block13_sepconv1_act\n",
      "1078 batch_normalization_81\n",
      "1079 activation_79\n",
      "1080 activation_80\n",
      "1081 activation_83\n",
      "1082 activation_84\n",
      "1083 batch_normalization_89\n",
      "1084 conv5_block31_1_bn\n",
      "1085 block13_sepconv1\n",
      "1086 activation_77\n",
      "1087 mixed9_0\n",
      "1088 concatenate_1\n",
      "1089 activation_85\n",
      "1090 conv5_block31_1_relu\n",
      "1091 block13_sepconv1_bn\n",
      "1092 mixed9\n",
      "1093 conv5_block31_2_conv\n",
      "1094 block13_sepconv2_act\n",
      "1095 conv2d_94\n",
      "1096 conv5_block31_concat\n",
      "1097 block13_sepconv2\n",
      "1098 batch_normalization_94\n",
      "1099 conv5_block32_0_bn\n",
      "1100 block13_sepconv2_bn\n",
      "1101 conv2d_4\n",
      "1102 activation_90\n",
      "1103 conv5_block32_0_relu\n",
      "1104 block13_pool\n",
      "1105 batch_normalization_4\n",
      "1106 conv2d_91\n",
      "1107 conv2d_95\n",
      "1108 conv5_block32_1_conv\n",
      "1109 add_12\n",
      "1110 batch_normalization_91\n",
      "1111 batch_normalization_95\n",
      "1112 conv5_block32_1_bn\n",
      "1113 block14_sepconv1\n",
      "1114 activation_87\n",
      "1115 activation_91\n",
      "1116 conv5_block32_1_relu\n",
      "1117 block14_sepconv1_bn\n",
      "1118 conv2d_92\n",
      "1119 conv2d_93\n",
      "1120 conv2d_96\n",
      "1121 conv2d_97\n",
      "1122 average_pooling2d_9\n",
      "1123 conv5_block32_2_conv\n",
      "1124 block14_sepconv1_act\n",
      "1125 conv2d_90\n",
      "1126 batch_normalization_92\n",
      "1127 batch_normalization_93\n",
      "1128 batch_normalization_96\n",
      "1129 batch_normalization_97\n",
      "1130 conv2d_98\n",
      "1131 conv5_block32_concat\n",
      "1132 block14_sepconv2\n",
      "1133 batch_normalization_90\n",
      "1134 activation_88\n",
      "1135 activation_89\n",
      "1136 activation_92\n",
      "1137 activation_93\n",
      "1138 batch_normalization_98\n",
      "1139 bn\n",
      "1140 block14_sepconv2_bn\n",
      "1141 activation_86\n",
      "1142 mixed9_1\n",
      "1143 concatenate_2\n",
      "1144 activation_94\n",
      "1145 relu\n",
      "1146 block14_sepconv2_act\n",
      "1147 mixed10\n",
      "1148 global_average_pooling2d_1\n",
      "1149 global_average_pooling2d_2\n",
      "1150 global_average_pooling2d_3\n",
      "1151 concatenate_3\n",
      "1152 dense_1\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = model.layers[9].output \n",
    "c1 = GlobalAveragePooling2D()(c1)       \n",
    "\n",
    "c2 = model.layers[55].output\n",
    "c2 = GlobalAveragePooling2D()(c2)       \n",
    "\n",
    "c3 = model.layers[143].output\n",
    "c3 = GlobalAveragePooling2D()(c3)       \n",
    "\n",
    "c4 = model.layers[483].output\n",
    "c4 = GlobalAveragePooling2D()(c4) \n",
    "\n",
    "c5 = model.layers[572].output\n",
    "c5 = GlobalAveragePooling2D()(c5) \n",
    "\n",
    "c6 = model.layers[586].output\n",
    "c6 = GlobalAveragePooling2D()(c6) \n",
    "\n",
    "c7 = model.layers[602].output\n",
    "c7 = GlobalAveragePooling2D()(c7) \n",
    "\n",
    "c8 = model.layers[636].output\n",
    "c8 = GlobalAveragePooling2D()(c8) \n",
    "\n",
    "c9 = model.layers[679].output\n",
    "c9 = GlobalAveragePooling2D()(c9) \n",
    "\n",
    "c10 = model.layers[702].output\n",
    "c10 = GlobalAveragePooling2D()(c10) \n",
    "\n",
    "c11 = model.layers[722].output\n",
    "c11 = GlobalAveragePooling2D()(c11) \n",
    "\n",
    "c12 = model.layers[738].output\n",
    "c12 = GlobalAveragePooling2D()(c12) \n",
    "\n",
    "c13 = model.layers[749].output\n",
    "c13 = GlobalAveragePooling2D()(c13) \n",
    "\n",
    "c14 = model.layers[783].output\n",
    "c14 = GlobalAveragePooling2D()(c14) \n",
    "\n",
    "c15 = model.layers[847].output\n",
    "c15 = GlobalAveragePooling2D()(c15) \n",
    "\n",
    "c16 = model.layers[911].output\n",
    "c16 = GlobalAveragePooling2D()(c16) \n",
    "\n",
    "c17 = model.layers[975].output\n",
    "c17 = GlobalAveragePooling2D()(c17) \n",
    "\n",
    "c18 = model.layers[1042].output\n",
    "c18 = GlobalAveragePooling2D()(c18) \n",
    "\n",
    "c19 = model.layers[1070].output\n",
    "c19 = GlobalAveragePooling2D()(c19) \n",
    "\n",
    "c20 = model.layers[1106].output\n",
    "c20 = GlobalAveragePooling2D()(c20) \n",
    "\n",
    "c21 = model.layers[1125].output\n",
    "c21 = GlobalAveragePooling2D()(c21) \n",
    "\n",
    "con = concatenate([c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15, c16, c17, c18, c19, c20, c21])\n",
    "\n",
    "bottleneck_final_model = Model(inputs=model.input, outputs=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 128, 128, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_1 (ZeroPadding2D (None, 134, 134, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1/conv (Conv2D)             (None, 64, 64, 64)   9408        zero_padding2d_1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv1/bn (BatchNormalization)   (None, 64, 64, 64)   256         conv1/conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1/relu (Activation)         (None, 64, 64, 64)   0           conv1/bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_2 (ZeroPadding2D (None, 66, 66, 64)   0           conv1/relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 32, 32, 64)   0           zero_padding2d_2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 32, 32, 64)   256         pool1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_relu (Activation (None, 32, 32, 64)   0           conv2_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 32, 32, 128)  8192        conv2_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 32, 32, 128)  0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_concat (Concatenat (None, 32, 32, 96)   0           pool1[0][0]                      \n",
      "                                                                 conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_bn (BatchNormali (None, 32, 32, 96)   384         conv2_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_0_relu (Activation (None, 32, 32, 96)   0           conv2_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 32, 32, 128)  12288       conv2_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 32, 32, 128)  0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_concat (Concatenat (None, 32, 32, 128)  0           conv2_block1_concat[0][0]        \n",
      "                                                                 conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_0_relu (Activation (None, 32, 32, 128)  0           conv2_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 32, 32, 128)  16384       conv2_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 32, 32, 128)  0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_concat (Concatenat (None, 32, 32, 160)  0           conv2_block2_concat[0][0]        \n",
      "                                                                 conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_bn (BatchNormali (None, 32, 32, 160)  640         conv2_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_0_relu (Activation (None, 32, 32, 160)  0           conv2_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_conv (Conv2D)    (None, 32, 32, 128)  20480       conv2_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_1_relu (Activation (None, 32, 32, 128)  0           conv2_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block4_concat (Concatenat (None, 32, 32, 192)  0           conv2_block3_concat[0][0]        \n",
      "                                                                 conv2_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_bn (BatchNormali (None, 32, 32, 192)  768         conv2_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_0_relu (Activation (None, 32, 32, 192)  0           conv2_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_conv (Conv2D)    (None, 32, 32, 128)  24576       conv2_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_1_relu (Activation (None, 32, 32, 128)  0           conv2_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block5_concat (Concatenat (None, 32, 32, 224)  0           conv2_block4_concat[0][0]        \n",
      "                                                                 conv2_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_bn (BatchNormali (None, 32, 32, 224)  896         conv2_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_0_relu (Activation (None, 32, 32, 224)  0           conv2_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_conv (Conv2D)    (None, 32, 32, 128)  28672       conv2_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_bn (BatchNormali (None, 32, 32, 128)  512         conv2_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_1_relu (Activation (None, 32, 32, 128)  0           conv2_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_2_conv (Conv2D)    (None, 32, 32, 32)   36864       conv2_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block6_concat (Concatenat (None, 32, 32, 256)  0           conv2_block5_concat[0][0]        \n",
      "                                                                 conv2_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_bn (BatchNormalization)   (None, 32, 32, 256)  1024        conv2_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool2_relu (Activation)         (None, 32, 32, 256)  0           pool2_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool2_conv (Conv2D)             (None, 32, 32, 128)  32768       pool2_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool2_pool (AveragePooling2D)   (None, 16, 16, 128)  0           pool2_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 16, 16, 128)  512         pool2_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_relu (Activation (None, 16, 16, 128)  0           conv3_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 16, 16, 128)  16384       conv3_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 16, 16, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_concat (Concatenat (None, 16, 16, 160)  0           pool2_pool[0][0]                 \n",
      "                                                                 conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_bn (BatchNormali (None, 16, 16, 160)  640         conv3_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_0_relu (Activation (None, 16, 16, 160)  0           conv3_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 16, 16, 128)  20480       conv3_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 16, 16, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_concat (Concatenat (None, 16, 16, 192)  0           conv3_block1_concat[0][0]        \n",
      "                                                                 conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_bn (BatchNormali (None, 16, 16, 192)  768         conv3_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_0_relu (Activation (None, 16, 16, 192)  0           conv3_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 16, 16, 128)  24576       conv3_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 16, 16, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_concat (Concatenat (None, 16, 16, 224)  0           conv3_block2_concat[0][0]        \n",
      "                                                                 conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_bn (BatchNormali (None, 16, 16, 224)  896         conv3_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_0_relu (Activation (None, 16, 16, 224)  0           conv3_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 16, 16, 128)  28672       conv3_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 16, 16, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_concat (Concatenat (None, 16, 16, 256)  0           conv3_block3_concat[0][0]        \n",
      "                                                                 conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_bn (BatchNormali (None, 16, 16, 256)  1024        conv3_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_0_relu (Activation (None, 16, 16, 256)  0           conv3_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_conv (Conv2D)    (None, 16, 16, 128)  32768       conv3_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_1_relu (Activation (None, 16, 16, 128)  0           conv3_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block5_concat (Concatenat (None, 16, 16, 288)  0           conv3_block4_concat[0][0]        \n",
      "                                                                 conv3_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_bn (BatchNormali (None, 16, 16, 288)  1152        conv3_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_0_relu (Activation (None, 16, 16, 288)  0           conv3_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_conv (Conv2D)    (None, 16, 16, 128)  36864       conv3_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_1_relu (Activation (None, 16, 16, 128)  0           conv3_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block6_concat (Concatenat (None, 16, 16, 320)  0           conv3_block5_concat[0][0]        \n",
      "                                                                 conv3_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_bn (BatchNormali (None, 16, 16, 320)  1280        conv3_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_0_relu (Activation (None, 16, 16, 320)  0           conv3_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_conv (Conv2D)    (None, 16, 16, 128)  40960       conv3_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_1_relu (Activation (None, 16, 16, 128)  0           conv3_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block7_concat (Concatenat (None, 16, 16, 352)  0           conv3_block6_concat[0][0]        \n",
      "                                                                 conv3_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_bn (BatchNormali (None, 16, 16, 352)  1408        conv3_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_0_relu (Activation (None, 16, 16, 352)  0           conv3_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_conv (Conv2D)    (None, 16, 16, 128)  45056       conv3_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_1_relu (Activation (None, 16, 16, 128)  0           conv3_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block8_concat (Concatenat (None, 16, 16, 384)  0           conv3_block7_concat[0][0]        \n",
      "                                                                 conv3_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_bn (BatchNormali (None, 16, 16, 384)  1536        conv3_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_0_relu (Activation (None, 16, 16, 384)  0           conv3_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_conv (Conv2D)    (None, 16, 16, 128)  49152       conv3_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_bn (BatchNormali (None, 16, 16, 128)  512         conv3_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_1_relu (Activation (None, 16, 16, 128)  0           conv3_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_2_conv (Conv2D)    (None, 16, 16, 32)   36864       conv3_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block9_concat (Concatenat (None, 16, 16, 416)  0           conv3_block8_concat[0][0]        \n",
      "                                                                 conv3_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_bn (BatchNormal (None, 16, 16, 416)  1664        conv3_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_0_relu (Activatio (None, 16, 16, 416)  0           conv3_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_conv (Conv2D)   (None, 16, 16, 128)  53248       conv3_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block10_concat (Concatena (None, 16, 16, 448)  0           conv3_block9_concat[0][0]        \n",
      "                                                                 conv3_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_bn (BatchNormal (None, 16, 16, 448)  1792        conv3_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_0_relu (Activatio (None, 16, 16, 448)  0           conv3_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_conv (Conv2D)   (None, 16, 16, 128)  57344       conv3_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block11_concat (Concatena (None, 16, 16, 480)  0           conv3_block10_concat[0][0]       \n",
      "                                                                 conv3_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_bn (BatchNormal (None, 16, 16, 480)  1920        conv3_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_0_relu (Activatio (None, 16, 16, 480)  0           conv3_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_conv (Conv2D)   (None, 16, 16, 128)  61440       conv3_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_bn (BatchNormal (None, 16, 16, 128)  512         conv3_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_1_relu (Activatio (None, 16, 16, 128)  0           conv3_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_2_conv (Conv2D)   (None, 16, 16, 32)   36864       conv3_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block12_concat (Concatena (None, 16, 16, 512)  0           conv3_block11_concat[0][0]       \n",
      "                                                                 conv3_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_bn (BatchNormalization)   (None, 16, 16, 512)  2048        conv3_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "pool3_relu (Activation)         (None, 16, 16, 512)  0           pool3_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool3_conv (Conv2D)             (None, 16, 16, 256)  131072      pool3_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool3_pool (AveragePooling2D)   (None, 8, 8, 256)    0           pool3_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 8, 8, 256)    1024        pool3_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_relu (Activation (None, 8, 8, 256)    0           conv4_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 8, 8, 128)    32768       conv4_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 8, 8, 128)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_concat (Concatenat (None, 8, 8, 288)    0           pool3_pool[0][0]                 \n",
      "                                                                 conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_bn (BatchNormali (None, 8, 8, 288)    1152        conv4_block1_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_0_relu (Activation (None, 8, 8, 288)    0           conv4_block2_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 8, 8, 128)    36864       conv4_block2_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 8, 8, 128)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_concat (Concatenat (None, 8, 8, 320)    0           conv4_block1_concat[0][0]        \n",
      "                                                                 conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_bn (BatchNormali (None, 8, 8, 320)    1280        conv4_block2_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_0_relu (Activation (None, 8, 8, 320)    0           conv4_block3_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 8, 8, 128)    40960       conv4_block3_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 8, 8, 128)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_concat (Concatenat (None, 8, 8, 352)    0           conv4_block2_concat[0][0]        \n",
      "                                                                 conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_bn (BatchNormali (None, 8, 8, 352)    1408        conv4_block3_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_0_relu (Activation (None, 8, 8, 352)    0           conv4_block4_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 8, 8, 128)    45056       conv4_block4_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 8, 8, 128)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_concat (Concatenat (None, 8, 8, 384)    0           conv4_block3_concat[0][0]        \n",
      "                                                                 conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_bn (BatchNormali (None, 8, 8, 384)    1536        conv4_block4_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_0_relu (Activation (None, 8, 8, 384)    0           conv4_block5_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 8, 8, 128)    49152       conv4_block5_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 8, 8, 128)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_concat (Concatenat (None, 8, 8, 416)    0           conv4_block4_concat[0][0]        \n",
      "                                                                 conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_bn (BatchNormali (None, 8, 8, 416)    1664        conv4_block5_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_0_relu (Activation (None, 8, 8, 416)    0           conv4_block6_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 8, 8, 128)    53248       conv4_block6_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 8, 8, 128)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_concat (Concatenat (None, 8, 8, 448)    0           conv4_block5_concat[0][0]        \n",
      "                                                                 conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_bn (BatchNormali (None, 8, 8, 448)    1792        conv4_block6_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_0_relu (Activation (None, 8, 8, 448)    0           conv4_block7_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_conv (Conv2D)    (None, 8, 8, 128)    57344       conv4_block7_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block7_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_1_relu (Activation (None, 8, 8, 128)    0           conv4_block7_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block7_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block7_concat (Concatenat (None, 8, 8, 480)    0           conv4_block6_concat[0][0]        \n",
      "                                                                 conv4_block7_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_bn (BatchNormali (None, 8, 8, 480)    1920        conv4_block7_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_0_relu (Activation (None, 8, 8, 480)    0           conv4_block8_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_conv (Conv2D)    (None, 8, 8, 128)    61440       conv4_block8_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block8_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_1_relu (Activation (None, 8, 8, 128)    0           conv4_block8_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block8_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block8_concat (Concatenat (None, 8, 8, 512)    0           conv4_block7_concat[0][0]        \n",
      "                                                                 conv4_block8_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_bn (BatchNormali (None, 8, 8, 512)    2048        conv4_block8_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_0_relu (Activation (None, 8, 8, 512)    0           conv4_block9_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_conv (Conv2D)    (None, 8, 8, 128)    65536       conv4_block9_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_bn (BatchNormali (None, 8, 8, 128)    512         conv4_block9_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_1_relu (Activation (None, 8, 8, 128)    0           conv4_block9_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_2_conv (Conv2D)    (None, 8, 8, 32)     36864       conv4_block9_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block9_concat (Concatenat (None, 8, 8, 544)    0           conv4_block8_concat[0][0]        \n",
      "                                                                 conv4_block9_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_bn (BatchNormal (None, 8, 8, 544)    2176        conv4_block9_concat[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_0_relu (Activatio (None, 8, 8, 544)    0           conv4_block10_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_conv (Conv2D)   (None, 8, 8, 128)    69632       conv4_block10_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block10_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block10_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block10_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block10_concat (Concatena (None, 8, 8, 576)    0           conv4_block9_concat[0][0]        \n",
      "                                                                 conv4_block10_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_bn (BatchNormal (None, 8, 8, 576)    2304        conv4_block10_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_0_relu (Activatio (None, 8, 8, 576)    0           conv4_block11_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_conv (Conv2D)   (None, 8, 8, 128)    73728       conv4_block11_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block11_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block11_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block11_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block11_concat (Concatena (None, 8, 8, 608)    0           conv4_block10_concat[0][0]       \n",
      "                                                                 conv4_block11_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_bn (BatchNormal (None, 8, 8, 608)    2432        conv4_block11_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_0_relu (Activatio (None, 8, 8, 608)    0           conv4_block12_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_conv (Conv2D)   (None, 8, 8, 128)    77824       conv4_block12_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block12_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block12_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block12_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block12_concat (Concatena (None, 8, 8, 640)    0           conv4_block11_concat[0][0]       \n",
      "                                                                 conv4_block12_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_bn (BatchNormal (None, 8, 8, 640)    2560        conv4_block12_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_0_relu (Activatio (None, 8, 8, 640)    0           conv4_block13_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_conv (Conv2D)   (None, 8, 8, 128)    81920       conv4_block13_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block13_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block13_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block13_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block13_concat (Concatena (None, 8, 8, 672)    0           conv4_block12_concat[0][0]       \n",
      "                                                                 conv4_block13_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_bn (BatchNormal (None, 8, 8, 672)    2688        conv4_block13_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_0_relu (Activatio (None, 8, 8, 672)    0           conv4_block14_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_conv (Conv2D)   (None, 8, 8, 128)    86016       conv4_block14_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block14_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block14_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block14_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block14_concat (Concatena (None, 8, 8, 704)    0           conv4_block13_concat[0][0]       \n",
      "                                                                 conv4_block14_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_bn (BatchNormal (None, 8, 8, 704)    2816        conv4_block14_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_0_relu (Activatio (None, 8, 8, 704)    0           conv4_block15_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_conv (Conv2D)   (None, 8, 8, 128)    90112       conv4_block15_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block15_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block15_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block15_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block15_concat (Concatena (None, 8, 8, 736)    0           conv4_block14_concat[0][0]       \n",
      "                                                                 conv4_block15_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_bn (BatchNormal (None, 8, 8, 736)    2944        conv4_block15_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_0_relu (Activatio (None, 8, 8, 736)    0           conv4_block16_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_conv (Conv2D)   (None, 8, 8, 128)    94208       conv4_block16_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block16_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block16_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block16_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block16_concat (Concatena (None, 8, 8, 768)    0           conv4_block15_concat[0][0]       \n",
      "                                                                 conv4_block16_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_bn (BatchNormal (None, 8, 8, 768)    3072        conv4_block16_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_0_relu (Activatio (None, 8, 8, 768)    0           conv4_block17_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_conv (Conv2D)   (None, 8, 8, 128)    98304       conv4_block17_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block17_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block17_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block17_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block17_concat (Concatena (None, 8, 8, 800)    0           conv4_block16_concat[0][0]       \n",
      "                                                                 conv4_block17_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_bn (BatchNormal (None, 8, 8, 800)    3200        conv4_block17_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_0_relu (Activatio (None, 8, 8, 800)    0           conv4_block18_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_conv (Conv2D)   (None, 8, 8, 128)    102400      conv4_block18_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block18_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block18_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block18_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block18_concat (Concatena (None, 8, 8, 832)    0           conv4_block17_concat[0][0]       \n",
      "                                                                 conv4_block18_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_bn (BatchNormal (None, 8, 8, 832)    3328        conv4_block18_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_0_relu (Activatio (None, 8, 8, 832)    0           conv4_block19_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_conv (Conv2D)   (None, 8, 8, 128)    106496      conv4_block19_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block19_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block19_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block19_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block19_concat (Concatena (None, 8, 8, 864)    0           conv4_block18_concat[0][0]       \n",
      "                                                                 conv4_block19_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_bn (BatchNormal (None, 8, 8, 864)    3456        conv4_block19_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_0_relu (Activatio (None, 8, 8, 864)    0           conv4_block20_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_conv (Conv2D)   (None, 8, 8, 128)    110592      conv4_block20_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block20_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block20_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block20_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block20_concat (Concatena (None, 8, 8, 896)    0           conv4_block19_concat[0][0]       \n",
      "                                                                 conv4_block20_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_bn (BatchNormal (None, 8, 8, 896)    3584        conv4_block20_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_0_relu (Activatio (None, 8, 8, 896)    0           conv4_block21_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_conv (Conv2D)   (None, 8, 8, 128)    114688      conv4_block21_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block21_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block21_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block21_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block21_concat (Concatena (None, 8, 8, 928)    0           conv4_block20_concat[0][0]       \n",
      "                                                                 conv4_block21_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_bn (BatchNormal (None, 8, 8, 928)    3712        conv4_block21_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_0_relu (Activatio (None, 8, 8, 928)    0           conv4_block22_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_conv (Conv2D)   (None, 8, 8, 128)    118784      conv4_block22_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block22_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block22_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block22_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block22_concat (Concatena (None, 8, 8, 960)    0           conv4_block21_concat[0][0]       \n",
      "                                                                 conv4_block22_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_bn (BatchNormal (None, 8, 8, 960)    3840        conv4_block22_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_0_relu (Activatio (None, 8, 8, 960)    0           conv4_block23_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_conv (Conv2D)   (None, 8, 8, 128)    122880      conv4_block23_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block23_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block23_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block23_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block23_concat (Concatena (None, 8, 8, 992)    0           conv4_block22_concat[0][0]       \n",
      "                                                                 conv4_block23_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_bn (BatchNormal (None, 8, 8, 992)    3968        conv4_block23_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_0_relu (Activatio (None, 8, 8, 992)    0           conv4_block24_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_conv (Conv2D)   (None, 8, 8, 128)    126976      conv4_block24_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block24_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block24_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block24_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block24_concat (Concatena (None, 8, 8, 1024)   0           conv4_block23_concat[0][0]       \n",
      "                                                                 conv4_block24_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_bn (BatchNormal (None, 8, 8, 1024)   4096        conv4_block24_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_0_relu (Activatio (None, 8, 8, 1024)   0           conv4_block25_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_conv (Conv2D)   (None, 8, 8, 128)    131072      conv4_block25_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block25_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block25_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block25_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block25_concat (Concatena (None, 8, 8, 1056)   0           conv4_block24_concat[0][0]       \n",
      "                                                                 conv4_block25_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_bn (BatchNormal (None, 8, 8, 1056)   4224        conv4_block25_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_0_relu (Activatio (None, 8, 8, 1056)   0           conv4_block26_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_conv (Conv2D)   (None, 8, 8, 128)    135168      conv4_block26_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block26_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block26_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block26_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block26_concat (Concatena (None, 8, 8, 1088)   0           conv4_block25_concat[0][0]       \n",
      "                                                                 conv4_block26_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_bn (BatchNormal (None, 8, 8, 1088)   4352        conv4_block26_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_0_relu (Activatio (None, 8, 8, 1088)   0           conv4_block27_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_conv (Conv2D)   (None, 8, 8, 128)    139264      conv4_block27_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block27_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block27_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block27_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block27_concat (Concatena (None, 8, 8, 1120)   0           conv4_block26_concat[0][0]       \n",
      "                                                                 conv4_block27_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_bn (BatchNormal (None, 8, 8, 1120)   4480        conv4_block27_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_0_relu (Activatio (None, 8, 8, 1120)   0           conv4_block28_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_conv (Conv2D)   (None, 8, 8, 128)    143360      conv4_block28_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block28_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block28_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block28_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block28_concat (Concatena (None, 8, 8, 1152)   0           conv4_block27_concat[0][0]       \n",
      "                                                                 conv4_block28_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_bn (BatchNormal (None, 8, 8, 1152)   4608        conv4_block28_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_0_relu (Activatio (None, 8, 8, 1152)   0           conv4_block29_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_conv (Conv2D)   (None, 8, 8, 128)    147456      conv4_block29_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 63, 63, 32)   96          conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block29_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 63, 63, 32)   0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block29_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 61, 61, 32)   9216        activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block29_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 61, 61, 32)   96          conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block29_concat (Concatena (None, 8, 8, 1184)   0           conv4_block28_concat[0][0]       \n",
      "                                                                 conv4_block29_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 61, 61, 32)   0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_bn (BatchNormal (None, 8, 8, 1184)   4736        conv4_block29_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 61, 61, 64)   18432       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_0_relu (Activatio (None, 8, 8, 1184)   0           conv4_block30_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 61, 61, 64)   192         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_conv (Conv2D)   (None, 8, 8, 128)    151552      conv4_block30_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 61, 61, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block30_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 30, 30, 64)   0           activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block30_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 30, 30, 80)   5120        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block30_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 30, 30, 80)   240         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block30_concat (Concatena (None, 8, 8, 1216)   0           conv4_block29_concat[0][0]       \n",
      "                                                                 conv4_block30_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 30, 30, 80)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_bn (BatchNormal (None, 8, 8, 1216)   4864        conv4_block30_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 28, 28, 192)  138240      activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_0_relu (Activatio (None, 8, 8, 1216)   0           conv4_block31_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 28, 28, 192)  576         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_conv (Conv2D)   (None, 8, 8, 128)    155648      conv4_block31_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 28, 28, 192)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block31_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 192)  0           activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block31_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 13, 13, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block31_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 13, 13, 64)   192         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block31_concat (Concatena (None, 8, 8, 1248)   0           conv4_block30_concat[0][0]       \n",
      "                                                                 conv4_block31_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 13, 13, 64)   0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_bn (BatchNormal (None, 8, 8, 1248)   4992        conv4_block31_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 13, 13, 48)   9216        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 13, 13, 96)   55296       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_0_relu (Activatio (None, 8, 8, 1248)   0           conv4_block32_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 13, 13, 48)   144         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 13, 13, 96)   288         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_conv (Conv2D)   (None, 8, 8, 128)    159744      conv4_block32_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 13, 13, 48)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 13, 13, 96)   0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_1 (AveragePoo (None, 13, 13, 192)  0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block32_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 13, 13, 64)   12288       max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 13, 13, 64)   76800       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 13, 13, 96)   82944       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 13, 13, 32)   6144        average_pooling2d_1[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block32_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 13, 13, 64)   192         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 13, 13, 64)   192         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 13, 13, 96)   288         conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 13, 13, 32)   96          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block32_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 13, 13, 64)   0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 13, 13, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 13, 13, 96)   0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 13, 13, 32)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block32_concat (Concatena (None, 8, 8, 1280)   0           conv4_block31_concat[0][0]       \n",
      "                                                                 conv4_block32_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_6[0][0]               \n",
      "                                                                 activation_8[0][0]               \n",
      "                                                                 activation_11[0][0]              \n",
      "                                                                 activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_bn (BatchNormal (None, 8, 8, 1280)   5120        conv4_block32_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_0_relu (Activatio (None, 8, 8, 1280)   0           conv4_block33_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 13, 13, 64)   192         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_conv (Conv2D)   (None, 8, 8, 128)    163840      conv4_block33_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 13, 13, 64)   0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block33_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 13, 13, 96)   55296       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block33_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 13, 13, 48)   144         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 13, 13, 96)   288         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block33_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 13, 13, 48)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 13, 13, 96)   0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block33_concat (Concatena (None, 8, 8, 1312)   0           conv4_block32_concat[0][0]       \n",
      "                                                                 conv4_block33_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 13, 13, 64)   76800       activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 13, 13, 96)   82944       activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 13, 13, 64)   16384       average_pooling2d_2[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_bn (BatchNormal (None, 8, 8, 1312)   5248        conv4_block33_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 13, 13, 64)   192         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 13, 13, 64)   192         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 13, 13, 96)   288         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 13, 13, 64)   192         conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_0_relu (Activatio (None, 8, 8, 1312)   0           conv4_block34_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 13, 13, 64)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 13, 13, 64)   0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 13, 13, 96)   0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 13, 13, 64)   0           batch_normalization_23[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_conv (Conv2D)   (None, 8, 8, 128)    167936      conv4_block34_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_13[0][0]              \n",
      "                                                                 activation_15[0][0]              \n",
      "                                                                 activation_18[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block34_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_27 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block34_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_27 (BatchNo (None, 13, 13, 64)   192         conv2d_27[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block34_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 13, 13, 64)   0           batch_normalization_27[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block34_concat (Concatena (None, 8, 8, 1344)   0           conv4_block33_concat[0][0]       \n",
      "                                                                 conv4_block34_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_25 (Conv2D)              (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_28 (Conv2D)              (None, 13, 13, 96)   55296       activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_bn (BatchNormal (None, 8, 8, 1344)   5376        conv4_block34_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_25 (BatchNo (None, 13, 13, 48)   144         conv2d_25[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_28 (BatchNo (None, 13, 13, 96)   288         conv2d_28[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_0_relu (Activatio (None, 8, 8, 1344)   0           conv4_block35_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 13, 13, 48)   0           batch_normalization_25[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 13, 13, 96)   0           batch_normalization_28[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_3 (AveragePoo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_conv (Conv2D)   (None, 8, 8, 128)    172032      conv4_block35_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_24 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_26 (Conv2D)              (None, 13, 13, 64)   76800       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_29 (Conv2D)              (None, 13, 13, 96)   82944       activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_30 (Conv2D)              (None, 13, 13, 64)   18432       average_pooling2d_3[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block35_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_24 (BatchNo (None, 13, 13, 64)   192         conv2d_24[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_26 (BatchNo (None, 13, 13, 64)   192         conv2d_26[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_29 (BatchNo (None, 13, 13, 96)   288         conv2d_29[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_30 (BatchNo (None, 13, 13, 64)   192         conv2d_30[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block35_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 13, 13, 64)   0           batch_normalization_24[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 13, 13, 64)   0           batch_normalization_26[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 13, 13, 96)   0           batch_normalization_29[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 13, 13, 64)   0           batch_normalization_30[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block35_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_20[0][0]              \n",
      "                                                                 activation_22[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "                                                                 activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block35_concat (Concatena (None, 8, 8, 1376)   0           conv4_block34_concat[0][0]       \n",
      "                                                                 conv4_block35_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_32 (Conv2D)              (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_bn (BatchNormal (None, 8, 8, 1376)   5504        conv4_block35_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_32 (BatchNo (None, 13, 13, 64)   192         conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_0_relu (Activatio (None, 8, 8, 1376)   0           conv4_block36_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 13, 13, 64)   0           batch_normalization_32[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_conv (Conv2D)   (None, 8, 8, 128)    176128      conv4_block36_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_33 (Conv2D)              (None, 13, 13, 96)   55296       activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block36_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_33 (BatchNo (None, 13, 13, 96)   288         conv2d_33[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block36_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 13, 13, 96)   0           batch_normalization_33[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block36_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_31 (Conv2D)              (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_34 (Conv2D)              (None, 6, 6, 96)     82944       activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block36_concat (Concatena (None, 8, 8, 1408)   0           conv4_block35_concat[0][0]       \n",
      "                                                                 conv4_block36_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_31 (BatchNo (None, 6, 6, 384)    1152        conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_34 (BatchNo (None, 6, 6, 96)     288         conv2d_34[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_bn (BatchNormal (None, 8, 8, 1408)   5632        conv4_block36_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 6, 6, 384)    0           batch_normalization_31[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 6, 6, 96)     0           batch_normalization_34[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_0_relu (Activatio (None, 8, 8, 1408)   0           conv4_block37_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_27[0][0]              \n",
      "                                                                 activation_30[0][0]              \n",
      "                                                                 max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_conv (Conv2D)   (None, 8, 8, 128)    180224      conv4_block37_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block37_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_39 (BatchNo (None, 6, 6, 128)    384         conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block37_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 6, 6, 128)    0           batch_normalization_39[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block37_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 6, 6, 128)    114688      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block37_concat (Concatena (None, 8, 8, 1440)   0           conv4_block36_concat[0][0]       \n",
      "                                                                 conv4_block37_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_40 (BatchNo (None, 6, 6, 128)    384         conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_bn (BatchNormal (None, 8, 8, 1440)   5760        conv4_block37_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 6, 6, 128)    0           batch_normalization_40[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_0_relu (Activatio (None, 8, 8, 1440)   0           conv4_block38_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 6, 6, 128)    114688      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_conv (Conv2D)   (None, 8, 8, 128)    184320      conv4_block38_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_36 (BatchNo (None, 6, 6, 128)    384         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_41 (BatchNo (None, 6, 6, 128)    384         conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block38_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 6, 6, 128)    0           batch_normalization_36[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 6, 6, 128)    0           batch_normalization_41[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block38_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 6, 6, 128)    114688      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 6, 6, 128)    114688      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block38_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_37 (BatchNo (None, 6, 6, 128)    384         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_42 (BatchNo (None, 6, 6, 128)    384         conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block38_concat (Concatena (None, 8, 8, 1472)   0           conv4_block37_concat[0][0]       \n",
      "                                                                 conv4_block38_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 6, 6, 128)    0           batch_normalization_37[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 6, 6, 128)    0           batch_normalization_42[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_4 (AveragePoo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_bn (BatchNormal (None, 8, 8, 1472)   5888        conv4_block38_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 6, 6, 192)    172032      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 6, 6, 192)    172032      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_4[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_0_relu (Activatio (None, 8, 8, 1472)   0           conv4_block39_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_35 (BatchNo (None, 6, 6, 192)    576         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_38 (BatchNo (None, 6, 6, 192)    576         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_43 (BatchNo (None, 6, 6, 192)    576         conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_44 (BatchNo (None, 6, 6, 192)    576         conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_conv (Conv2D)   (None, 8, 8, 128)    188416      conv4_block39_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 6, 6, 192)    0           batch_normalization_35[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 6, 6, 192)    0           batch_normalization_38[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 6, 6, 192)    0           batch_normalization_43[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 6, 6, 192)    0           batch_normalization_44[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block39_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_31[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "                                                                 activation_39[0][0]              \n",
      "                                                                 activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block39_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_49 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block39_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_49 (BatchNo (None, 6, 6, 160)    480         conv2d_49[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block39_concat (Concatena (None, 8, 8, 1504)   0           conv4_block38_concat[0][0]       \n",
      "                                                                 conv4_block39_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 6, 6, 160)    0           batch_normalization_49[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_bn (BatchNormal (None, 8, 8, 1504)   6016        conv4_block39_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 6, 6, 160)    179200      activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_0_relu (Activatio (None, 8, 8, 1504)   0           conv4_block40_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_50 (BatchNo (None, 6, 6, 160)    480         conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_conv (Conv2D)   (None, 8, 8, 128)    192512      conv4_block40_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 6, 6, 160)    0           batch_normalization_50[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block40_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 6, 6, 160)    179200      activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block40_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_46 (BatchNo (None, 6, 6, 160)    480         conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_51 (BatchNo (None, 6, 6, 160)    480         conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block40_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 6, 6, 160)    0           batch_normalization_46[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 6, 6, 160)    0           batch_normalization_51[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block40_concat (Concatena (None, 8, 8, 1536)   0           conv4_block39_concat[0][0]       \n",
      "                                                                 conv4_block40_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 6, 6, 160)    179200      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 6, 6, 160)    179200      activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_bn (BatchNormal (None, 8, 8, 1536)   6144        conv4_block40_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_47 (BatchNo (None, 6, 6, 160)    480         conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 6, 6, 160)    480         conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_0_relu (Activatio (None, 8, 8, 1536)   0           conv4_block41_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 6, 6, 160)    0           batch_normalization_47[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 6, 6, 160)    0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_conv (Conv2D)   (None, 8, 8, 128)    196608      conv4_block41_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 6, 6, 192)    215040      activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 6, 6, 192)    215040      activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block41_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_45 (BatchNo (None, 6, 6, 192)    576         conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_48 (BatchNo (None, 6, 6, 192)    576         conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 6, 6, 192)    576         conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 6, 6, 192)    576         conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block41_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 6, 6, 192)    0           batch_normalization_45[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 6, 6, 192)    0           batch_normalization_48[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 6, 6, 192)    0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 6, 6, 192)    0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block41_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_41[0][0]              \n",
      "                                                                 activation_44[0][0]              \n",
      "                                                                 activation_49[0][0]              \n",
      "                                                                 activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block41_concat (Concatena (None, 8, 8, 1568)   0           conv4_block40_concat[0][0]       \n",
      "                                                                 conv4_block41_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_bn (BatchNormal (None, 8, 8, 1568)   6272        conv4_block41_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 6, 6, 160)    480         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_0_relu (Activatio (None, 8, 8, 1568)   0           conv4_block42_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 6, 6, 160)    0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_conv (Conv2D)   (None, 8, 8, 128)    200704      conv4_block42_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 6, 6, 160)    179200      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block42_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 6, 6, 160)    480         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block42_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 6, 6, 160)    0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block42_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 6, 6, 160)    179200      activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block42_concat (Concatena (None, 8, 8, 1600)   0           conv4_block41_concat[0][0]       \n",
      "                                                                 conv4_block42_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 6, 6, 160)    480         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 6, 6, 160)    480         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_bn (BatchNormal (None, 8, 8, 1600)   6400        conv4_block42_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 6, 6, 160)    0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 6, 6, 160)    0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_0_relu (Activatio (None, 8, 8, 1600)   0           conv4_block43_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 6, 6, 160)    179200      activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 6, 6, 160)    179200      activation_57[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_conv (Conv2D)   (None, 8, 8, 128)    204800      conv4_block43_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 6, 6, 160)    480         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 6, 6, 160)    480         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block43_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 6, 6, 160)    0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 6, 6, 160)    0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block43_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 6, 6, 192)    215040      activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 6, 6, 192)    215040      activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block43_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 6, 6, 192)    576         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 6, 6, 192)    576         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 6, 6, 192)    576         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 6, 6, 192)    576         conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block43_concat (Concatena (None, 8, 8, 1632)   0           conv4_block42_concat[0][0]       \n",
      "                                                                 conv4_block43_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_51 (Activation)      (None, 6, 6, 192)    0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 6, 6, 192)    0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 6, 6, 192)    0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 6, 6, 192)    0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_bn (BatchNormal (None, 8, 8, 1632)   6528        conv4_block43_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_51[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_0_relu (Activatio (None, 8, 8, 1632)   0           conv4_block44_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_conv (Conv2D)   (None, 8, 8, 128)    208896      conv4_block44_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 6, 6, 192)    576         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block44_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 6, 6, 192)    0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block44_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 6, 6, 192)    258048      activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block44_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 6, 6, 192)    576         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block44_concat (Concatena (None, 8, 8, 1664)   0           conv4_block43_concat[0][0]       \n",
      "                                                                 conv4_block44_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 6, 6, 192)    0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_bn (BatchNormal (None, 8, 8, 1664)   6656        conv4_block44_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 6, 6, 192)    258048      activation_66[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_0_relu (Activatio (None, 8, 8, 1664)   0           conv4_block45_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 6, 6, 192)    576         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 6, 6, 192)    576         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_conv (Conv2D)   (None, 8, 8, 128)    212992      conv4_block45_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 6, 6, 192)    0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 6, 6, 192)    0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block45_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 6, 6, 192)    258048      activation_62[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 6, 6, 192)    258048      activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block45_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 6, 6, 192)    576         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 6, 6, 192)    576         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block45_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 6, 6, 192)    0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 6, 6, 192)    0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block45_concat (Concatena (None, 8, 8, 1696)   0           conv4_block44_concat[0][0]       \n",
      "                                                                 conv4_block45_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 6, 6, 192)    258048      activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 6, 6, 192)    258048      activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_bn (BatchNormal (None, 8, 8, 1696)   6784        conv4_block45_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 6, 6, 192)    576         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 6, 6, 192)    576         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 6, 6, 192)    576         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 6, 6, 192)    576         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_0_relu (Activatio (None, 8, 8, 1696)   0           conv4_block46_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 6, 6, 192)    0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 6, 6, 192)    0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 6, 6, 192)    0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 6, 6, 192)    0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_conv (Conv2D)   (None, 8, 8, 128)    217088      conv4_block46_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_61[0][0]              \n",
      "                                                                 activation_64[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block46_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block46_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 6, 6, 192)    576         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block46_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 6, 6, 192)    0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block46_concat (Concatena (None, 8, 8, 1728)   0           conv4_block45_concat[0][0]       \n",
      "                                                                 conv4_block46_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 6, 6, 192)    258048      activation_73[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_bn (BatchNormal (None, 8, 8, 1728)   6912        conv4_block46_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 6, 6, 192)    576         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_0_relu (Activatio (None, 8, 8, 1728)   0           conv4_block47_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 6, 6, 192)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_conv (Conv2D)   (None, 8, 8, 128)    221184      conv4_block47_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 6, 6, 192)    258048      activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block47_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 6, 6, 192)    576         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 6, 6, 192)    576         conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block47_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 6, 6, 192)    0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 6, 6, 192)    0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block47_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 2, 2, 320)    552960      activation_71[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 2, 2, 192)    331776      activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block47_concat (Concatena (None, 8, 8, 1760)   0           conv4_block46_concat[0][0]       \n",
      "                                                                 conv4_block47_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 2, 2, 192)    576         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_bn (BatchNormal (None, 8, 8, 1760)   7040        conv4_block47_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 2, 2, 192)    0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_0_relu (Activatio (None, 8, 8, 1760)   0           conv4_block48_0_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_72[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_conv (Conv2D)   (None, 8, 8, 128)    225280      conv4_block48_0_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_bn (BatchNormal (None, 8, 8, 128)    512         conv4_block48_1_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 2, 2, 448)    1344        conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_1_relu (Activatio (None, 8, 8, 128)    0           conv4_block48_1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 2, 2, 448)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_2_conv (Conv2D)   (None, 8, 8, 32)     36864       conv4_block48_1_relu[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 2, 2, 384)    1548288     activation_81[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block48_concat (Concatena (None, 8, 8, 1792)   0           conv4_block47_concat[0][0]       \n",
      "                                                                 conv4_block48_2_conv[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool4_bn (BatchNormalization)   (None, 8, 8, 1792)   7168        conv4_block48_concat[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 63, 63, 32)   864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "pool4_relu (Activation)         (None, 8, 8, 1792)   0           pool4_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 63, 63, 32)   128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 2, 2, 384)    442368      activation_78[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_82[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "pool4_conv (Conv2D)             (None, 8, 8, 896)    1605632     pool4_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 63, 63, 32)   0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 2, 2, 384)    1152        conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "pool4_pool (AveragePooling2D)   (None, 4, 4, 896)    0           pool4_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 61, 61, 64)   18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 2, 2, 320)    960         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 2, 2, 384)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 2, 2, 192)    576         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 4, 4, 896)    3584        pool4_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 61, 61, 64)   256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 2, 2, 320)    0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_79[0][0]              \n",
      "                                                                 activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 2, 2, 768)    0           activation_83[0][0]              \n",
      "                                                                 activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 2, 2, 192)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_relu (Activation (None, 4, 4, 896)    0           conv5_block1_0_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 61, 61, 64)   0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_77[0][0]              \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 128)    114688      conv5_block1_0_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 31, 31, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 128)          0           conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_5 (Glo (None, 128)          0           conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_6 (Glo (None, 128)          0           conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_7 (Glo (None, 128)          0           conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_8 (Glo (None, 80)           0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_9 (Glo (None, 64)           0           conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_10 (Gl (None, 64)           0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_11 (Gl (None, 64)           0           conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_12 (Gl (None, 128)          0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_13 (Gl (None, 64)           0           conv2d_32[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_14 (Gl (None, 384)          0           conv2d_31[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_15 (Gl (None, 128)          0           conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_16 (Gl (None, 128)          0           conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_17 (Gl (None, 192)          0           conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_18 (Gl (None, 192)          0           conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_19 (Gl (None, 192)          0           conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_20 (Gl (None, 192)          0           conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_21 (Gl (None, 448)          0           conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_22 (Gl (None, 320)          0           conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_23 (Gl (None, 384)          0           conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_24 (Gl (None, 320)          0           conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3856)         0           global_average_pooling2d_4[0][0] \n",
      "                                                                 global_average_pooling2d_5[0][0] \n",
      "                                                                 global_average_pooling2d_6[0][0] \n",
      "                                                                 global_average_pooling2d_7[0][0] \n",
      "                                                                 global_average_pooling2d_8[0][0] \n",
      "                                                                 global_average_pooling2d_9[0][0] \n",
      "                                                                 global_average_pooling2d_10[0][0]\n",
      "                                                                 global_average_pooling2d_11[0][0]\n",
      "                                                                 global_average_pooling2d_12[0][0]\n",
      "                                                                 global_average_pooling2d_13[0][0]\n",
      "                                                                 global_average_pooling2d_14[0][0]\n",
      "                                                                 global_average_pooling2d_15[0][0]\n",
      "                                                                 global_average_pooling2d_16[0][0]\n",
      "                                                                 global_average_pooling2d_17[0][0]\n",
      "                                                                 global_average_pooling2d_18[0][0]\n",
      "                                                                 global_average_pooling2d_19[0][0]\n",
      "                                                                 global_average_pooling2d_20[0][0]\n",
      "                                                                 global_average_pooling2d_21[0][0]\n",
      "                                                                 global_average_pooling2d_22[0][0]\n",
      "                                                                 global_average_pooling2d_23[0][0]\n",
      "                                                                 global_average_pooling2d_24[0][0]\n",
      "==================================================================================================\n",
      "Total params: 28,549,120\n",
      "Trainable params: 28,391,296\n",
      "Non-trainable params: 157,824\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bottleneck_final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train)\n",
    "np.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\n",
    "np.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)\n",
    "\n",
    "bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\n",
    "np.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\n",
    "validation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\n",
    "test_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n",
    "\n",
    "train_labels = train_generator.classes\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "validation_labels = validation_generator.classes\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "test_labels = test_generator.classes\n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 319152 samples, validate on 79784 samples\n",
      "Epoch 1/1000\n",
      " - 17s - loss: 0.6610 - acc: 0.7925 - val_loss: 0.4455 - val_acc: 0.8686\n",
      "Epoch 2/1000\n",
      " - 12s - loss: 0.4391 - acc: 0.8660 - val_loss: 0.3893 - val_acc: 0.8807\n",
      "Epoch 3/1000\n",
      " - 12s - loss: 0.3877 - acc: 0.8812 - val_loss: 0.3516 - val_acc: 0.8928\n",
      "Epoch 4/1000\n",
      " - 12s - loss: 0.3567 - acc: 0.8906 - val_loss: 0.3228 - val_acc: 0.9024\n",
      "Epoch 5/1000\n",
      " - 12s - loss: 0.3359 - acc: 0.8972 - val_loss: 0.3094 - val_acc: 0.9070\n",
      "Epoch 6/1000\n",
      " - 12s - loss: 0.3199 - acc: 0.9027 - val_loss: 0.2999 - val_acc: 0.9093\n",
      "Epoch 7/1000\n",
      " - 12s - loss: 0.3072 - acc: 0.9070 - val_loss: 0.2889 - val_acc: 0.9138\n",
      "Epoch 8/1000\n",
      " - 12s - loss: 0.2969 - acc: 0.9107 - val_loss: 0.2838 - val_acc: 0.9162\n",
      "Epoch 9/1000\n",
      " - 12s - loss: 0.2883 - acc: 0.9130 - val_loss: 0.2769 - val_acc: 0.9181\n",
      "Epoch 10/1000\n",
      " - 12s - loss: 0.2802 - acc: 0.9164 - val_loss: 0.2696 - val_acc: 0.9189\n",
      "Epoch 11/1000\n",
      " - 12s - loss: 0.2736 - acc: 0.9186 - val_loss: 0.2589 - val_acc: 0.9247\n",
      "Epoch 12/1000\n",
      " - 12s - loss: 0.2679 - acc: 0.9204 - val_loss: 0.2637 - val_acc: 0.9213\n",
      "Epoch 13/1000\n",
      " - 12s - loss: 0.2631 - acc: 0.9224 - val_loss: 0.2552 - val_acc: 0.9223\n",
      "Epoch 14/1000\n",
      " - 12s - loss: 0.2591 - acc: 0.9236 - val_loss: 0.2516 - val_acc: 0.9242\n",
      "Epoch 15/1000\n",
      " - 12s - loss: 0.2544 - acc: 0.9251 - val_loss: 0.2364 - val_acc: 0.9320\n",
      "Epoch 16/1000\n",
      " - 12s - loss: 0.2492 - acc: 0.9265 - val_loss: 0.2410 - val_acc: 0.9289\n",
      "Epoch 17/1000\n",
      " - 12s - loss: 0.2462 - acc: 0.9277 - val_loss: 0.2341 - val_acc: 0.9329\n",
      "Epoch 18/1000\n",
      " - 12s - loss: 0.2430 - acc: 0.9294 - val_loss: 0.2297 - val_acc: 0.9354\n",
      "Epoch 19/1000\n",
      " - 12s - loss: 0.2397 - acc: 0.9300 - val_loss: 0.2392 - val_acc: 0.9289\n",
      "Epoch 20/1000\n",
      " - 12s - loss: 0.2368 - acc: 0.9317 - val_loss: 0.2279 - val_acc: 0.9338\n",
      "Epoch 21/1000\n",
      " - 12s - loss: 0.2338 - acc: 0.9326 - val_loss: 0.2213 - val_acc: 0.9379\n",
      "Epoch 22/1000\n",
      " - 12s - loss: 0.2324 - acc: 0.9329 - val_loss: 0.2292 - val_acc: 0.9341\n",
      "Epoch 23/1000\n",
      " - 12s - loss: 0.2295 - acc: 0.9341 - val_loss: 0.2164 - val_acc: 0.9401\n",
      "Epoch 24/1000\n",
      " - 12s - loss: 0.2276 - acc: 0.9347 - val_loss: 0.2202 - val_acc: 0.9383\n",
      "Epoch 25/1000\n",
      " - 12s - loss: 0.2252 - acc: 0.9356 - val_loss: 0.2069 - val_acc: 0.9422\n",
      "Epoch 26/1000\n",
      " - 12s - loss: 0.2228 - acc: 0.9366 - val_loss: 0.2138 - val_acc: 0.9381\n",
      "Epoch 27/1000\n",
      " - 12s - loss: 0.2214 - acc: 0.9368 - val_loss: 0.2062 - val_acc: 0.9425\n",
      "Epoch 28/1000\n",
      " - 12s - loss: 0.2198 - acc: 0.9378 - val_loss: 0.2234 - val_acc: 0.9365\n",
      "Epoch 29/1000\n",
      " - 12s - loss: 0.2178 - acc: 0.9382 - val_loss: 0.2057 - val_acc: 0.9429\n",
      "Epoch 30/1000\n",
      " - 12s - loss: 0.2155 - acc: 0.9391 - val_loss: 0.1986 - val_acc: 0.9457\n",
      "Epoch 31/1000\n",
      " - 12s - loss: 0.2147 - acc: 0.9390 - val_loss: 0.1987 - val_acc: 0.9458\n",
      "Epoch 32/1000\n",
      " - 12s - loss: 0.2137 - acc: 0.9397 - val_loss: 0.2041 - val_acc: 0.9429\n",
      "Epoch 33/1000\n",
      " - 12s - loss: 0.2111 - acc: 0.9401 - val_loss: 0.1914 - val_acc: 0.9481\n",
      "Epoch 34/1000\n",
      " - 12s - loss: 0.2104 - acc: 0.9408 - val_loss: 0.2179 - val_acc: 0.9374\n",
      "Epoch 35/1000\n",
      " - 12s - loss: 0.2091 - acc: 0.9413 - val_loss: 0.1999 - val_acc: 0.9451\n",
      "Epoch 36/1000\n",
      " - 12s - loss: 0.2068 - acc: 0.9419 - val_loss: 0.1914 - val_acc: 0.9486\n",
      "Epoch 37/1000\n",
      " - 12s - loss: 0.2072 - acc: 0.9418 - val_loss: 0.1906 - val_acc: 0.9482\n",
      "Epoch 38/1000\n",
      " - 12s - loss: 0.2046 - acc: 0.9429 - val_loss: 0.1924 - val_acc: 0.9474\n",
      "Epoch 39/1000\n",
      " - 12s - loss: 0.2049 - acc: 0.9426 - val_loss: 0.1906 - val_acc: 0.9479\n",
      "Epoch 40/1000\n",
      " - 12s - loss: 0.2035 - acc: 0.9434 - val_loss: 0.1871 - val_acc: 0.9497\n",
      "Epoch 41/1000\n",
      " - 12s - loss: 0.2018 - acc: 0.9440 - val_loss: 0.2087 - val_acc: 0.9405\n",
      "Epoch 42/1000\n",
      " - 12s - loss: 0.2009 - acc: 0.9443 - val_loss: 0.2005 - val_acc: 0.9454\n",
      "Epoch 43/1000\n",
      " - 12s - loss: 0.2001 - acc: 0.9447 - val_loss: 0.1945 - val_acc: 0.9463\n",
      "Epoch 44/1000\n",
      " - 12s - loss: 0.1996 - acc: 0.9449 - val_loss: 0.1819 - val_acc: 0.9520\n",
      "Epoch 45/1000\n",
      " - 12s - loss: 0.1983 - acc: 0.9454 - val_loss: 0.1813 - val_acc: 0.9529\n",
      "Epoch 46/1000\n",
      " - 12s - loss: 0.1975 - acc: 0.9456 - val_loss: 0.1878 - val_acc: 0.9498\n",
      "Epoch 47/1000\n",
      " - 12s - loss: 0.1959 - acc: 0.9459 - val_loss: 0.1857 - val_acc: 0.9494\n",
      "Epoch 48/1000\n",
      " - 12s - loss: 0.1964 - acc: 0.9457 - val_loss: 0.1817 - val_acc: 0.9536\n",
      "Epoch 49/1000\n",
      " - 12s - loss: 0.1948 - acc: 0.9466 - val_loss: 0.1801 - val_acc: 0.9526\n",
      "Epoch 50/1000\n",
      " - 12s - loss: 0.1942 - acc: 0.9471 - val_loss: 0.1894 - val_acc: 0.9495\n",
      "Epoch 51/1000\n",
      " - 12s - loss: 0.1935 - acc: 0.9472 - val_loss: 0.1748 - val_acc: 0.9544\n",
      "Epoch 52/1000\n",
      " - 12s - loss: 0.1923 - acc: 0.9477 - val_loss: 0.1787 - val_acc: 0.9522\n",
      "Epoch 53/1000\n",
      " - 12s - loss: 0.1918 - acc: 0.9477 - val_loss: 0.1854 - val_acc: 0.9509\n",
      "Epoch 54/1000\n",
      " - 12s - loss: 0.1915 - acc: 0.9479 - val_loss: 0.1757 - val_acc: 0.9548\n",
      "Epoch 55/1000\n",
      " - 12s - loss: 0.1903 - acc: 0.9485 - val_loss: 0.1789 - val_acc: 0.9536\n",
      "Epoch 56/1000\n",
      " - 12s - loss: 0.1901 - acc: 0.9482 - val_loss: 0.1706 - val_acc: 0.9559\n",
      "Epoch 57/1000\n",
      " - 12s - loss: 0.1892 - acc: 0.9495 - val_loss: 0.1736 - val_acc: 0.9554\n",
      "Epoch 58/1000\n",
      " - 12s - loss: 0.1892 - acc: 0.9487 - val_loss: 0.1755 - val_acc: 0.9533\n",
      "Epoch 59/1000\n",
      " - 12s - loss: 0.1869 - acc: 0.9495 - val_loss: 0.1724 - val_acc: 0.9553\n",
      "Epoch 60/1000\n",
      " - 12s - loss: 0.1866 - acc: 0.9497 - val_loss: 0.1740 - val_acc: 0.9543\n",
      "Epoch 61/1000\n",
      " - 12s - loss: 0.1868 - acc: 0.9495 - val_loss: 0.1872 - val_acc: 0.9491\n",
      "Epoch 62/1000\n",
      " - 12s - loss: 0.1865 - acc: 0.9499 - val_loss: 0.1792 - val_acc: 0.9521\n",
      "Epoch 63/1000\n",
      " - 12s - loss: 0.1854 - acc: 0.9506 - val_loss: 0.1780 - val_acc: 0.9526\n",
      "Epoch 64/1000\n",
      " - 12s - loss: 0.1849 - acc: 0.9507 - val_loss: 0.1694 - val_acc: 0.9557\n",
      "Epoch 65/1000\n",
      " - 12s - loss: 0.1838 - acc: 0.9512 - val_loss: 0.1842 - val_acc: 0.9509\n",
      "Epoch 66/1000\n",
      " - 12s - loss: 0.1839 - acc: 0.9506 - val_loss: 0.1765 - val_acc: 0.9537\n",
      "Epoch 67/1000\n",
      " - 12s - loss: 0.1832 - acc: 0.9508 - val_loss: 0.1693 - val_acc: 0.9566\n",
      "Epoch 68/1000\n",
      " - 12s - loss: 0.1828 - acc: 0.9513 - val_loss: 0.1684 - val_acc: 0.9577\n",
      "Epoch 69/1000\n",
      " - 12s - loss: 0.1818 - acc: 0.9518 - val_loss: 0.1699 - val_acc: 0.9568\n",
      "Epoch 70/1000\n",
      " - 12s - loss: 0.1828 - acc: 0.9509 - val_loss: 0.1652 - val_acc: 0.9595\n",
      "Epoch 71/1000\n",
      " - 12s - loss: 0.1813 - acc: 0.9516 - val_loss: 0.1698 - val_acc: 0.9562\n",
      "Epoch 72/1000\n",
      " - 12s - loss: 0.1814 - acc: 0.9518 - val_loss: 0.1793 - val_acc: 0.9511\n",
      "Epoch 73/1000\n",
      " - 12s - loss: 0.1805 - acc: 0.9519 - val_loss: 0.1657 - val_acc: 0.9589\n",
      "Epoch 74/1000\n",
      " - 12s - loss: 0.1793 - acc: 0.9523 - val_loss: 0.1734 - val_acc: 0.9551\n",
      "Epoch 75/1000\n",
      " - 12s - loss: 0.1803 - acc: 0.9524 - val_loss: 0.1654 - val_acc: 0.9578\n",
      "Epoch 76/1000\n",
      " - 12s - loss: 0.1793 - acc: 0.9525 - val_loss: 0.1632 - val_acc: 0.9590\n",
      "Epoch 77/1000\n",
      " - 12s - loss: 0.1793 - acc: 0.9525 - val_loss: 0.1620 - val_acc: 0.9595\n",
      "Epoch 78/1000\n",
      " - 12s - loss: 0.1781 - acc: 0.9533 - val_loss: 0.1612 - val_acc: 0.9595\n",
      "Epoch 79/1000\n",
      " - 12s - loss: 0.1783 - acc: 0.9528 - val_loss: 0.1656 - val_acc: 0.9575\n",
      "Epoch 80/1000\n",
      " - 12s - loss: 0.1777 - acc: 0.9538 - val_loss: 0.1603 - val_acc: 0.9600\n",
      "Epoch 81/1000\n",
      " - 12s - loss: 0.1769 - acc: 0.9536 - val_loss: 0.1607 - val_acc: 0.9601\n",
      "Epoch 82/1000\n",
      " - 12s - loss: 0.1767 - acc: 0.9537 - val_loss: 0.1621 - val_acc: 0.9588\n",
      "Epoch 83/1000\n",
      " - 12s - loss: 0.1759 - acc: 0.9543 - val_loss: 0.1670 - val_acc: 0.9574\n",
      "Epoch 84/1000\n",
      " - 12s - loss: 0.1766 - acc: 0.9537 - val_loss: 0.1621 - val_acc: 0.9598\n",
      "Epoch 85/1000\n",
      " - 12s - loss: 0.1759 - acc: 0.9540 - val_loss: 0.1618 - val_acc: 0.9595\n",
      "Epoch 86/1000\n",
      " - 12s - loss: 0.1758 - acc: 0.9543 - val_loss: 0.1627 - val_acc: 0.9588\n",
      "Epoch 87/1000\n",
      " - 12s - loss: 0.1752 - acc: 0.9541 - val_loss: 0.1601 - val_acc: 0.9604\n",
      "Epoch 88/1000\n",
      " - 12s - loss: 0.1747 - acc: 0.9547 - val_loss: 0.1544 - val_acc: 0.9628\n",
      "Epoch 89/1000\n",
      " - 12s - loss: 0.1747 - acc: 0.9549 - val_loss: 0.1613 - val_acc: 0.9601\n",
      "Epoch 90/1000\n",
      " - 12s - loss: 0.1741 - acc: 0.9550 - val_loss: 0.1660 - val_acc: 0.9587\n",
      "Epoch 91/1000\n",
      " - 12s - loss: 0.1727 - acc: 0.9553 - val_loss: 0.1639 - val_acc: 0.9580\n",
      "Epoch 92/1000\n",
      " - 12s - loss: 0.1738 - acc: 0.9551 - val_loss: 0.1548 - val_acc: 0.9633\n",
      "Epoch 93/1000\n",
      " - 12s - loss: 0.1728 - acc: 0.9551 - val_loss: 0.1614 - val_acc: 0.9596\n",
      "Epoch 94/1000\n",
      " - 12s - loss: 0.1731 - acc: 0.9552 - val_loss: 0.1597 - val_acc: 0.9606\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/1000\n",
      " - 12s - loss: 0.1719 - acc: 0.9558 - val_loss: 0.1596 - val_acc: 0.9614\n",
      "Epoch 96/1000\n",
      " - 12s - loss: 0.1720 - acc: 0.9557 - val_loss: 0.1557 - val_acc: 0.9624\n",
      "Epoch 97/1000\n",
      " - 12s - loss: 0.1719 - acc: 0.9559 - val_loss: 0.1626 - val_acc: 0.9591\n",
      "Epoch 98/1000\n",
      " - 12s - loss: 0.1710 - acc: 0.9558 - val_loss: 0.1563 - val_acc: 0.9625\n",
      "Epoch 99/1000\n",
      " - 12s - loss: 0.1717 - acc: 0.9558 - val_loss: 0.1558 - val_acc: 0.9622\n",
      "Epoch 100/1000\n",
      " - 12s - loss: 0.1699 - acc: 0.9566 - val_loss: 0.1588 - val_acc: 0.9604\n",
      "Epoch 101/1000\n",
      " - 12s - loss: 0.1715 - acc: 0.9560 - val_loss: 0.1509 - val_acc: 0.9637\n",
      "Epoch 102/1000\n",
      " - 12s - loss: 0.1707 - acc: 0.9567 - val_loss: 0.1493 - val_acc: 0.9650\n",
      "Epoch 103/1000\n",
      " - 12s - loss: 0.1701 - acc: 0.9564 - val_loss: 0.1500 - val_acc: 0.9646\n",
      "Epoch 104/1000\n",
      " - 12s - loss: 0.1705 - acc: 0.9563 - val_loss: 0.1582 - val_acc: 0.9612\n",
      "Epoch 105/1000\n",
      " - 12s - loss: 0.1702 - acc: 0.9564 - val_loss: 0.1514 - val_acc: 0.9646\n",
      "Epoch 106/1000\n",
      " - 12s - loss: 0.1689 - acc: 0.9570 - val_loss: 0.1506 - val_acc: 0.9651\n",
      "Epoch 107/1000\n",
      " - 12s - loss: 0.1694 - acc: 0.9566 - val_loss: 0.1533 - val_acc: 0.9630\n",
      "Epoch 108/1000\n",
      " - 12s - loss: 0.1685 - acc: 0.9574 - val_loss: 0.1501 - val_acc: 0.9643\n",
      "Epoch 109/1000\n",
      " - 12s - loss: 0.1693 - acc: 0.9569 - val_loss: 0.1527 - val_acc: 0.9633\n",
      "Epoch 110/1000\n",
      " - 12s - loss: 0.1684 - acc: 0.9575 - val_loss: 0.1589 - val_acc: 0.9607\n",
      "Epoch 111/1000\n",
      " - 12s - loss: 0.1685 - acc: 0.9572 - val_loss: 0.1540 - val_acc: 0.9627\n",
      "Epoch 112/1000\n",
      " - 12s - loss: 0.1675 - acc: 0.9575 - val_loss: 0.1589 - val_acc: 0.9606\n",
      "Epoch 113/1000\n",
      " - 12s - loss: 0.1677 - acc: 0.9575 - val_loss: 0.1574 - val_acc: 0.9614\n",
      "Epoch 114/1000\n",
      " - 12s - loss: 0.1674 - acc: 0.9579 - val_loss: 0.1517 - val_acc: 0.9642\n",
      "Epoch 115/1000\n",
      " - 12s - loss: 0.1679 - acc: 0.9573 - val_loss: 0.1586 - val_acc: 0.9618\n",
      "Epoch 116/1000\n",
      " - 12s - loss: 0.1667 - acc: 0.9585 - val_loss: 0.1506 - val_acc: 0.9646\n",
      "Epoch 117/1000\n",
      " - 12s - loss: 0.1662 - acc: 0.9581 - val_loss: 0.1518 - val_acc: 0.9644\n",
      "Epoch 118/1000\n",
      " - 12s - loss: 0.1678 - acc: 0.9577 - val_loss: 0.1499 - val_acc: 0.9642\n",
      "Epoch 119/1000\n",
      " - 12s - loss: 0.1660 - acc: 0.9584 - val_loss: 0.1517 - val_acc: 0.9645\n",
      "Epoch 120/1000\n",
      " - 12s - loss: 0.1668 - acc: 0.9577 - val_loss: 0.1504 - val_acc: 0.9659\n",
      "Epoch 121/1000\n",
      " - 12s - loss: 0.1662 - acc: 0.9582 - val_loss: 0.1503 - val_acc: 0.9637\n",
      "Epoch 122/1000\n",
      " - 12s - loss: 0.1665 - acc: 0.9582 - val_loss: 0.1495 - val_acc: 0.9650\n",
      "Epoch 123/1000\n",
      " - 12s - loss: 0.1656 - acc: 0.9583 - val_loss: 0.1467 - val_acc: 0.9661\n",
      "Epoch 124/1000\n",
      " - 12s - loss: 0.1652 - acc: 0.9586 - val_loss: 0.1498 - val_acc: 0.9650\n",
      "Epoch 125/1000\n",
      " - 12s - loss: 0.1654 - acc: 0.9582 - val_loss: 0.1511 - val_acc: 0.9635\n",
      "Epoch 126/1000\n",
      " - 12s - loss: 0.1657 - acc: 0.9583 - val_loss: 0.1476 - val_acc: 0.9662\n",
      "Epoch 127/1000\n",
      " - 12s - loss: 0.1654 - acc: 0.9585 - val_loss: 0.1486 - val_acc: 0.9651\n",
      "Epoch 128/1000\n",
      " - 12s - loss: 0.1642 - acc: 0.9594 - val_loss: 0.1463 - val_acc: 0.9662\n",
      "Epoch 129/1000\n",
      " - 12s - loss: 0.1647 - acc: 0.9586 - val_loss: 0.1478 - val_acc: 0.9664\n",
      "Epoch 130/1000\n",
      " - 12s - loss: 0.1647 - acc: 0.9593 - val_loss: 0.1469 - val_acc: 0.9668\n",
      "Epoch 131/1000\n",
      " - 12s - loss: 0.1654 - acc: 0.9585 - val_loss: 0.1465 - val_acc: 0.9662\n",
      "Epoch 132/1000\n",
      " - 12s - loss: 0.1640 - acc: 0.9596 - val_loss: 0.1497 - val_acc: 0.9661\n",
      "Epoch 133/1000\n",
      " - 12s - loss: 0.1638 - acc: 0.9593 - val_loss: 0.1472 - val_acc: 0.9659\n",
      "Epoch 134/1000\n",
      " - 12s - loss: 0.1639 - acc: 0.9591 - val_loss: 0.1479 - val_acc: 0.9668\n",
      "Epoch 135/1000\n",
      " - 12s - loss: 0.1639 - acc: 0.9590 - val_loss: 0.1490 - val_acc: 0.9651\n",
      "Epoch 136/1000\n",
      " - 12s - loss: 0.1634 - acc: 0.9593 - val_loss: 0.1477 - val_acc: 0.9651\n",
      "Epoch 137/1000\n",
      " - 12s - loss: 0.1630 - acc: 0.9597 - val_loss: 0.1567 - val_acc: 0.9624\n",
      "Epoch 138/1000\n",
      " - 12s - loss: 0.1634 - acc: 0.9594 - val_loss: 0.1492 - val_acc: 0.9655\n",
      "Epoch 139/1000\n",
      " - 12s - loss: 0.1635 - acc: 0.9597 - val_loss: 0.1443 - val_acc: 0.9671\n",
      "Epoch 140/1000\n",
      " - 12s - loss: 0.1627 - acc: 0.9598 - val_loss: 0.1467 - val_acc: 0.9666\n",
      "Epoch 141/1000\n",
      " - 12s - loss: 0.1622 - acc: 0.9599 - val_loss: 0.1515 - val_acc: 0.9640\n",
      "Epoch 142/1000\n",
      " - 12s - loss: 0.1617 - acc: 0.9603 - val_loss: 0.1441 - val_acc: 0.9670\n",
      "Epoch 143/1000\n",
      " - 12s - loss: 0.1619 - acc: 0.9600 - val_loss: 0.1486 - val_acc: 0.9650\n",
      "Epoch 144/1000\n",
      " - 12s - loss: 0.1625 - acc: 0.9598 - val_loss: 0.1518 - val_acc: 0.9638\n",
      "Epoch 145/1000\n",
      " - 12s - loss: 0.1624 - acc: 0.9603 - val_loss: 0.1477 - val_acc: 0.9654\n",
      "Epoch 146/1000\n",
      " - 12s - loss: 0.1624 - acc: 0.9598 - val_loss: 0.1448 - val_acc: 0.9671\n",
      "Epoch 147/1000\n",
      " - 12s - loss: 0.1610 - acc: 0.9605 - val_loss: 0.1553 - val_acc: 0.9626\n",
      "Epoch 148/1000\n",
      " - 12s - loss: 0.1623 - acc: 0.9601 - val_loss: 0.1436 - val_acc: 0.9673\n",
      "Epoch 149/1000\n",
      " - 12s - loss: 0.1615 - acc: 0.9604 - val_loss: 0.1529 - val_acc: 0.9632\n",
      "Epoch 150/1000\n",
      " - 12s - loss: 0.1609 - acc: 0.9606 - val_loss: 0.1519 - val_acc: 0.9645\n",
      "Epoch 151/1000\n",
      " - 12s - loss: 0.1614 - acc: 0.9602 - val_loss: 0.1445 - val_acc: 0.9663\n",
      "Epoch 152/1000\n",
      " - 12s - loss: 0.1608 - acc: 0.9607 - val_loss: 0.1426 - val_acc: 0.9674\n",
      "Epoch 153/1000\n",
      " - 12s - loss: 0.1617 - acc: 0.9602 - val_loss: 0.1430 - val_acc: 0.9679\n",
      "Epoch 154/1000\n",
      " - 12s - loss: 0.1604 - acc: 0.9608 - val_loss: 0.1483 - val_acc: 0.9660\n",
      "Epoch 155/1000\n",
      " - 12s - loss: 0.1608 - acc: 0.9608 - val_loss: 0.1473 - val_acc: 0.9663\n",
      "Epoch 156/1000\n",
      " - 12s - loss: 0.1604 - acc: 0.9607 - val_loss: 0.1423 - val_acc: 0.9674\n",
      "Epoch 157/1000\n",
      " - 12s - loss: 0.1602 - acc: 0.9610 - val_loss: 0.1439 - val_acc: 0.9668\n",
      "Epoch 158/1000\n",
      " - 12s - loss: 0.1601 - acc: 0.9608 - val_loss: 0.1458 - val_acc: 0.9666\n",
      "Epoch 159/1000\n",
      " - 12s - loss: 0.1604 - acc: 0.9608 - val_loss: 0.1449 - val_acc: 0.9672\n",
      "Epoch 160/1000\n",
      " - 12s - loss: 0.1607 - acc: 0.9609 - val_loss: 0.1398 - val_acc: 0.9694\n",
      "Epoch 161/1000\n",
      " - 12s - loss: 0.1595 - acc: 0.9610 - val_loss: 0.1460 - val_acc: 0.9666\n",
      "Epoch 162/1000\n",
      " - 12s - loss: 0.1599 - acc: 0.9613 - val_loss: 0.1433 - val_acc: 0.9686\n",
      "Epoch 163/1000\n",
      " - 12s - loss: 0.1588 - acc: 0.9615 - val_loss: 0.1452 - val_acc: 0.9672\n",
      "Epoch 164/1000\n",
      " - 12s - loss: 0.1594 - acc: 0.9612 - val_loss: 0.1467 - val_acc: 0.9658\n",
      "Epoch 165/1000\n",
      " - 12s - loss: 0.1591 - acc: 0.9614 - val_loss: 0.1446 - val_acc: 0.9674\n",
      "Epoch 166/1000\n",
      " - 12s - loss: 0.1596 - acc: 0.9610 - val_loss: 0.1419 - val_acc: 0.9673\n",
      "Epoch 167/1000\n",
      " - 12s - loss: 0.1585 - acc: 0.9616 - val_loss: 0.1474 - val_acc: 0.9673\n",
      "Epoch 168/1000\n",
      " - 12s - loss: 0.1583 - acc: 0.9618 - val_loss: 0.1407 - val_acc: 0.9698\n",
      "Epoch 169/1000\n",
      " - 12s - loss: 0.1591 - acc: 0.9611 - val_loss: 0.1479 - val_acc: 0.9661\n",
      "Epoch 170/1000\n",
      " - 12s - loss: 0.1584 - acc: 0.9617 - val_loss: 0.1422 - val_acc: 0.9685\n",
      "Epoch 171/1000\n",
      " - 12s - loss: 0.1580 - acc: 0.9615 - val_loss: 0.1430 - val_acc: 0.9680\n",
      "Epoch 172/1000\n",
      " - 12s - loss: 0.1587 - acc: 0.9617 - val_loss: 0.1476 - val_acc: 0.9656\n",
      "Epoch 173/1000\n",
      " - 12s - loss: 0.1587 - acc: 0.9616 - val_loss: 0.1443 - val_acc: 0.9669\n",
      "Epoch 174/1000\n",
      " - 12s - loss: 0.1583 - acc: 0.9615 - val_loss: 0.1523 - val_acc: 0.9643\n",
      "Epoch 175/1000\n",
      " - 12s - loss: 0.1580 - acc: 0.9618 - val_loss: 0.1459 - val_acc: 0.9660\n",
      "Epoch 176/1000\n",
      " - 12s - loss: 0.1580 - acc: 0.9619 - val_loss: 0.1415 - val_acc: 0.9692\n",
      "Epoch 177/1000\n",
      " - 12s - loss: 0.1580 - acc: 0.9622 - val_loss: 0.1414 - val_acc: 0.9688\n",
      "Epoch 178/1000\n",
      " - 12s - loss: 0.1573 - acc: 0.9620 - val_loss: 0.1475 - val_acc: 0.9652\n",
      "Epoch 179/1000\n",
      " - 12s - loss: 0.1582 - acc: 0.9617 - val_loss: 0.1461 - val_acc: 0.9662\n",
      "Epoch 180/1000\n",
      " - 12s - loss: 0.1576 - acc: 0.9621 - val_loss: 0.1410 - val_acc: 0.9678\n",
      "Epoch 181/1000\n",
      " - 12s - loss: 0.1572 - acc: 0.9624 - val_loss: 0.1413 - val_acc: 0.9684\n",
      "Epoch 182/1000\n",
      " - 12s - loss: 0.1571 - acc: 0.9620 - val_loss: 0.1432 - val_acc: 0.9681\n",
      "Epoch 183/1000\n",
      " - 12s - loss: 0.1575 - acc: 0.9621 - val_loss: 0.1503 - val_acc: 0.9643\n",
      "Epoch 184/1000\n",
      " - 12s - loss: 0.1574 - acc: 0.9623 - val_loss: 0.1541 - val_acc: 0.9629\n",
      "Epoch 185/1000\n",
      " - 12s - loss: 0.1568 - acc: 0.9625 - val_loss: 0.1428 - val_acc: 0.9690\n",
      "Epoch 186/1000\n",
      " - 12s - loss: 0.1563 - acc: 0.9626 - val_loss: 0.1398 - val_acc: 0.9693\n",
      "Epoch 187/1000\n",
      " - 12s - loss: 0.1564 - acc: 0.9628 - val_loss: 0.1384 - val_acc: 0.9690\n",
      "Epoch 188/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.1568 - acc: 0.9624 - val_loss: 0.1433 - val_acc: 0.9678\n",
      "Epoch 189/1000\n",
      " - 12s - loss: 0.1560 - acc: 0.9627 - val_loss: 0.1415 - val_acc: 0.9687\n",
      "Epoch 190/1000\n",
      " - 12s - loss: 0.1562 - acc: 0.9625 - val_loss: 0.1410 - val_acc: 0.9700\n",
      "Epoch 191/1000\n",
      " - 12s - loss: 0.1558 - acc: 0.9629 - val_loss: 0.1491 - val_acc: 0.9655\n",
      "Epoch 192/1000\n",
      " - 12s - loss: 0.1562 - acc: 0.9629 - val_loss: 0.1373 - val_acc: 0.9700\n",
      "Epoch 193/1000\n",
      " - 12s - loss: 0.1565 - acc: 0.9627 - val_loss: 0.1428 - val_acc: 0.9679\n",
      "Epoch 194/1000\n",
      " - 12s - loss: 0.1561 - acc: 0.9626 - val_loss: 0.1465 - val_acc: 0.9673\n",
      "Epoch 195/1000\n",
      " - 12s - loss: 0.1554 - acc: 0.9630 - val_loss: 0.1380 - val_acc: 0.9700\n",
      "Epoch 196/1000\n",
      " - 12s - loss: 0.1565 - acc: 0.9628 - val_loss: 0.1455 - val_acc: 0.9671\n",
      "Epoch 197/1000\n",
      " - 12s - loss: 0.1552 - acc: 0.9632 - val_loss: 0.1348 - val_acc: 0.9711\n",
      "Epoch 198/1000\n",
      " - 12s - loss: 0.1558 - acc: 0.9627 - val_loss: 0.1455 - val_acc: 0.9684\n",
      "Epoch 199/1000\n",
      " - 12s - loss: 0.1558 - acc: 0.9629 - val_loss: 0.1444 - val_acc: 0.9673\n",
      "Epoch 200/1000\n",
      " - 12s - loss: 0.1564 - acc: 0.9626 - val_loss: 0.1366 - val_acc: 0.9704\n",
      "Epoch 201/1000\n",
      " - 12s - loss: 0.1564 - acc: 0.9628 - val_loss: 0.1405 - val_acc: 0.9692\n",
      "Epoch 202/1000\n",
      " - 12s - loss: 0.1552 - acc: 0.9630 - val_loss: 0.1386 - val_acc: 0.9708\n",
      "Epoch 203/1000\n",
      " - 12s - loss: 0.1553 - acc: 0.9631 - val_loss: 0.1451 - val_acc: 0.9667\n",
      "Epoch 204/1000\n",
      " - 12s - loss: 0.1540 - acc: 0.9632 - val_loss: 0.1423 - val_acc: 0.9702\n",
      "Epoch 205/1000\n",
      " - 12s - loss: 0.1548 - acc: 0.9632 - val_loss: 0.1379 - val_acc: 0.9699\n",
      "Epoch 206/1000\n",
      " - 12s - loss: 0.1552 - acc: 0.9632 - val_loss: 0.1394 - val_acc: 0.9689\n",
      "Epoch 207/1000\n",
      " - 12s - loss: 0.1547 - acc: 0.9636 - val_loss: 0.1398 - val_acc: 0.9698\n",
      "Epoch 208/1000\n",
      " - 12s - loss: 0.1545 - acc: 0.9631 - val_loss: 0.1528 - val_acc: 0.9640\n",
      "Epoch 209/1000\n",
      " - 12s - loss: 0.1545 - acc: 0.9638 - val_loss: 0.1405 - val_acc: 0.9690\n",
      "Epoch 210/1000\n",
      " - 12s - loss: 0.1540 - acc: 0.9637 - val_loss: 0.1369 - val_acc: 0.9706\n",
      "Epoch 211/1000\n",
      " - 12s - loss: 0.1545 - acc: 0.9635 - val_loss: 0.1356 - val_acc: 0.9711\n",
      "Epoch 212/1000\n",
      " - 12s - loss: 0.1542 - acc: 0.9635 - val_loss: 0.1350 - val_acc: 0.9713\n",
      "Epoch 213/1000\n",
      " - 12s - loss: 0.1551 - acc: 0.9633 - val_loss: 0.1398 - val_acc: 0.9697\n",
      "Epoch 214/1000\n",
      " - 12s - loss: 0.1541 - acc: 0.9638 - val_loss: 0.1405 - val_acc: 0.9687\n",
      "Epoch 215/1000\n",
      " - 12s - loss: 0.1539 - acc: 0.9634 - val_loss: 0.1419 - val_acc: 0.9685\n",
      "Epoch 216/1000\n",
      " - 12s - loss: 0.1536 - acc: 0.9636 - val_loss: 0.1393 - val_acc: 0.9701\n",
      "Epoch 217/1000\n",
      " - 12s - loss: 0.1543 - acc: 0.9633 - val_loss: 0.1391 - val_acc: 0.9696\n",
      "Epoch 218/1000\n",
      " - 12s - loss: 0.1547 - acc: 0.9631 - val_loss: 0.1449 - val_acc: 0.9666\n",
      "Epoch 219/1000\n",
      " - 12s - loss: 0.1540 - acc: 0.9637 - val_loss: 0.1419 - val_acc: 0.9674\n",
      "Epoch 220/1000\n",
      " - 12s - loss: 0.1534 - acc: 0.9640 - val_loss: 0.1380 - val_acc: 0.9705\n",
      "Epoch 221/1000\n",
      " - 12s - loss: 0.1526 - acc: 0.9642 - val_loss: 0.1400 - val_acc: 0.9694\n",
      "Epoch 222/1000\n",
      " - 12s - loss: 0.1537 - acc: 0.9641 - val_loss: 0.1388 - val_acc: 0.9699\n",
      "Epoch 223/1000\n",
      " - 12s - loss: 0.1532 - acc: 0.9640 - val_loss: 0.1348 - val_acc: 0.9721\n",
      "Epoch 224/1000\n",
      " - 12s - loss: 0.1528 - acc: 0.9641 - val_loss: 0.1504 - val_acc: 0.9642\n",
      "Epoch 225/1000\n",
      " - 12s - loss: 0.1532 - acc: 0.9641 - val_loss: 0.1393 - val_acc: 0.9688\n",
      "Epoch 226/1000\n",
      " - 12s - loss: 0.1532 - acc: 0.9640 - val_loss: 0.1331 - val_acc: 0.9733\n",
      "Epoch 227/1000\n",
      " - 12s - loss: 0.1538 - acc: 0.9635 - val_loss: 0.1359 - val_acc: 0.9707\n",
      "Epoch 228/1000\n",
      " - 12s - loss: 0.1533 - acc: 0.9640 - val_loss: 0.1389 - val_acc: 0.9698\n",
      "Epoch 229/1000\n",
      " - 12s - loss: 0.1524 - acc: 0.9643 - val_loss: 0.1329 - val_acc: 0.9718\n",
      "Epoch 230/1000\n",
      " - 12s - loss: 0.1533 - acc: 0.9642 - val_loss: 0.1387 - val_acc: 0.9698\n",
      "Epoch 231/1000\n",
      " - 12s - loss: 0.1528 - acc: 0.9643 - val_loss: 0.1358 - val_acc: 0.9707\n",
      "Epoch 232/1000\n",
      " - 12s - loss: 0.1526 - acc: 0.9642 - val_loss: 0.1373 - val_acc: 0.9709\n",
      "Epoch 233/1000\n",
      " - 12s - loss: 0.1528 - acc: 0.9642 - val_loss: 0.1363 - val_acc: 0.9701\n",
      "Epoch 234/1000\n",
      " - 12s - loss: 0.1533 - acc: 0.9641 - val_loss: 0.1389 - val_acc: 0.9703\n",
      "Epoch 235/1000\n",
      " - 12s - loss: 0.1538 - acc: 0.9637 - val_loss: 0.1426 - val_acc: 0.9677\n",
      "Epoch 236/1000\n",
      " - 12s - loss: 0.1527 - acc: 0.9645 - val_loss: 0.1432 - val_acc: 0.9679\n",
      "Epoch 237/1000\n",
      " - 12s - loss: 0.1531 - acc: 0.9643 - val_loss: 0.1359 - val_acc: 0.9705\n",
      "Epoch 238/1000\n",
      " - 12s - loss: 0.1522 - acc: 0.9645 - val_loss: 0.1351 - val_acc: 0.9716\n",
      "Epoch 239/1000\n",
      " - 12s - loss: 0.1528 - acc: 0.9641 - val_loss: 0.1384 - val_acc: 0.9711\n",
      "Epoch 240/1000\n",
      " - 12s - loss: 0.1524 - acc: 0.9643 - val_loss: 0.1429 - val_acc: 0.9672\n",
      "Epoch 241/1000\n",
      " - 12s - loss: 0.1530 - acc: 0.9642 - val_loss: 0.1391 - val_acc: 0.9704\n",
      "Epoch 242/1000\n",
      " - 12s - loss: 0.1520 - acc: 0.9643 - val_loss: 0.1390 - val_acc: 0.9689\n",
      "Epoch 243/1000\n",
      " - 12s - loss: 0.1529 - acc: 0.9644 - val_loss: 0.1377 - val_acc: 0.9708\n",
      "Epoch 244/1000\n",
      " - 12s - loss: 0.1522 - acc: 0.9644 - val_loss: 0.1348 - val_acc: 0.9725\n",
      "Epoch 245/1000\n",
      " - 12s - loss: 0.1519 - acc: 0.9647 - val_loss: 0.1379 - val_acc: 0.9712\n",
      "Epoch 246/1000\n",
      " - 12s - loss: 0.1525 - acc: 0.9648 - val_loss: 0.1387 - val_acc: 0.9702\n",
      "Epoch 247/1000\n",
      " - 12s - loss: 0.1509 - acc: 0.9649 - val_loss: 0.1325 - val_acc: 0.9720\n",
      "Epoch 248/1000\n",
      " - 12s - loss: 0.1513 - acc: 0.9647 - val_loss: 0.1355 - val_acc: 0.9711\n",
      "Epoch 249/1000\n",
      " - 12s - loss: 0.1525 - acc: 0.9648 - val_loss: 0.1340 - val_acc: 0.9721\n",
      "Epoch 250/1000\n",
      " - 12s - loss: 0.1521 - acc: 0.9645 - val_loss: 0.1325 - val_acc: 0.9721\n",
      "Epoch 251/1000\n",
      " - 12s - loss: 0.1520 - acc: 0.9645 - val_loss: 0.1384 - val_acc: 0.9696\n",
      "Epoch 252/1000\n",
      " - 12s - loss: 0.1509 - acc: 0.9651 - val_loss: 0.1346 - val_acc: 0.9711\n",
      "Epoch 253/1000\n",
      " - 12s - loss: 0.1515 - acc: 0.9649 - val_loss: 0.1398 - val_acc: 0.9703\n",
      "Epoch 254/1000\n",
      " - 12s - loss: 0.1514 - acc: 0.9651 - val_loss: 0.1358 - val_acc: 0.9712\n",
      "Epoch 255/1000\n",
      " - 12s - loss: 0.1517 - acc: 0.9651 - val_loss: 0.1381 - val_acc: 0.9703\n",
      "Epoch 256/1000\n",
      " - 12s - loss: 0.1512 - acc: 0.9649 - val_loss: 0.1303 - val_acc: 0.9738\n",
      "Epoch 257/1000\n",
      " - 12s - loss: 0.1510 - acc: 0.9652 - val_loss: 0.1394 - val_acc: 0.9691\n",
      "Epoch 258/1000\n",
      " - 12s - loss: 0.1512 - acc: 0.9651 - val_loss: 0.1374 - val_acc: 0.9706\n",
      "Epoch 259/1000\n",
      " - 12s - loss: 0.1518 - acc: 0.9646 - val_loss: 0.1418 - val_acc: 0.9681\n",
      "Epoch 260/1000\n",
      " - 12s - loss: 0.1504 - acc: 0.9653 - val_loss: 0.1346 - val_acc: 0.9713\n",
      "Epoch 261/1000\n",
      " - 12s - loss: 0.1511 - acc: 0.9651 - val_loss: 0.1368 - val_acc: 0.9717\n",
      "Epoch 262/1000\n",
      " - 12s - loss: 0.1512 - acc: 0.9647 - val_loss: 0.1326 - val_acc: 0.9735\n",
      "Epoch 263/1000\n",
      " - 12s - loss: 0.1508 - acc: 0.9651 - val_loss: 0.1356 - val_acc: 0.9714\n",
      "Epoch 264/1000\n",
      " - 12s - loss: 0.1518 - acc: 0.9648 - val_loss: 0.1358 - val_acc: 0.9720\n",
      "Epoch 265/1000\n",
      " - 12s - loss: 0.1511 - acc: 0.9649 - val_loss: 0.1385 - val_acc: 0.9698\n",
      "Epoch 266/1000\n",
      " - 12s - loss: 0.1507 - acc: 0.9651 - val_loss: 0.1447 - val_acc: 0.9677\n",
      "Epoch 267/1000\n",
      " - 12s - loss: 0.1502 - acc: 0.9653 - val_loss: 0.1423 - val_acc: 0.9679\n",
      "Epoch 268/1000\n",
      " - 12s - loss: 0.1515 - acc: 0.9651 - val_loss: 0.1419 - val_acc: 0.9681\n",
      "Epoch 269/1000\n",
      " - 12s - loss: 0.1506 - acc: 0.9653 - val_loss: 0.1350 - val_acc: 0.9724\n",
      "Epoch 270/1000\n",
      " - 12s - loss: 0.1498 - acc: 0.9659 - val_loss: 0.1393 - val_acc: 0.9704\n",
      "Epoch 271/1000\n",
      " - 12s - loss: 0.1504 - acc: 0.9654 - val_loss: 0.1343 - val_acc: 0.9719\n",
      "Epoch 272/1000\n",
      " - 12s - loss: 0.1504 - acc: 0.9656 - val_loss: 0.1342 - val_acc: 0.9718\n",
      "Epoch 273/1000\n",
      " - 12s - loss: 0.1502 - acc: 0.9654 - val_loss: 0.1379 - val_acc: 0.9699\n",
      "Epoch 274/1000\n",
      " - 12s - loss: 0.1502 - acc: 0.9654 - val_loss: 0.1364 - val_acc: 0.9714\n",
      "Epoch 275/1000\n",
      " - 12s - loss: 0.1503 - acc: 0.9653 - val_loss: 0.1347 - val_acc: 0.9716\n",
      "Epoch 276/1000\n",
      " - 12s - loss: 0.1498 - acc: 0.9656 - val_loss: 0.1422 - val_acc: 0.9687\n",
      "Epoch 277/1000\n",
      " - 12s - loss: 0.1506 - acc: 0.9656 - val_loss: 0.1312 - val_acc: 0.9725\n",
      "Epoch 278/1000\n",
      " - 12s - loss: 0.1499 - acc: 0.9654 - val_loss: 0.1326 - val_acc: 0.9721\n",
      "Epoch 279/1000\n",
      " - 12s - loss: 0.1507 - acc: 0.9651 - val_loss: 0.1329 - val_acc: 0.9738\n",
      "Epoch 280/1000\n",
      " - 12s - loss: 0.1499 - acc: 0.9661 - val_loss: 0.1395 - val_acc: 0.9701\n",
      "Epoch 281/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9656 - val_loss: 0.1306 - val_acc: 0.9731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 282/1000\n",
      " - 12s - loss: 0.1506 - acc: 0.9654 - val_loss: 0.1395 - val_acc: 0.9699\n",
      "Epoch 283/1000\n",
      " - 12s - loss: 0.1499 - acc: 0.9660 - val_loss: 0.1353 - val_acc: 0.9716\n",
      "Epoch 284/1000\n",
      " - 12s - loss: 0.1497 - acc: 0.9655 - val_loss: 0.1335 - val_acc: 0.9726\n",
      "Epoch 285/1000\n",
      " - 12s - loss: 0.1492 - acc: 0.9660 - val_loss: 0.1398 - val_acc: 0.9689\n",
      "Epoch 286/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9659 - val_loss: 0.1337 - val_acc: 0.9720\n",
      "Epoch 287/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9657 - val_loss: 0.1490 - val_acc: 0.9648\n",
      "Epoch 288/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9654 - val_loss: 0.1359 - val_acc: 0.9714\n",
      "Epoch 289/1000\n",
      " - 12s - loss: 0.1490 - acc: 0.9662 - val_loss: 0.1357 - val_acc: 0.9711\n",
      "Epoch 290/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9659 - val_loss: 0.1480 - val_acc: 0.9653\n",
      "Epoch 291/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9655 - val_loss: 0.1305 - val_acc: 0.9735\n",
      "Epoch 292/1000\n",
      " - 12s - loss: 0.1487 - acc: 0.9661 - val_loss: 0.1309 - val_acc: 0.9733\n",
      "Epoch 293/1000\n",
      " - 12s - loss: 0.1494 - acc: 0.9660 - val_loss: 0.1326 - val_acc: 0.9718\n",
      "Epoch 294/1000\n",
      " - 12s - loss: 0.1492 - acc: 0.9661 - val_loss: 0.1360 - val_acc: 0.9715\n",
      "Epoch 295/1000\n",
      " - 12s - loss: 0.1488 - acc: 0.9659 - val_loss: 0.1298 - val_acc: 0.9744\n",
      "Epoch 296/1000\n",
      " - 12s - loss: 0.1491 - acc: 0.9663 - val_loss: 0.1349 - val_acc: 0.9715\n",
      "Epoch 297/1000\n",
      " - 12s - loss: 0.1497 - acc: 0.9658 - val_loss: 0.1429 - val_acc: 0.9684\n",
      "Epoch 298/1000\n",
      " - 12s - loss: 0.1501 - acc: 0.9659 - val_loss: 0.1310 - val_acc: 0.9732\n",
      "Epoch 299/1000\n",
      " - 12s - loss: 0.1488 - acc: 0.9661 - val_loss: 0.1375 - val_acc: 0.9698\n",
      "Epoch 300/1000\n",
      " - 12s - loss: 0.1490 - acc: 0.9660 - val_loss: 0.1329 - val_acc: 0.9719\n",
      "Epoch 301/1000\n",
      " - 12s - loss: 0.1489 - acc: 0.9661 - val_loss: 0.1288 - val_acc: 0.9741\n",
      "Epoch 302/1000\n",
      " - 12s - loss: 0.1493 - acc: 0.9658 - val_loss: 0.1391 - val_acc: 0.9700\n",
      "Epoch 303/1000\n",
      " - 12s - loss: 0.1490 - acc: 0.9659 - val_loss: 0.1272 - val_acc: 0.9749\n",
      "Epoch 304/1000\n",
      " - 12s - loss: 0.1488 - acc: 0.9664 - val_loss: 0.1364 - val_acc: 0.9718\n",
      "Epoch 305/1000\n",
      " - 12s - loss: 0.1494 - acc: 0.9662 - val_loss: 0.1357 - val_acc: 0.9710\n",
      "Epoch 306/1000\n",
      " - 12s - loss: 0.1484 - acc: 0.9663 - val_loss: 0.1312 - val_acc: 0.9726\n",
      "Epoch 307/1000\n",
      " - 12s - loss: 0.1486 - acc: 0.9666 - val_loss: 0.1403 - val_acc: 0.9694\n",
      "Epoch 308/1000\n",
      " - 12s - loss: 0.1484 - acc: 0.9661 - val_loss: 0.1395 - val_acc: 0.9695\n",
      "Epoch 309/1000\n",
      " - 12s - loss: 0.1484 - acc: 0.9663 - val_loss: 0.1296 - val_acc: 0.9733\n",
      "Epoch 310/1000\n",
      " - 12s - loss: 0.1482 - acc: 0.9664 - val_loss: 0.1342 - val_acc: 0.9728\n",
      "Epoch 311/1000\n",
      " - 12s - loss: 0.1486 - acc: 0.9661 - val_loss: 0.1391 - val_acc: 0.9700\n",
      "Epoch 312/1000\n",
      " - 12s - loss: 0.1496 - acc: 0.9657 - val_loss: 0.1358 - val_acc: 0.9714\n",
      "Epoch 313/1000\n",
      " - 12s - loss: 0.1479 - acc: 0.9664 - val_loss: 0.1345 - val_acc: 0.9725\n",
      "Epoch 314/1000\n",
      " - 12s - loss: 0.1486 - acc: 0.9664 - val_loss: 0.1314 - val_acc: 0.9737\n",
      "Epoch 315/1000\n",
      " - 12s - loss: 0.1481 - acc: 0.9664 - val_loss: 0.1284 - val_acc: 0.9743\n",
      "Epoch 316/1000\n",
      " - 12s - loss: 0.1487 - acc: 0.9663 - val_loss: 0.1372 - val_acc: 0.9709\n",
      "Epoch 317/1000\n",
      " - 12s - loss: 0.1488 - acc: 0.9660 - val_loss: 0.1336 - val_acc: 0.9717\n",
      "Epoch 318/1000\n",
      " - 12s - loss: 0.1477 - acc: 0.9669 - val_loss: 0.1274 - val_acc: 0.9746\n",
      "Epoch 319/1000\n",
      " - 12s - loss: 0.1479 - acc: 0.9667 - val_loss: 0.1358 - val_acc: 0.9710\n",
      "Epoch 320/1000\n",
      " - 12s - loss: 0.1483 - acc: 0.9665 - val_loss: 0.1340 - val_acc: 0.9724\n",
      "Epoch 321/1000\n",
      " - 12s - loss: 0.1482 - acc: 0.9664 - val_loss: 0.1326 - val_acc: 0.9722\n",
      "Epoch 322/1000\n",
      " - 12s - loss: 0.1480 - acc: 0.9666 - val_loss: 0.1327 - val_acc: 0.9729\n",
      "Epoch 323/1000\n",
      " - 12s - loss: 0.1472 - acc: 0.9666 - val_loss: 0.1329 - val_acc: 0.9740\n",
      "Epoch 324/1000\n",
      " - 12s - loss: 0.1489 - acc: 0.9663 - val_loss: 0.1346 - val_acc: 0.9720\n",
      "Epoch 325/1000\n",
      " - 12s - loss: 0.1490 - acc: 0.9660 - val_loss: 0.1287 - val_acc: 0.9750\n",
      "Epoch 326/1000\n",
      " - 12s - loss: 0.1471 - acc: 0.9669 - val_loss: 0.1318 - val_acc: 0.9737\n",
      "Epoch 327/1000\n",
      " - 12s - loss: 0.1483 - acc: 0.9664 - val_loss: 0.1286 - val_acc: 0.9743\n",
      "Epoch 328/1000\n",
      " - 12s - loss: 0.1483 - acc: 0.9663 - val_loss: 0.1305 - val_acc: 0.9737\n",
      "Epoch 329/1000\n",
      " - 12s - loss: 0.1477 - acc: 0.9667 - val_loss: 0.1328 - val_acc: 0.9726\n",
      "Epoch 330/1000\n",
      " - 12s - loss: 0.1479 - acc: 0.9664 - val_loss: 0.1329 - val_acc: 0.9727\n",
      "Epoch 331/1000\n",
      " - 12s - loss: 0.1474 - acc: 0.9670 - val_loss: 0.1329 - val_acc: 0.9729\n",
      "Epoch 332/1000\n",
      " - 12s - loss: 0.1473 - acc: 0.9671 - val_loss: 0.1312 - val_acc: 0.9728\n",
      "Epoch 333/1000\n",
      " - 12s - loss: 0.1480 - acc: 0.9666 - val_loss: 0.1311 - val_acc: 0.9724\n",
      "Epoch 334/1000\n",
      " - 12s - loss: 0.1473 - acc: 0.9669 - val_loss: 0.1273 - val_acc: 0.9747\n",
      "Epoch 335/1000\n",
      " - 12s - loss: 0.1472 - acc: 0.9666 - val_loss: 0.1324 - val_acc: 0.9738\n",
      "Epoch 336/1000\n",
      " - 12s - loss: 0.1475 - acc: 0.9667 - val_loss: 0.1390 - val_acc: 0.9700\n",
      "Epoch 337/1000\n",
      " - 12s - loss: 0.1464 - acc: 0.9670 - val_loss: 0.1328 - val_acc: 0.9728\n",
      "Epoch 338/1000\n",
      " - 12s - loss: 0.1476 - acc: 0.9667 - val_loss: 0.1304 - val_acc: 0.9737\n",
      "Epoch 339/1000\n",
      " - 12s - loss: 0.1467 - acc: 0.9671 - val_loss: 0.1329 - val_acc: 0.9726\n",
      "Epoch 340/1000\n",
      " - 12s - loss: 0.1473 - acc: 0.9670 - val_loss: 0.1312 - val_acc: 0.9737\n",
      "Epoch 341/1000\n",
      " - 12s - loss: 0.1470 - acc: 0.9667 - val_loss: 0.1282 - val_acc: 0.9746\n",
      "Epoch 342/1000\n",
      " - 12s - loss: 0.1470 - acc: 0.9670 - val_loss: 0.1302 - val_acc: 0.9736\n",
      "Epoch 343/1000\n",
      " - 12s - loss: 0.1484 - acc: 0.9663 - val_loss: 0.1332 - val_acc: 0.9727\n",
      "Epoch 344/1000\n",
      " - 12s - loss: 0.1477 - acc: 0.9667 - val_loss: 0.1301 - val_acc: 0.9739\n",
      "Epoch 345/1000\n",
      " - 12s - loss: 0.1469 - acc: 0.9666 - val_loss: 0.1313 - val_acc: 0.9730\n",
      "Epoch 346/1000\n",
      " - 12s - loss: 0.1465 - acc: 0.9673 - val_loss: 0.1288 - val_acc: 0.9749\n",
      "Epoch 347/1000\n",
      " - 12s - loss: 0.1467 - acc: 0.9672 - val_loss: 0.1349 - val_acc: 0.9724\n",
      "Epoch 348/1000\n",
      " - 12s - loss: 0.1476 - acc: 0.9667 - val_loss: 0.1299 - val_acc: 0.9746\n",
      "Epoch 349/1000\n",
      " - 12s - loss: 0.1466 - acc: 0.9671 - val_loss: 0.1317 - val_acc: 0.9746\n",
      "Epoch 350/1000\n",
      " - 12s - loss: 0.1463 - acc: 0.9671 - val_loss: 0.1327 - val_acc: 0.9728\n",
      "Epoch 351/1000\n",
      " - 12s - loss: 0.1470 - acc: 0.9669 - val_loss: 0.1302 - val_acc: 0.9738\n",
      "Epoch 352/1000\n",
      " - 12s - loss: 0.1470 - acc: 0.9670 - val_loss: 0.1367 - val_acc: 0.9712\n",
      "Epoch 353/1000\n",
      " - 12s - loss: 0.1470 - acc: 0.9669 - val_loss: 0.1275 - val_acc: 0.9756\n",
      "Epoch 354/1000\n",
      " - 12s - loss: 0.1468 - acc: 0.9673 - val_loss: 0.1315 - val_acc: 0.9734\n",
      "Epoch 355/1000\n",
      " - 12s - loss: 0.1476 - acc: 0.9668 - val_loss: 0.1295 - val_acc: 0.9740\n",
      "Epoch 356/1000\n",
      " - 12s - loss: 0.1472 - acc: 0.9666 - val_loss: 0.1333 - val_acc: 0.9727\n",
      "Epoch 357/1000\n",
      " - 12s - loss: 0.1462 - acc: 0.9673 - val_loss: 0.1365 - val_acc: 0.9704\n",
      "Epoch 358/1000\n",
      " - 12s - loss: 0.1476 - acc: 0.9669 - val_loss: 0.1307 - val_acc: 0.9740\n",
      "Epoch 359/1000\n",
      " - 12s - loss: 0.1460 - acc: 0.9672 - val_loss: 0.1291 - val_acc: 0.9742\n",
      "Epoch 360/1000\n",
      " - 12s - loss: 0.1458 - acc: 0.9676 - val_loss: 0.1275 - val_acc: 0.9749\n",
      "Epoch 361/1000\n",
      " - 12s - loss: 0.1473 - acc: 0.9668 - val_loss: 0.1268 - val_acc: 0.9750\n",
      "Epoch 362/1000\n",
      " - 12s - loss: 0.1465 - acc: 0.9673 - val_loss: 0.1327 - val_acc: 0.9741\n",
      "Epoch 363/1000\n",
      " - 12s - loss: 0.1456 - acc: 0.9677 - val_loss: 0.1305 - val_acc: 0.9742\n",
      "Epoch 364/1000\n",
      " - 12s - loss: 0.1460 - acc: 0.9673 - val_loss: 0.1275 - val_acc: 0.9753\n",
      "Epoch 365/1000\n",
      " - 12s - loss: 0.1468 - acc: 0.9673 - val_loss: 0.1303 - val_acc: 0.9737\n",
      "Epoch 366/1000\n",
      " - 12s - loss: 0.1461 - acc: 0.9675 - val_loss: 0.1284 - val_acc: 0.9741\n",
      "Epoch 367/1000\n",
      " - 12s - loss: 0.1463 - acc: 0.9673 - val_loss: 0.1279 - val_acc: 0.9744\n",
      "Epoch 368/1000\n",
      " - 12s - loss: 0.1466 - acc: 0.9672 - val_loss: 0.1276 - val_acc: 0.9754\n",
      "Epoch 369/1000\n",
      " - 12s - loss: 0.1470 - acc: 0.9673 - val_loss: 0.1294 - val_acc: 0.9758\n",
      "Epoch 370/1000\n",
      " - 12s - loss: 0.1462 - acc: 0.9671 - val_loss: 0.1327 - val_acc: 0.9728\n",
      "Epoch 371/1000\n",
      " - 12s - loss: 0.1462 - acc: 0.9673 - val_loss: 0.1260 - val_acc: 0.9755\n",
      "Epoch 372/1000\n",
      " - 12s - loss: 0.1460 - acc: 0.9677 - val_loss: 0.1295 - val_acc: 0.9737\n",
      "Epoch 373/1000\n",
      " - 12s - loss: 0.1458 - acc: 0.9674 - val_loss: 0.1285 - val_acc: 0.9744\n",
      "Epoch 374/1000\n",
      " - 12s - loss: 0.1460 - acc: 0.9674 - val_loss: 0.1259 - val_acc: 0.9756\n",
      "Epoch 375/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.1468 - acc: 0.9672 - val_loss: 0.1291 - val_acc: 0.9741\n",
      "Epoch 376/1000\n",
      " - 12s - loss: 0.1465 - acc: 0.9672 - val_loss: 0.1311 - val_acc: 0.9729\n",
      "Epoch 377/1000\n",
      " - 12s - loss: 0.1462 - acc: 0.9675 - val_loss: 0.1286 - val_acc: 0.9746\n",
      "Epoch 378/1000\n",
      " - 12s - loss: 0.1469 - acc: 0.9672 - val_loss: 0.1297 - val_acc: 0.9744\n",
      "Epoch 379/1000\n",
      " - 12s - loss: 0.1452 - acc: 0.9677 - val_loss: 0.1254 - val_acc: 0.9761\n",
      "Epoch 380/1000\n",
      " - 12s - loss: 0.1455 - acc: 0.9677 - val_loss: 0.1317 - val_acc: 0.9749\n",
      "Epoch 381/1000\n",
      " - 12s - loss: 0.1461 - acc: 0.9675 - val_loss: 0.1270 - val_acc: 0.9763\n",
      "Epoch 382/1000\n",
      " - 12s - loss: 0.1460 - acc: 0.9677 - val_loss: 0.1335 - val_acc: 0.9730\n",
      "Epoch 383/1000\n",
      " - 12s - loss: 0.1464 - acc: 0.9671 - val_loss: 0.1267 - val_acc: 0.9753\n",
      "Epoch 384/1000\n",
      " - 12s - loss: 0.1457 - acc: 0.9678 - val_loss: 0.1308 - val_acc: 0.9735\n",
      "Epoch 385/1000\n",
      " - 12s - loss: 0.1457 - acc: 0.9679 - val_loss: 0.1302 - val_acc: 0.9745\n",
      "Epoch 386/1000\n",
      " - 12s - loss: 0.1461 - acc: 0.9675 - val_loss: 0.1308 - val_acc: 0.9739\n",
      "Epoch 387/1000\n",
      " - 12s - loss: 0.1463 - acc: 0.9674 - val_loss: 0.1257 - val_acc: 0.9756\n",
      "Epoch 388/1000\n",
      " - 12s - loss: 0.1463 - acc: 0.9676 - val_loss: 0.1321 - val_acc: 0.9732\n",
      "Epoch 389/1000\n",
      " - 12s - loss: 0.1465 - acc: 0.9675 - val_loss: 0.1339 - val_acc: 0.9729\n",
      "Epoch 390/1000\n",
      " - 12s - loss: 0.1451 - acc: 0.9680 - val_loss: 0.1298 - val_acc: 0.9742\n",
      "Epoch 391/1000\n",
      " - 12s - loss: 0.1456 - acc: 0.9678 - val_loss: 0.1262 - val_acc: 0.9753\n",
      "Epoch 392/1000\n",
      " - 12s - loss: 0.1453 - acc: 0.9682 - val_loss: 0.1298 - val_acc: 0.9752\n",
      "Epoch 393/1000\n",
      " - 12s - loss: 0.1464 - acc: 0.9674 - val_loss: 0.1247 - val_acc: 0.9764\n",
      "Epoch 394/1000\n",
      " - 12s - loss: 0.1456 - acc: 0.9677 - val_loss: 0.1280 - val_acc: 0.9763\n",
      "Epoch 395/1000\n",
      " - 12s - loss: 0.1462 - acc: 0.9677 - val_loss: 0.1291 - val_acc: 0.9757\n",
      "Epoch 396/1000\n",
      " - 12s - loss: 0.1459 - acc: 0.9676 - val_loss: 0.1261 - val_acc: 0.9766\n",
      "Epoch 397/1000\n",
      " - 12s - loss: 0.1454 - acc: 0.9677 - val_loss: 0.1294 - val_acc: 0.9738\n",
      "Epoch 398/1000\n",
      " - 12s - loss: 0.1459 - acc: 0.9675 - val_loss: 0.1280 - val_acc: 0.9756\n",
      "Epoch 399/1000\n",
      " - 12s - loss: 0.1447 - acc: 0.9684 - val_loss: 0.1280 - val_acc: 0.9747\n",
      "Epoch 400/1000\n",
      " - 12s - loss: 0.1449 - acc: 0.9678 - val_loss: 0.1312 - val_acc: 0.9750\n",
      "Epoch 401/1000\n",
      " - 12s - loss: 0.1453 - acc: 0.9681 - val_loss: 0.1263 - val_acc: 0.9753\n",
      "Epoch 402/1000\n",
      " - 12s - loss: 0.1463 - acc: 0.9675 - val_loss: 0.1306 - val_acc: 0.9734\n",
      "Epoch 403/1000\n",
      " - 12s - loss: 0.1453 - acc: 0.9677 - val_loss: 0.1315 - val_acc: 0.9735\n",
      "Epoch 404/1000\n",
      " - 12s - loss: 0.1450 - acc: 0.9684 - val_loss: 0.1306 - val_acc: 0.9738\n",
      "Epoch 405/1000\n",
      " - 12s - loss: 0.1447 - acc: 0.9680 - val_loss: 0.1310 - val_acc: 0.9728\n",
      "Epoch 406/1000\n",
      " - 12s - loss: 0.1457 - acc: 0.9677 - val_loss: 0.1247 - val_acc: 0.9763\n",
      "Epoch 407/1000\n",
      " - 12s - loss: 0.1462 - acc: 0.9675 - val_loss: 0.1322 - val_acc: 0.9724\n",
      "Epoch 408/1000\n",
      " - 12s - loss: 0.1456 - acc: 0.9678 - val_loss: 0.1269 - val_acc: 0.9758\n",
      "Epoch 409/1000\n",
      " - 12s - loss: 0.1453 - acc: 0.9679 - val_loss: 0.1335 - val_acc: 0.9723\n",
      "Epoch 410/1000\n",
      " - 12s - loss: 0.1451 - acc: 0.9682 - val_loss: 0.1396 - val_acc: 0.9697\n",
      "Epoch 411/1000\n",
      " - 12s - loss: 0.1465 - acc: 0.9675 - val_loss: 0.1244 - val_acc: 0.9758\n",
      "Epoch 412/1000\n",
      " - 12s - loss: 0.1450 - acc: 0.9682 - val_loss: 0.1253 - val_acc: 0.9758\n",
      "Epoch 413/1000\n",
      " - 12s - loss: 0.1452 - acc: 0.9676 - val_loss: 0.1342 - val_acc: 0.9731\n",
      "Epoch 414/1000\n",
      " - 12s - loss: 0.1444 - acc: 0.9683 - val_loss: 0.1273 - val_acc: 0.9761\n",
      "Epoch 415/1000\n",
      " - 12s - loss: 0.1457 - acc: 0.9679 - val_loss: 0.1292 - val_acc: 0.9742\n",
      "Epoch 416/1000\n",
      " - 12s - loss: 0.1448 - acc: 0.9680 - val_loss: 0.1262 - val_acc: 0.9768\n",
      "Epoch 417/1000\n",
      " - 12s - loss: 0.1451 - acc: 0.9680 - val_loss: 0.1471 - val_acc: 0.9670\n",
      "Epoch 418/1000\n",
      " - 12s - loss: 0.1448 - acc: 0.9683 - val_loss: 0.1273 - val_acc: 0.9750\n",
      "Epoch 419/1000\n",
      " - 12s - loss: 0.1450 - acc: 0.9678 - val_loss: 0.1271 - val_acc: 0.9752\n",
      "Epoch 420/1000\n",
      " - 12s - loss: 0.1450 - acc: 0.9678 - val_loss: 0.1306 - val_acc: 0.9733\n",
      "Epoch 421/1000\n",
      " - 12s - loss: 0.1449 - acc: 0.9682 - val_loss: 0.1266 - val_acc: 0.9756\n",
      "Epoch 422/1000\n",
      " - 12s - loss: 0.1449 - acc: 0.9681 - val_loss: 0.1305 - val_acc: 0.9730\n",
      "Epoch 423/1000\n",
      " - 12s - loss: 0.1444 - acc: 0.9683 - val_loss: 0.1304 - val_acc: 0.9746\n",
      "Epoch 424/1000\n",
      " - 12s - loss: 0.1446 - acc: 0.9684 - val_loss: 0.1294 - val_acc: 0.9736\n",
      "Epoch 425/1000\n",
      " - 12s - loss: 0.1455 - acc: 0.9678 - val_loss: 0.1341 - val_acc: 0.9724\n",
      "Epoch 426/1000\n",
      " - 12s - loss: 0.1446 - acc: 0.9681 - val_loss: 0.1301 - val_acc: 0.9729\n",
      "Epoch 427/1000\n",
      " - 12s - loss: 0.1444 - acc: 0.9681 - val_loss: 0.1272 - val_acc: 0.9758\n",
      "Epoch 428/1000\n",
      " - 12s - loss: 0.1448 - acc: 0.9679 - val_loss: 0.1373 - val_acc: 0.9716\n",
      "Epoch 429/1000\n",
      " - 12s - loss: 0.1455 - acc: 0.9680 - val_loss: 0.1275 - val_acc: 0.9753\n",
      "Epoch 430/1000\n",
      " - 12s - loss: 0.1448 - acc: 0.9682 - val_loss: 0.1290 - val_acc: 0.9750\n",
      "Epoch 431/1000\n",
      " - 12s - loss: 0.1446 - acc: 0.9681 - val_loss: 0.1307 - val_acc: 0.9741\n",
      "Epoch 432/1000\n",
      " - 12s - loss: 0.1443 - acc: 0.9686 - val_loss: 0.1257 - val_acc: 0.9759\n",
      "Epoch 433/1000\n",
      " - 12s - loss: 0.1448 - acc: 0.9680 - val_loss: 0.1266 - val_acc: 0.9752\n",
      "Epoch 434/1000\n",
      " - 12s - loss: 0.1446 - acc: 0.9681 - val_loss: 0.1286 - val_acc: 0.9767\n",
      "Epoch 435/1000\n",
      " - 12s - loss: 0.1440 - acc: 0.9684 - val_loss: 0.1271 - val_acc: 0.9745\n",
      "Epoch 436/1000\n",
      " - 12s - loss: 0.1444 - acc: 0.9682 - val_loss: 0.1233 - val_acc: 0.9765\n",
      "Epoch 437/1000\n",
      " - 12s - loss: 0.1447 - acc: 0.9685 - val_loss: 0.1259 - val_acc: 0.9763\n",
      "Epoch 438/1000\n",
      " - 12s - loss: 0.1443 - acc: 0.9683 - val_loss: 0.1236 - val_acc: 0.9762\n",
      "Epoch 439/1000\n",
      " - 12s - loss: 0.1449 - acc: 0.9682 - val_loss: 0.1259 - val_acc: 0.9754\n",
      "Epoch 440/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9685 - val_loss: 0.1236 - val_acc: 0.9770\n",
      "Epoch 441/1000\n",
      " - 12s - loss: 0.1450 - acc: 0.9680 - val_loss: 0.1288 - val_acc: 0.9739\n",
      "Epoch 442/1000\n",
      " - 12s - loss: 0.1441 - acc: 0.9684 - val_loss: 0.1268 - val_acc: 0.9756\n",
      "Epoch 443/1000\n",
      " - 12s - loss: 0.1442 - acc: 0.9682 - val_loss: 0.1290 - val_acc: 0.9743\n",
      "Epoch 444/1000\n",
      " - 12s - loss: 0.1445 - acc: 0.9683 - val_loss: 0.1248 - val_acc: 0.9765\n",
      "Epoch 445/1000\n",
      " - 12s - loss: 0.1445 - acc: 0.9681 - val_loss: 0.1275 - val_acc: 0.9745\n",
      "Epoch 446/1000\n",
      " - 12s - loss: 0.1439 - acc: 0.9684 - val_loss: 0.1300 - val_acc: 0.9744\n",
      "Epoch 447/1000\n",
      " - 12s - loss: 0.1439 - acc: 0.9687 - val_loss: 0.1333 - val_acc: 0.9727\n",
      "Epoch 448/1000\n",
      " - 12s - loss: 0.1439 - acc: 0.9684 - val_loss: 0.1433 - val_acc: 0.9692\n",
      "Epoch 449/1000\n",
      " - 12s - loss: 0.1440 - acc: 0.9682 - val_loss: 0.1293 - val_acc: 0.9750\n",
      "Epoch 450/1000\n",
      " - 12s - loss: 0.1446 - acc: 0.9682 - val_loss: 0.1247 - val_acc: 0.9758\n",
      "Epoch 451/1000\n",
      " - 12s - loss: 0.1447 - acc: 0.9684 - val_loss: 0.1231 - val_acc: 0.9768\n",
      "Epoch 452/1000\n",
      " - 12s - loss: 0.1441 - acc: 0.9685 - val_loss: 0.1235 - val_acc: 0.9764\n",
      "Epoch 453/1000\n",
      " - 12s - loss: 0.1443 - acc: 0.9681 - val_loss: 0.1374 - val_acc: 0.9712\n",
      "Epoch 454/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9684 - val_loss: 0.1286 - val_acc: 0.9750\n",
      "Epoch 455/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9687 - val_loss: 0.1247 - val_acc: 0.9766\n",
      "Epoch 456/1000\n",
      " - 12s - loss: 0.1447 - acc: 0.9680 - val_loss: 0.1255 - val_acc: 0.9764\n",
      "Epoch 457/1000\n",
      " - 12s - loss: 0.1443 - acc: 0.9682 - val_loss: 0.1276 - val_acc: 0.9751\n",
      "Epoch 458/1000\n",
      " - 12s - loss: 0.1438 - acc: 0.9689 - val_loss: 0.1285 - val_acc: 0.9752\n",
      "Epoch 459/1000\n",
      " - 12s - loss: 0.1440 - acc: 0.9685 - val_loss: 0.1247 - val_acc: 0.9760\n",
      "Epoch 460/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9686 - val_loss: 0.1297 - val_acc: 0.9743\n",
      "Epoch 461/1000\n",
      " - 12s - loss: 0.1435 - acc: 0.9690 - val_loss: 0.1296 - val_acc: 0.9750\n",
      "Epoch 462/1000\n",
      " - 12s - loss: 0.1436 - acc: 0.9683 - val_loss: 0.1288 - val_acc: 0.9759\n",
      "Epoch 463/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9685 - val_loss: 0.1238 - val_acc: 0.9774\n",
      "Epoch 464/1000\n",
      " - 12s - loss: 0.1440 - acc: 0.9687 - val_loss: 0.1254 - val_acc: 0.9753\n",
      "Epoch 465/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9685 - val_loss: 0.1218 - val_acc: 0.9776\n",
      "Epoch 466/1000\n",
      " - 12s - loss: 0.1438 - acc: 0.9684 - val_loss: 0.1267 - val_acc: 0.9751\n",
      "Epoch 467/1000\n",
      " - 12s - loss: 0.1436 - acc: 0.9687 - val_loss: 0.1237 - val_acc: 0.9766\n",
      "Epoch 468/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9686 - val_loss: 0.1266 - val_acc: 0.9760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9685 - val_loss: 0.1341 - val_acc: 0.9759\n",
      "Epoch 470/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9686 - val_loss: 0.1359 - val_acc: 0.9721\n",
      "Epoch 471/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9686 - val_loss: 0.1232 - val_acc: 0.9763\n",
      "Epoch 472/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9687 - val_loss: 0.1249 - val_acc: 0.9759\n",
      "Epoch 473/1000\n",
      " - 12s - loss: 0.1435 - acc: 0.9685 - val_loss: 0.1317 - val_acc: 0.9735\n",
      "Epoch 474/1000\n",
      " - 12s - loss: 0.1436 - acc: 0.9682 - val_loss: 0.1271 - val_acc: 0.9744\n",
      "Epoch 475/1000\n",
      " - 12s - loss: 0.1435 - acc: 0.9686 - val_loss: 0.1294 - val_acc: 0.9754\n",
      "Epoch 476/1000\n",
      " - 12s - loss: 0.1436 - acc: 0.9687 - val_loss: 0.1259 - val_acc: 0.9762\n",
      "Epoch 477/1000\n",
      " - 12s - loss: 0.1429 - acc: 0.9689 - val_loss: 0.1256 - val_acc: 0.9764\n",
      "Epoch 478/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9684 - val_loss: 0.1235 - val_acc: 0.9771\n",
      "Epoch 479/1000\n",
      " - 12s - loss: 0.1441 - acc: 0.9685 - val_loss: 0.1276 - val_acc: 0.9748\n",
      "Epoch 480/1000\n",
      " - 12s - loss: 0.1444 - acc: 0.9685 - val_loss: 0.1267 - val_acc: 0.9751\n",
      "Epoch 481/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9686 - val_loss: 0.1237 - val_acc: 0.9768\n",
      "Epoch 482/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9690 - val_loss: 0.1241 - val_acc: 0.9762\n",
      "Epoch 483/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9686 - val_loss: 0.1248 - val_acc: 0.9763\n",
      "Epoch 484/1000\n",
      " - 12s - loss: 0.1428 - acc: 0.9688 - val_loss: 0.1270 - val_acc: 0.9748\n",
      "Epoch 485/1000\n",
      " - 12s - loss: 0.1442 - acc: 0.9688 - val_loss: 0.1273 - val_acc: 0.9754\n",
      "Epoch 486/1000\n",
      " - 12s - loss: 0.1433 - acc: 0.9684 - val_loss: 0.1226 - val_acc: 0.9769\n",
      "Epoch 487/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9688 - val_loss: 0.1233 - val_acc: 0.9769\n",
      "Epoch 488/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9688 - val_loss: 0.1263 - val_acc: 0.9758\n",
      "Epoch 489/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9688 - val_loss: 0.1242 - val_acc: 0.9760\n",
      "Epoch 490/1000\n",
      " - 12s - loss: 0.1438 - acc: 0.9688 - val_loss: 0.1219 - val_acc: 0.9777\n",
      "Epoch 491/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9689 - val_loss: 0.1235 - val_acc: 0.9770\n",
      "Epoch 492/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9689 - val_loss: 0.1292 - val_acc: 0.9744\n",
      "Epoch 493/1000\n",
      " - 12s - loss: 0.1433 - acc: 0.9688 - val_loss: 0.1237 - val_acc: 0.9765\n",
      "Epoch 494/1000\n",
      " - 12s - loss: 0.1427 - acc: 0.9690 - val_loss: 0.1265 - val_acc: 0.9757\n",
      "Epoch 495/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9692 - val_loss: 0.1352 - val_acc: 0.9710\n",
      "Epoch 496/1000\n",
      " - 12s - loss: 0.1426 - acc: 0.9692 - val_loss: 0.1240 - val_acc: 0.9768\n",
      "Epoch 497/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9691 - val_loss: 0.1235 - val_acc: 0.9771\n",
      "Epoch 498/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9687 - val_loss: 0.1233 - val_acc: 0.9772\n",
      "Epoch 499/1000\n",
      " - 12s - loss: 0.1437 - acc: 0.9687 - val_loss: 0.1254 - val_acc: 0.9760\n",
      "Epoch 500/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9689 - val_loss: 0.1273 - val_acc: 0.9747\n",
      "Epoch 501/1000\n",
      " - 12s - loss: 0.1424 - acc: 0.9694 - val_loss: 0.1242 - val_acc: 0.9766\n",
      "Epoch 502/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9690 - val_loss: 0.1255 - val_acc: 0.9761\n",
      "Epoch 503/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9693 - val_loss: 0.1278 - val_acc: 0.9759\n",
      "Epoch 504/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9688 - val_loss: 0.1248 - val_acc: 0.9762\n",
      "Epoch 505/1000\n",
      " - 12s - loss: 0.1436 - acc: 0.9687 - val_loss: 0.1255 - val_acc: 0.9753\n",
      "Epoch 506/1000\n",
      " - 12s - loss: 0.1429 - acc: 0.9690 - val_loss: 0.1268 - val_acc: 0.9761\n",
      "Epoch 507/1000\n",
      " - 12s - loss: 0.1424 - acc: 0.9693 - val_loss: 0.1260 - val_acc: 0.9759\n",
      "Epoch 508/1000\n",
      " - 12s - loss: 0.1422 - acc: 0.9689 - val_loss: 0.1267 - val_acc: 0.9769\n",
      "Epoch 509/1000\n",
      " - 12s - loss: 0.1428 - acc: 0.9691 - val_loss: 0.1246 - val_acc: 0.9765\n",
      "Epoch 510/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9692 - val_loss: 0.1225 - val_acc: 0.9767\n",
      "Epoch 511/1000\n",
      " - 12s - loss: 0.1434 - acc: 0.9686 - val_loss: 0.1302 - val_acc: 0.9740\n",
      "Epoch 512/1000\n",
      " - 12s - loss: 0.1435 - acc: 0.9687 - val_loss: 0.1231 - val_acc: 0.9773\n",
      "Epoch 513/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9687 - val_loss: 0.1277 - val_acc: 0.9752\n",
      "Epoch 514/1000\n",
      " - 12s - loss: 0.1427 - acc: 0.9694 - val_loss: 0.1287 - val_acc: 0.9745\n",
      "Epoch 515/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9688 - val_loss: 0.1282 - val_acc: 0.9752\n",
      "Epoch 516/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9689 - val_loss: 0.1250 - val_acc: 0.9762\n",
      "Epoch 517/1000\n",
      " - 12s - loss: 0.1433 - acc: 0.9688 - val_loss: 0.1222 - val_acc: 0.9772\n",
      "Epoch 518/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9692 - val_loss: 0.1236 - val_acc: 0.9769\n",
      "Epoch 519/1000\n",
      " - 12s - loss: 0.1422 - acc: 0.9694 - val_loss: 0.1252 - val_acc: 0.9763\n",
      "Epoch 520/1000\n",
      " - 12s - loss: 0.1433 - acc: 0.9690 - val_loss: 0.1240 - val_acc: 0.9763\n",
      "Epoch 521/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9689 - val_loss: 0.1219 - val_acc: 0.9768\n",
      "Epoch 522/1000\n",
      " - 12s - loss: 0.1427 - acc: 0.9690 - val_loss: 0.1216 - val_acc: 0.9777\n",
      "Epoch 523/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9693 - val_loss: 0.1248 - val_acc: 0.9761\n",
      "Epoch 524/1000\n",
      " - 12s - loss: 0.1427 - acc: 0.9694 - val_loss: 0.1252 - val_acc: 0.9759\n",
      "Epoch 525/1000\n",
      " - 12s - loss: 0.1428 - acc: 0.9690 - val_loss: 0.1265 - val_acc: 0.9759\n",
      "Epoch 526/1000\n",
      " - 12s - loss: 0.1427 - acc: 0.9693 - val_loss: 0.1264 - val_acc: 0.9763\n",
      "Epoch 527/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9691 - val_loss: 0.1249 - val_acc: 0.9754\n",
      "Epoch 528/1000\n",
      " - 12s - loss: 0.1422 - acc: 0.9697 - val_loss: 0.1247 - val_acc: 0.9760\n",
      "Epoch 529/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9694 - val_loss: 0.1257 - val_acc: 0.9756\n",
      "Epoch 530/1000\n",
      " - 12s - loss: 0.1416 - acc: 0.9695 - val_loss: 0.1272 - val_acc: 0.9754\n",
      "Epoch 531/1000\n",
      " - 12s - loss: 0.1417 - acc: 0.9695 - val_loss: 0.1267 - val_acc: 0.9755\n",
      "Epoch 532/1000\n",
      " - 12s - loss: 0.1432 - acc: 0.9693 - val_loss: 0.1291 - val_acc: 0.9742\n",
      "Epoch 533/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9690 - val_loss: 0.1248 - val_acc: 0.9764\n",
      "Epoch 534/1000\n",
      " - 12s - loss: 0.1424 - acc: 0.9691 - val_loss: 0.1232 - val_acc: 0.9773\n",
      "Epoch 535/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9694 - val_loss: 0.1247 - val_acc: 0.9759\n",
      "Epoch 536/1000\n",
      " - 12s - loss: 0.1415 - acc: 0.9696 - val_loss: 0.1269 - val_acc: 0.9753\n",
      "Epoch 537/1000\n",
      " - 12s - loss: 0.1428 - acc: 0.9688 - val_loss: 0.1196 - val_acc: 0.9779\n",
      "Epoch 538/1000\n",
      " - 12s - loss: 0.1417 - acc: 0.9694 - val_loss: 0.1273 - val_acc: 0.9760\n",
      "Epoch 539/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9696 - val_loss: 0.1246 - val_acc: 0.9760\n",
      "Epoch 540/1000\n",
      " - 12s - loss: 0.1428 - acc: 0.9693 - val_loss: 0.1266 - val_acc: 0.9752\n",
      "Epoch 541/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9692 - val_loss: 0.1207 - val_acc: 0.9778\n",
      "Epoch 542/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9692 - val_loss: 0.1260 - val_acc: 0.9755\n",
      "Epoch 543/1000\n",
      " - 12s - loss: 0.1431 - acc: 0.9692 - val_loss: 0.1316 - val_acc: 0.9731\n",
      "Epoch 544/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9691 - val_loss: 0.1225 - val_acc: 0.9768\n",
      "Epoch 545/1000\n",
      " - 12s - loss: 0.1421 - acc: 0.9691 - val_loss: 0.1237 - val_acc: 0.9774\n",
      "Epoch 546/1000\n",
      " - 12s - loss: 0.1426 - acc: 0.9691 - val_loss: 0.1257 - val_acc: 0.9758\n",
      "Epoch 547/1000\n",
      " - 12s - loss: 0.1428 - acc: 0.9688 - val_loss: 0.1226 - val_acc: 0.9768\n",
      "Epoch 548/1000\n",
      " - 12s - loss: 0.1430 - acc: 0.9690 - val_loss: 0.1211 - val_acc: 0.9776\n",
      "Epoch 549/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9696 - val_loss: 0.1234 - val_acc: 0.9769\n",
      "Epoch 550/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9693 - val_loss: 0.1221 - val_acc: 0.9773\n",
      "Epoch 551/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9692 - val_loss: 0.1236 - val_acc: 0.9764\n",
      "Epoch 552/1000\n",
      " - 12s - loss: 0.1419 - acc: 0.9696 - val_loss: 0.1267 - val_acc: 0.9749\n",
      "Epoch 553/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9699 - val_loss: 0.1223 - val_acc: 0.9784\n",
      "Epoch 554/1000\n",
      " - 12s - loss: 0.1421 - acc: 0.9693 - val_loss: 0.1252 - val_acc: 0.9755\n",
      "Epoch 555/1000\n",
      " - 12s - loss: 0.1425 - acc: 0.9694 - val_loss: 0.1244 - val_acc: 0.9759\n",
      "Epoch 556/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9693 - val_loss: 0.1290 - val_acc: 0.9741\n",
      "Epoch 557/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9694 - val_loss: 0.1285 - val_acc: 0.9757\n",
      "Epoch 558/1000\n",
      " - 12s - loss: 0.1419 - acc: 0.9694 - val_loss: 0.1254 - val_acc: 0.9766\n",
      "Epoch 559/1000\n",
      " - 12s - loss: 0.1421 - acc: 0.9697 - val_loss: 0.1362 - val_acc: 0.9714\n",
      "Epoch 560/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9700 - val_loss: 0.1256 - val_acc: 0.9755\n",
      "Epoch 561/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9694 - val_loss: 0.1247 - val_acc: 0.9763\n",
      "Epoch 562/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.1411 - acc: 0.9698 - val_loss: 0.1241 - val_acc: 0.9758\n",
      "Epoch 563/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9696 - val_loss: 0.1225 - val_acc: 0.9771\n",
      "Epoch 564/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9697 - val_loss: 0.1217 - val_acc: 0.9770\n",
      "Epoch 565/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9696 - val_loss: 0.1224 - val_acc: 0.9771\n",
      "Epoch 566/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9697 - val_loss: 0.1250 - val_acc: 0.9774\n",
      "Epoch 567/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9696 - val_loss: 0.1240 - val_acc: 0.9767\n",
      "Epoch 568/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9697 - val_loss: 0.1241 - val_acc: 0.9774\n",
      "Epoch 569/1000\n",
      " - 12s - loss: 0.1421 - acc: 0.9694 - val_loss: 0.1272 - val_acc: 0.9777\n",
      "Epoch 570/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9696 - val_loss: 0.1237 - val_acc: 0.9768\n",
      "Epoch 571/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9694 - val_loss: 0.1309 - val_acc: 0.9738\n",
      "Epoch 572/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9694 - val_loss: 0.1244 - val_acc: 0.9770\n",
      "Epoch 573/1000\n",
      " - 12s - loss: 0.1419 - acc: 0.9695 - val_loss: 0.1246 - val_acc: 0.9771\n",
      "Epoch 574/1000\n",
      " - 12s - loss: 0.1419 - acc: 0.9698 - val_loss: 0.1200 - val_acc: 0.9784\n",
      "Epoch 575/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9696 - val_loss: 0.1217 - val_acc: 0.9771\n",
      "Epoch 576/1000\n",
      " - 12s - loss: 0.1417 - acc: 0.9696 - val_loss: 0.1275 - val_acc: 0.9759\n",
      "Epoch 577/1000\n",
      " - 12s - loss: 0.1416 - acc: 0.9697 - val_loss: 0.1237 - val_acc: 0.9770\n",
      "Epoch 578/1000\n",
      " - 12s - loss: 0.1426 - acc: 0.9694 - val_loss: 0.1248 - val_acc: 0.9769\n",
      "Epoch 579/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9694 - val_loss: 0.1246 - val_acc: 0.9776\n",
      "Epoch 580/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9699 - val_loss: 0.1254 - val_acc: 0.9764\n",
      "Epoch 581/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9694 - val_loss: 0.1232 - val_acc: 0.9774\n",
      "Epoch 582/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9693 - val_loss: 0.1234 - val_acc: 0.9764\n",
      "Epoch 583/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9693 - val_loss: 0.1234 - val_acc: 0.9768\n",
      "Epoch 584/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9689 - val_loss: 0.1263 - val_acc: 0.9770\n",
      "Epoch 585/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9699 - val_loss: 0.1260 - val_acc: 0.9764\n",
      "Epoch 586/1000\n",
      " - 12s - loss: 0.1422 - acc: 0.9694 - val_loss: 0.1222 - val_acc: 0.9775\n",
      "Epoch 587/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9693 - val_loss: 0.1271 - val_acc: 0.9756\n",
      "Epoch 588/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9694 - val_loss: 0.1212 - val_acc: 0.9778\n",
      "Epoch 589/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9698 - val_loss: 0.1241 - val_acc: 0.9771\n",
      "Epoch 590/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9694 - val_loss: 0.1236 - val_acc: 0.9770\n",
      "Epoch 591/1000\n",
      " - 12s - loss: 0.1416 - acc: 0.9696 - val_loss: 0.1292 - val_acc: 0.9741\n",
      "Epoch 592/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9690 - val_loss: 0.1303 - val_acc: 0.9738\n",
      "Epoch 593/1000\n",
      " - 12s - loss: 0.1419 - acc: 0.9696 - val_loss: 0.1303 - val_acc: 0.9742\n",
      "Epoch 594/1000\n",
      " - 12s - loss: 0.1416 - acc: 0.9697 - val_loss: 0.1304 - val_acc: 0.9763\n",
      "Epoch 595/1000\n",
      " - 12s - loss: 0.1423 - acc: 0.9696 - val_loss: 0.1217 - val_acc: 0.9773\n",
      "Epoch 596/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9697 - val_loss: 0.1263 - val_acc: 0.9753\n",
      "Epoch 597/1000\n",
      " - 12s - loss: 0.1417 - acc: 0.9697 - val_loss: 0.1299 - val_acc: 0.9747\n",
      "Epoch 598/1000\n",
      " - 12s - loss: 0.1416 - acc: 0.9694 - val_loss: 0.1270 - val_acc: 0.9759\n",
      "Epoch 599/1000\n",
      " - 12s - loss: 0.1408 - acc: 0.9700 - val_loss: 0.1259 - val_acc: 0.9770\n",
      "Epoch 600/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9697 - val_loss: 0.1243 - val_acc: 0.9777\n",
      "Epoch 601/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9700 - val_loss: 0.1240 - val_acc: 0.9777\n",
      "Epoch 602/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9695 - val_loss: 0.1225 - val_acc: 0.9772\n",
      "Epoch 603/1000\n",
      " - 12s - loss: 0.1422 - acc: 0.9695 - val_loss: 0.1239 - val_acc: 0.9765\n",
      "Epoch 604/1000\n",
      " - 12s - loss: 0.1415 - acc: 0.9696 - val_loss: 0.1263 - val_acc: 0.9763\n",
      "Epoch 605/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9697 - val_loss: 0.1232 - val_acc: 0.9771\n",
      "Epoch 606/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9698 - val_loss: 0.1278 - val_acc: 0.9745\n",
      "Epoch 607/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9700 - val_loss: 0.1229 - val_acc: 0.9775\n",
      "Epoch 608/1000\n",
      " - 12s - loss: 0.1416 - acc: 0.9695 - val_loss: 0.1259 - val_acc: 0.9773\n",
      "Epoch 609/1000\n",
      " - 12s - loss: 0.1420 - acc: 0.9695 - val_loss: 0.1266 - val_acc: 0.9759\n",
      "Epoch 610/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9701 - val_loss: 0.1216 - val_acc: 0.9784\n",
      "Epoch 611/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9703 - val_loss: 0.1323 - val_acc: 0.9727\n",
      "Epoch 612/1000\n",
      " - 12s - loss: 0.1414 - acc: 0.9699 - val_loss: 0.1254 - val_acc: 0.9756\n",
      "Epoch 613/1000\n",
      " - 12s - loss: 0.1415 - acc: 0.9698 - val_loss: 0.1200 - val_acc: 0.9780\n",
      "Epoch 614/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9694 - val_loss: 0.1260 - val_acc: 0.9766\n",
      "Epoch 615/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9700 - val_loss: 0.1211 - val_acc: 0.9778\n",
      "Epoch 616/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9700 - val_loss: 0.1223 - val_acc: 0.9773\n",
      "Epoch 617/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9699 - val_loss: 0.1212 - val_acc: 0.9779\n",
      "Epoch 618/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9698 - val_loss: 0.1235 - val_acc: 0.9766\n",
      "Epoch 619/1000\n",
      " - 12s - loss: 0.1404 - acc: 0.9700 - val_loss: 0.1274 - val_acc: 0.9758\n",
      "Epoch 620/1000\n",
      " - 12s - loss: 0.1422 - acc: 0.9698 - val_loss: 0.1216 - val_acc: 0.9777\n",
      "Epoch 621/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9701 - val_loss: 0.1384 - val_acc: 0.9696\n",
      "Epoch 622/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9702 - val_loss: 0.1261 - val_acc: 0.9762\n",
      "Epoch 623/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9700 - val_loss: 0.1254 - val_acc: 0.9756\n",
      "Epoch 624/1000\n",
      " - 12s - loss: 0.1404 - acc: 0.9705 - val_loss: 0.1219 - val_acc: 0.9776\n",
      "Epoch 625/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9699 - val_loss: 0.1274 - val_acc: 0.9751\n",
      "Epoch 626/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9700 - val_loss: 0.1213 - val_acc: 0.9781\n",
      "Epoch 627/1000\n",
      " - 12s - loss: 0.1419 - acc: 0.9695 - val_loss: 0.1252 - val_acc: 0.9762\n",
      "Epoch 628/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9698 - val_loss: 0.1210 - val_acc: 0.9777\n",
      "Epoch 629/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9698 - val_loss: 0.1192 - val_acc: 0.9792\n",
      "Epoch 630/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9700 - val_loss: 0.1193 - val_acc: 0.9788\n",
      "Epoch 631/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9699 - val_loss: 0.1201 - val_acc: 0.9785\n",
      "Epoch 632/1000\n",
      " - 12s - loss: 0.1408 - acc: 0.9699 - val_loss: 0.1216 - val_acc: 0.9775\n",
      "Epoch 633/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9702 - val_loss: 0.1209 - val_acc: 0.9779\n",
      "Epoch 634/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9699 - val_loss: 0.1240 - val_acc: 0.9769\n",
      "Epoch 635/1000\n",
      " - 12s - loss: 0.1418 - acc: 0.9699 - val_loss: 0.1199 - val_acc: 0.9785\n",
      "Epoch 636/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9701 - val_loss: 0.1230 - val_acc: 0.9781\n",
      "Epoch 637/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9702 - val_loss: 0.1219 - val_acc: 0.9774\n",
      "Epoch 638/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9703 - val_loss: 0.1240 - val_acc: 0.9778\n",
      "Epoch 639/1000\n",
      " - 12s - loss: 0.1421 - acc: 0.9696 - val_loss: 0.1192 - val_acc: 0.9782\n",
      "Epoch 640/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9703 - val_loss: 0.1271 - val_acc: 0.9763\n",
      "Epoch 641/1000\n",
      " - 12s - loss: 0.1421 - acc: 0.9695 - val_loss: 0.1216 - val_acc: 0.9779\n",
      "Epoch 642/1000\n",
      " - 12s - loss: 0.1408 - acc: 0.9699 - val_loss: 0.1224 - val_acc: 0.9776\n",
      "Epoch 643/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9705 - val_loss: 0.1287 - val_acc: 0.9753\n",
      "Epoch 644/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9697 - val_loss: 0.1225 - val_acc: 0.9774\n",
      "Epoch 645/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9698 - val_loss: 0.1189 - val_acc: 0.9787\n",
      "Epoch 646/1000\n",
      " - 12s - loss: 0.1408 - acc: 0.9700 - val_loss: 0.1316 - val_acc: 0.9734\n",
      "Epoch 647/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9700 - val_loss: 0.1347 - val_acc: 0.9718\n",
      "Epoch 648/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9699 - val_loss: 0.1244 - val_acc: 0.9761\n",
      "Epoch 649/1000\n",
      " - 12s - loss: 0.1404 - acc: 0.9701 - val_loss: 0.1245 - val_acc: 0.9775\n",
      "Epoch 650/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9699 - val_loss: 0.1230 - val_acc: 0.9772\n",
      "Epoch 651/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9704 - val_loss: 0.1236 - val_acc: 0.9773\n",
      "Epoch 652/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9700 - val_loss: 0.1213 - val_acc: 0.9789\n",
      "Epoch 653/1000\n",
      " - 12s - loss: 0.1404 - acc: 0.9699 - val_loss: 0.1252 - val_acc: 0.9756\n",
      "Epoch 654/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9701 - val_loss: 0.1221 - val_acc: 0.9768\n",
      "Epoch 655/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9700 - val_loss: 0.1245 - val_acc: 0.9770\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 656/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9700 - val_loss: 0.1254 - val_acc: 0.9760\n",
      "Epoch 657/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9701 - val_loss: 0.1224 - val_acc: 0.9776\n",
      "Epoch 658/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9702 - val_loss: 0.1228 - val_acc: 0.9780\n",
      "Epoch 659/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9702 - val_loss: 0.1316 - val_acc: 0.9735\n",
      "Epoch 660/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9703 - val_loss: 0.1228 - val_acc: 0.9780\n",
      "Epoch 661/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9701 - val_loss: 0.1219 - val_acc: 0.9780\n",
      "Epoch 662/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9703 - val_loss: 0.1278 - val_acc: 0.9743\n",
      "Epoch 663/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9704 - val_loss: 0.1237 - val_acc: 0.9776\n",
      "Epoch 664/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9703 - val_loss: 0.1228 - val_acc: 0.9778\n",
      "Epoch 665/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9698 - val_loss: 0.1248 - val_acc: 0.9768\n",
      "Epoch 666/1000\n",
      " - 12s - loss: 0.1412 - acc: 0.9698 - val_loss: 0.1228 - val_acc: 0.9775\n",
      "Epoch 667/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9699 - val_loss: 0.1251 - val_acc: 0.9769\n",
      "Epoch 668/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9699 - val_loss: 0.1212 - val_acc: 0.9777\n",
      "Epoch 669/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9701 - val_loss: 0.1217 - val_acc: 0.9775\n",
      "Epoch 670/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9699 - val_loss: 0.1215 - val_acc: 0.9780\n",
      "Epoch 671/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9703 - val_loss: 0.1292 - val_acc: 0.9746\n",
      "Epoch 672/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9703 - val_loss: 0.1246 - val_acc: 0.9757\n",
      "Epoch 673/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9705 - val_loss: 0.1244 - val_acc: 0.9763\n",
      "Epoch 674/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9702 - val_loss: 0.1228 - val_acc: 0.9782\n",
      "Epoch 675/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9704 - val_loss: 0.1342 - val_acc: 0.9722\n",
      "Epoch 676/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9701 - val_loss: 0.1218 - val_acc: 0.9780\n",
      "Epoch 677/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9702 - val_loss: 0.1226 - val_acc: 0.9776\n",
      "Epoch 678/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9703 - val_loss: 0.1249 - val_acc: 0.9788\n",
      "Epoch 679/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9702 - val_loss: 0.1206 - val_acc: 0.9785\n",
      "Epoch 680/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9703 - val_loss: 0.1225 - val_acc: 0.9777\n",
      "Epoch 681/1000\n",
      " - 12s - loss: 0.1406 - acc: 0.9699 - val_loss: 0.1219 - val_acc: 0.9779\n",
      "Epoch 682/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9701 - val_loss: 0.1309 - val_acc: 0.9730\n",
      "Epoch 683/1000\n",
      " - 12s - loss: 0.1408 - acc: 0.9702 - val_loss: 0.1186 - val_acc: 0.9789\n",
      "Epoch 684/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9702 - val_loss: 0.1213 - val_acc: 0.9772\n",
      "Epoch 685/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9703 - val_loss: 0.1232 - val_acc: 0.9769\n",
      "Epoch 686/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9700 - val_loss: 0.1202 - val_acc: 0.9781\n",
      "Epoch 687/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9703 - val_loss: 0.1192 - val_acc: 0.9782\n",
      "Epoch 688/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9704 - val_loss: 0.1238 - val_acc: 0.9767\n",
      "Epoch 689/1000\n",
      " - 12s - loss: 0.1413 - acc: 0.9703 - val_loss: 0.1251 - val_acc: 0.9774\n",
      "Epoch 690/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9705 - val_loss: 0.1229 - val_acc: 0.9776\n",
      "Epoch 691/1000\n",
      " - 12s - loss: 0.1409 - acc: 0.9703 - val_loss: 0.1248 - val_acc: 0.9764\n",
      "Epoch 692/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9702 - val_loss: 0.1198 - val_acc: 0.9786\n",
      "Epoch 693/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9702 - val_loss: 0.1218 - val_acc: 0.9783\n",
      "Epoch 694/1000\n",
      " - 12s - loss: 0.1404 - acc: 0.9703 - val_loss: 0.1310 - val_acc: 0.9743\n",
      "Epoch 695/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9703 - val_loss: 0.1243 - val_acc: 0.9764\n",
      "Epoch 696/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9704 - val_loss: 0.1204 - val_acc: 0.9787\n",
      "Epoch 697/1000\n",
      " - 12s - loss: 0.1406 - acc: 0.9701 - val_loss: 0.1242 - val_acc: 0.9766\n",
      "Epoch 698/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9705 - val_loss: 0.1266 - val_acc: 0.9762\n",
      "Epoch 699/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9703 - val_loss: 0.1220 - val_acc: 0.9778\n",
      "Epoch 700/1000\n",
      " - 12s - loss: 0.1406 - acc: 0.9702 - val_loss: 0.1279 - val_acc: 0.9752\n",
      "Epoch 701/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9706 - val_loss: 0.1191 - val_acc: 0.9781\n",
      "Epoch 702/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9705 - val_loss: 0.1183 - val_acc: 0.9793\n",
      "Epoch 703/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9704 - val_loss: 0.1200 - val_acc: 0.9788\n",
      "Epoch 704/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9705 - val_loss: 0.1249 - val_acc: 0.9785\n",
      "Epoch 705/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9703 - val_loss: 0.1190 - val_acc: 0.9783\n",
      "Epoch 706/1000\n",
      " - 12s - loss: 0.1410 - acc: 0.9705 - val_loss: 0.1327 - val_acc: 0.9737\n",
      "Epoch 707/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9704 - val_loss: 0.1213 - val_acc: 0.9793\n",
      "Epoch 708/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9707 - val_loss: 0.1242 - val_acc: 0.9785\n",
      "Epoch 709/1000\n",
      " - 12s - loss: 0.1406 - acc: 0.9703 - val_loss: 0.1212 - val_acc: 0.9777\n",
      "Epoch 710/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9704 - val_loss: 0.1218 - val_acc: 0.9777\n",
      "Epoch 711/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9703 - val_loss: 0.1219 - val_acc: 0.9775\n",
      "Epoch 712/1000\n",
      " - 12s - loss: 0.1406 - acc: 0.9705 - val_loss: 0.1193 - val_acc: 0.9786\n",
      "Epoch 713/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9707 - val_loss: 0.1237 - val_acc: 0.9763\n",
      "Epoch 714/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9707 - val_loss: 0.1241 - val_acc: 0.9764\n",
      "Epoch 715/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9701 - val_loss: 0.1246 - val_acc: 0.9770\n",
      "Epoch 716/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9705 - val_loss: 0.1217 - val_acc: 0.9775\n",
      "Epoch 717/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9707 - val_loss: 0.1354 - val_acc: 0.9712\n",
      "Epoch 718/1000\n",
      " - 12s - loss: 0.1406 - acc: 0.9702 - val_loss: 0.1279 - val_acc: 0.9760\n",
      "Epoch 719/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9711 - val_loss: 0.1178 - val_acc: 0.9800\n",
      "Epoch 720/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9701 - val_loss: 0.1184 - val_acc: 0.9793\n",
      "Epoch 721/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9702 - val_loss: 0.1233 - val_acc: 0.9773\n",
      "Epoch 722/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9703 - val_loss: 0.1227 - val_acc: 0.9775\n",
      "Epoch 723/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9702 - val_loss: 0.1372 - val_acc: 0.9717\n",
      "Epoch 724/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9706 - val_loss: 0.1187 - val_acc: 0.9788\n",
      "Epoch 725/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9706 - val_loss: 0.1249 - val_acc: 0.9777\n",
      "Epoch 726/1000\n",
      " - 12s - loss: 0.1411 - acc: 0.9699 - val_loss: 0.1235 - val_acc: 0.9774\n",
      "Epoch 727/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9704 - val_loss: 0.1236 - val_acc: 0.9771\n",
      "Epoch 728/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9705 - val_loss: 0.1219 - val_acc: 0.9778\n",
      "Epoch 729/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9708 - val_loss: 0.1179 - val_acc: 0.9795\n",
      "Epoch 730/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9706 - val_loss: 0.1236 - val_acc: 0.9778\n",
      "Epoch 731/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9703 - val_loss: 0.1223 - val_acc: 0.9768\n",
      "Epoch 732/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9707 - val_loss: 0.1259 - val_acc: 0.9758\n",
      "Epoch 733/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9706 - val_loss: 0.1318 - val_acc: 0.9733\n",
      "Epoch 734/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9704 - val_loss: 0.1207 - val_acc: 0.9785\n",
      "Epoch 735/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9703 - val_loss: 0.1279 - val_acc: 0.9750\n",
      "Epoch 736/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9708 - val_loss: 0.1207 - val_acc: 0.9788\n",
      "Epoch 737/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9708 - val_loss: 0.1172 - val_acc: 0.9796\n",
      "Epoch 738/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9707 - val_loss: 0.1219 - val_acc: 0.9774\n",
      "Epoch 739/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9704 - val_loss: 0.1201 - val_acc: 0.9780\n",
      "Epoch 740/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9707 - val_loss: 0.1215 - val_acc: 0.9779\n",
      "Epoch 741/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9707 - val_loss: 0.1264 - val_acc: 0.9759\n",
      "Epoch 742/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9701 - val_loss: 0.1218 - val_acc: 0.9777\n",
      "Epoch 743/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1283 - val_acc: 0.9745\n",
      "Epoch 744/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9708 - val_loss: 0.1193 - val_acc: 0.9784\n",
      "Epoch 745/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9705 - val_loss: 0.1220 - val_acc: 0.9795\n",
      "Epoch 746/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9707 - val_loss: 0.1209 - val_acc: 0.9778\n",
      "Epoch 747/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9706 - val_loss: 0.1246 - val_acc: 0.9778\n",
      "Epoch 748/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9705 - val_loss: 0.1213 - val_acc: 0.9785\n",
      "Epoch 749/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.1395 - acc: 0.9706 - val_loss: 0.1186 - val_acc: 0.9786\n",
      "Epoch 750/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9705 - val_loss: 0.1197 - val_acc: 0.9788\n",
      "Epoch 751/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9707 - val_loss: 0.1210 - val_acc: 0.9778\n",
      "Epoch 752/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9704 - val_loss: 0.1159 - val_acc: 0.9801\n",
      "Epoch 753/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9706 - val_loss: 0.1289 - val_acc: 0.9754\n",
      "Epoch 754/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9708 - val_loss: 0.1194 - val_acc: 0.9785\n",
      "Epoch 755/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9706 - val_loss: 0.1265 - val_acc: 0.9768\n",
      "Epoch 756/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9705 - val_loss: 0.1192 - val_acc: 0.9793\n",
      "Epoch 757/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9709 - val_loss: 0.1238 - val_acc: 0.9770\n",
      "Epoch 758/1000\n",
      " - 12s - loss: 0.1407 - acc: 0.9703 - val_loss: 0.1210 - val_acc: 0.9776\n",
      "Epoch 759/1000\n",
      " - 12s - loss: 0.1404 - acc: 0.9706 - val_loss: 0.1229 - val_acc: 0.9769\n",
      "Epoch 760/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9707 - val_loss: 0.1232 - val_acc: 0.9769\n",
      "Epoch 761/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1224 - val_acc: 0.9791\n",
      "Epoch 762/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9706 - val_loss: 0.1279 - val_acc: 0.9758\n",
      "Epoch 763/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9708 - val_loss: 0.1264 - val_acc: 0.9755\n",
      "Epoch 764/1000\n",
      " - 12s - loss: 0.1405 - acc: 0.9704 - val_loss: 0.1232 - val_acc: 0.9763\n",
      "Epoch 765/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9706 - val_loss: 0.1220 - val_acc: 0.9778\n",
      "Epoch 766/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9704 - val_loss: 0.1219 - val_acc: 0.9773\n",
      "Epoch 767/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9707 - val_loss: 0.1191 - val_acc: 0.9792\n",
      "Epoch 768/1000\n",
      " - 12s - loss: 0.1403 - acc: 0.9702 - val_loss: 0.1267 - val_acc: 0.9759\n",
      "Epoch 769/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9704 - val_loss: 0.1205 - val_acc: 0.9784\n",
      "Epoch 770/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9706 - val_loss: 0.1277 - val_acc: 0.9763\n",
      "Epoch 771/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1246 - val_acc: 0.9772\n",
      "Epoch 772/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9707 - val_loss: 0.1255 - val_acc: 0.9759\n",
      "Epoch 773/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9709 - val_loss: 0.1246 - val_acc: 0.9775\n",
      "Epoch 774/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9707 - val_loss: 0.1252 - val_acc: 0.9769\n",
      "Epoch 775/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9705 - val_loss: 0.1180 - val_acc: 0.9795\n",
      "Epoch 776/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9707 - val_loss: 0.1200 - val_acc: 0.9786\n",
      "Epoch 777/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9709 - val_loss: 0.1229 - val_acc: 0.9774\n",
      "Epoch 778/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9707 - val_loss: 0.1196 - val_acc: 0.9786\n",
      "Epoch 779/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9709 - val_loss: 0.1192 - val_acc: 0.9787\n",
      "Epoch 780/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9709 - val_loss: 0.1234 - val_acc: 0.9770\n",
      "Epoch 781/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9707 - val_loss: 0.1186 - val_acc: 0.9792\n",
      "Epoch 782/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9707 - val_loss: 0.1211 - val_acc: 0.9778\n",
      "Epoch 783/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9707 - val_loss: 0.1218 - val_acc: 0.9780\n",
      "Epoch 784/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9708 - val_loss: 0.1223 - val_acc: 0.9776\n",
      "Epoch 785/1000\n",
      " - 12s - loss: 0.1401 - acc: 0.9704 - val_loss: 0.1217 - val_acc: 0.9784\n",
      "Epoch 786/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9705 - val_loss: 0.1222 - val_acc: 0.9787\n",
      "Epoch 787/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9709 - val_loss: 0.1193 - val_acc: 0.9785\n",
      "Epoch 788/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9709 - val_loss: 0.1233 - val_acc: 0.9772\n",
      "Epoch 789/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9703 - val_loss: 0.1216 - val_acc: 0.9772\n",
      "Epoch 790/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9711 - val_loss: 0.1218 - val_acc: 0.9780\n",
      "Epoch 791/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9711 - val_loss: 0.1200 - val_acc: 0.9783\n",
      "Epoch 792/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1220 - val_acc: 0.9770\n",
      "Epoch 793/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9708 - val_loss: 0.1217 - val_acc: 0.9774\n",
      "Epoch 794/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9709 - val_loss: 0.1215 - val_acc: 0.9773\n",
      "Epoch 795/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9704 - val_loss: 0.1210 - val_acc: 0.9781\n",
      "Epoch 796/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9707 - val_loss: 0.1227 - val_acc: 0.9781\n",
      "Epoch 797/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9709 - val_loss: 0.1183 - val_acc: 0.9788\n",
      "Epoch 798/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9706 - val_loss: 0.1180 - val_acc: 0.9791\n",
      "Epoch 799/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9704 - val_loss: 0.1230 - val_acc: 0.9782\n",
      "Epoch 800/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9707 - val_loss: 0.1254 - val_acc: 0.9755\n",
      "Epoch 801/1000\n",
      " - 12s - loss: 0.1388 - acc: 0.9710 - val_loss: 0.1236 - val_acc: 0.9774\n",
      "Epoch 802/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9706 - val_loss: 0.1177 - val_acc: 0.9789\n",
      "Epoch 803/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9712 - val_loss: 0.1148 - val_acc: 0.9810\n",
      "Epoch 804/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9711 - val_loss: 0.1216 - val_acc: 0.9780\n",
      "Epoch 805/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9703 - val_loss: 0.1232 - val_acc: 0.9777\n",
      "Epoch 806/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9707 - val_loss: 0.1189 - val_acc: 0.9789\n",
      "Epoch 807/1000\n",
      " - 12s - loss: 0.1400 - acc: 0.9703 - val_loss: 0.1237 - val_acc: 0.9773\n",
      "Epoch 808/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9707 - val_loss: 0.1212 - val_acc: 0.9782\n",
      "Epoch 809/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1184 - val_acc: 0.9792\n",
      "Epoch 810/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9707 - val_loss: 0.1282 - val_acc: 0.9753\n",
      "Epoch 811/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9709 - val_loss: 0.1240 - val_acc: 0.9778\n",
      "Epoch 812/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9708 - val_loss: 0.1252 - val_acc: 0.9771\n",
      "Epoch 813/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9708 - val_loss: 0.1173 - val_acc: 0.9796\n",
      "Epoch 814/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9711 - val_loss: 0.1252 - val_acc: 0.9753\n",
      "Epoch 815/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9708 - val_loss: 0.1183 - val_acc: 0.9791\n",
      "Epoch 816/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9708 - val_loss: 0.1209 - val_acc: 0.9781\n",
      "Epoch 817/1000\n",
      " - 12s - loss: 0.1399 - acc: 0.9704 - val_loss: 0.1220 - val_acc: 0.9782\n",
      "Epoch 818/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9706 - val_loss: 0.1251 - val_acc: 0.9764\n",
      "Epoch 819/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9707 - val_loss: 0.1233 - val_acc: 0.9764\n",
      "Epoch 820/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9708 - val_loss: 0.1186 - val_acc: 0.9789\n",
      "Epoch 821/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9706 - val_loss: 0.1223 - val_acc: 0.9789\n",
      "Epoch 822/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9708 - val_loss: 0.1188 - val_acc: 0.9786\n",
      "Epoch 823/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9707 - val_loss: 0.1230 - val_acc: 0.9778\n",
      "Epoch 824/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9705 - val_loss: 0.1281 - val_acc: 0.9750\n",
      "Epoch 825/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9708 - val_loss: 0.1257 - val_acc: 0.9773\n",
      "Epoch 826/1000\n",
      " - 12s - loss: 0.1402 - acc: 0.9704 - val_loss: 0.1172 - val_acc: 0.9793\n",
      "Epoch 827/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9709 - val_loss: 0.1196 - val_acc: 0.9797\n",
      "Epoch 828/1000\n",
      " - 12s - loss: 0.1397 - acc: 0.9703 - val_loss: 0.1215 - val_acc: 0.9784\n",
      "Epoch 829/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9709 - val_loss: 0.1222 - val_acc: 0.9783\n",
      "Epoch 830/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9708 - val_loss: 0.1221 - val_acc: 0.9773\n",
      "Epoch 831/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1202 - val_acc: 0.9783\n",
      "Epoch 832/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9711 - val_loss: 0.1196 - val_acc: 0.9785\n",
      "Epoch 833/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9707 - val_loss: 0.1199 - val_acc: 0.9784\n",
      "Epoch 834/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9707 - val_loss: 0.1214 - val_acc: 0.9782\n",
      "Epoch 835/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9707 - val_loss: 0.1197 - val_acc: 0.9785\n",
      "Epoch 836/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9709 - val_loss: 0.1259 - val_acc: 0.9766\n",
      "Epoch 837/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9711 - val_loss: 0.1225 - val_acc: 0.9783\n",
      "Epoch 838/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9711 - val_loss: 0.1173 - val_acc: 0.9795\n",
      "Epoch 839/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9712 - val_loss: 0.1176 - val_acc: 0.9794\n",
      "Epoch 840/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9710 - val_loss: 0.1193 - val_acc: 0.9790\n",
      "Epoch 841/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9708 - val_loss: 0.1158 - val_acc: 0.9805\n",
      "Epoch 842/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9713 - val_loss: 0.1204 - val_acc: 0.9783\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 843/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9709 - val_loss: 0.1214 - val_acc: 0.9776\n",
      "Epoch 844/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9710 - val_loss: 0.1228 - val_acc: 0.9776\n",
      "Epoch 845/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9706 - val_loss: 0.1183 - val_acc: 0.9790\n",
      "Epoch 846/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9711 - val_loss: 0.1202 - val_acc: 0.9778\n",
      "Epoch 847/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9710 - val_loss: 0.1163 - val_acc: 0.9796\n",
      "Epoch 848/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9712 - val_loss: 0.1173 - val_acc: 0.9791\n",
      "Epoch 849/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9708 - val_loss: 0.1253 - val_acc: 0.9760\n",
      "Epoch 850/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9713 - val_loss: 0.1212 - val_acc: 0.9779\n",
      "Epoch 851/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9713 - val_loss: 0.1195 - val_acc: 0.9788\n",
      "Epoch 852/1000\n",
      " - 12s - loss: 0.1398 - acc: 0.9704 - val_loss: 0.1176 - val_acc: 0.9794\n",
      "Epoch 853/1000\n",
      " - 12s - loss: 0.1395 - acc: 0.9711 - val_loss: 0.1204 - val_acc: 0.9801\n",
      "Epoch 854/1000\n",
      " - 12s - loss: 0.1396 - acc: 0.9705 - val_loss: 0.1221 - val_acc: 0.9792\n",
      "Epoch 855/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9715 - val_loss: 0.1194 - val_acc: 0.9785\n",
      "Epoch 856/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9712 - val_loss: 0.1189 - val_acc: 0.9790\n",
      "Epoch 857/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9712 - val_loss: 0.1223 - val_acc: 0.9766\n",
      "Epoch 858/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9708 - val_loss: 0.1178 - val_acc: 0.9797\n",
      "Epoch 859/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9714 - val_loss: 0.1208 - val_acc: 0.9778\n",
      "Epoch 860/1000\n",
      " - 12s - loss: 0.1392 - acc: 0.9710 - val_loss: 0.1324 - val_acc: 0.9737\n",
      "Epoch 861/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9710 - val_loss: 0.1249 - val_acc: 0.9763\n",
      "Epoch 862/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9710 - val_loss: 0.1306 - val_acc: 0.9738\n",
      "Epoch 863/1000\n",
      " - 12s - loss: 0.1377 - acc: 0.9714 - val_loss: 0.1210 - val_acc: 0.9791\n",
      "Epoch 864/1000\n",
      " - 12s - loss: 0.1388 - acc: 0.9709 - val_loss: 0.1197 - val_acc: 0.9785\n",
      "Epoch 865/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9708 - val_loss: 0.1194 - val_acc: 0.9789\n",
      "Epoch 866/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9709 - val_loss: 0.1177 - val_acc: 0.9801\n",
      "Epoch 867/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9712 - val_loss: 0.1243 - val_acc: 0.9778\n",
      "Epoch 868/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9710 - val_loss: 0.1248 - val_acc: 0.9767\n",
      "Epoch 869/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9708 - val_loss: 0.1212 - val_acc: 0.9783\n",
      "Epoch 870/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9709 - val_loss: 0.1191 - val_acc: 0.9789\n",
      "Epoch 871/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9710 - val_loss: 0.1210 - val_acc: 0.9782\n",
      "Epoch 872/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9715 - val_loss: 0.1246 - val_acc: 0.9779\n",
      "Epoch 873/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9712 - val_loss: 0.1206 - val_acc: 0.9797\n",
      "Epoch 874/1000\n",
      " - 12s - loss: 0.1383 - acc: 0.9714 - val_loss: 0.1199 - val_acc: 0.9797\n",
      "Epoch 875/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9712 - val_loss: 0.1199 - val_acc: 0.9779\n",
      "Epoch 876/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9708 - val_loss: 0.1210 - val_acc: 0.9782\n",
      "Epoch 877/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9709 - val_loss: 0.1194 - val_acc: 0.9796\n",
      "Epoch 878/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9711 - val_loss: 0.1205 - val_acc: 0.9782\n",
      "Epoch 879/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9710 - val_loss: 0.1253 - val_acc: 0.9757\n",
      "Epoch 880/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9712 - val_loss: 0.1172 - val_acc: 0.9794\n",
      "Epoch 881/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9710 - val_loss: 0.1193 - val_acc: 0.9783\n",
      "Epoch 882/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9709 - val_loss: 0.1176 - val_acc: 0.9795\n",
      "Epoch 883/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9708 - val_loss: 0.1221 - val_acc: 0.9775\n",
      "Epoch 884/1000\n",
      " - 12s - loss: 0.1383 - acc: 0.9710 - val_loss: 0.1202 - val_acc: 0.9785\n",
      "Epoch 885/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9709 - val_loss: 0.1212 - val_acc: 0.9782\n",
      "Epoch 886/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9713 - val_loss: 0.1191 - val_acc: 0.9785\n",
      "Epoch 887/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9712 - val_loss: 0.1241 - val_acc: 0.9778\n",
      "Epoch 888/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9709 - val_loss: 0.1202 - val_acc: 0.9781\n",
      "Epoch 889/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9714 - val_loss: 0.1227 - val_acc: 0.9766\n",
      "Epoch 890/1000\n",
      " - 12s - loss: 0.1394 - acc: 0.9708 - val_loss: 0.1207 - val_acc: 0.9774\n",
      "Epoch 891/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9711 - val_loss: 0.1218 - val_acc: 0.9790\n",
      "Epoch 892/1000\n",
      " - 12s - loss: 0.1379 - acc: 0.9715 - val_loss: 0.1224 - val_acc: 0.9773\n",
      "Epoch 893/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9712 - val_loss: 0.1177 - val_acc: 0.9795\n",
      "Epoch 894/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9713 - val_loss: 0.1209 - val_acc: 0.9779\n",
      "Epoch 895/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9710 - val_loss: 0.1241 - val_acc: 0.9765\n",
      "Epoch 896/1000\n",
      " - 12s - loss: 0.1388 - acc: 0.9710 - val_loss: 0.1172 - val_acc: 0.9795\n",
      "Epoch 897/1000\n",
      " - 12s - loss: 0.1393 - acc: 0.9712 - val_loss: 0.1195 - val_acc: 0.9791\n",
      "Epoch 898/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9713 - val_loss: 0.1176 - val_acc: 0.9790\n",
      "Epoch 899/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9710 - val_loss: 0.1182 - val_acc: 0.9796\n",
      "Epoch 900/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9715 - val_loss: 0.1187 - val_acc: 0.9799\n",
      "Epoch 901/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9712 - val_loss: 0.1188 - val_acc: 0.9786\n",
      "Epoch 902/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9713 - val_loss: 0.1198 - val_acc: 0.9793\n",
      "Epoch 903/1000\n",
      " - 12s - loss: 0.1388 - acc: 0.9712 - val_loss: 0.1197 - val_acc: 0.9789\n",
      "Epoch 904/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9706 - val_loss: 0.1224 - val_acc: 0.9787\n",
      "Epoch 905/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9712 - val_loss: 0.1194 - val_acc: 0.9788\n",
      "Epoch 906/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9712 - val_loss: 0.1245 - val_acc: 0.9772\n",
      "Epoch 907/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9712 - val_loss: 0.1213 - val_acc: 0.9785\n",
      "Epoch 908/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9709 - val_loss: 0.1236 - val_acc: 0.9772\n",
      "Epoch 909/1000\n",
      " - 12s - loss: 0.1391 - acc: 0.9709 - val_loss: 0.1172 - val_acc: 0.9806\n",
      "Epoch 910/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9714 - val_loss: 0.1264 - val_acc: 0.9764\n",
      "Epoch 911/1000\n",
      " - 12s - loss: 0.1376 - acc: 0.9715 - val_loss: 0.1202 - val_acc: 0.9783\n",
      "Epoch 912/1000\n",
      " - 12s - loss: 0.1383 - acc: 0.9713 - val_loss: 0.1168 - val_acc: 0.9796\n",
      "Epoch 913/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9710 - val_loss: 0.1182 - val_acc: 0.9798\n",
      "Epoch 914/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9715 - val_loss: 0.1209 - val_acc: 0.9781\n",
      "Epoch 915/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9709 - val_loss: 0.1190 - val_acc: 0.9780\n",
      "Epoch 916/1000\n",
      " - 12s - loss: 0.1379 - acc: 0.9712 - val_loss: 0.1307 - val_acc: 0.9771\n",
      "Epoch 917/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9711 - val_loss: 0.1211 - val_acc: 0.9782\n",
      "Epoch 918/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9713 - val_loss: 0.1290 - val_acc: 0.9751\n",
      "Epoch 919/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9711 - val_loss: 0.1221 - val_acc: 0.9776\n",
      "Epoch 920/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9711 - val_loss: 0.1247 - val_acc: 0.9759\n",
      "Epoch 921/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9712 - val_loss: 0.1239 - val_acc: 0.9767\n",
      "Epoch 922/1000\n",
      " - 12s - loss: 0.1381 - acc: 0.9717 - val_loss: 0.1213 - val_acc: 0.9782\n",
      "Epoch 923/1000\n",
      " - 12s - loss: 0.1383 - acc: 0.9711 - val_loss: 0.1205 - val_acc: 0.9777\n",
      "Epoch 924/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9710 - val_loss: 0.1183 - val_acc: 0.9784\n",
      "Epoch 925/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9715 - val_loss: 0.1228 - val_acc: 0.9768\n",
      "Epoch 926/1000\n",
      " - 12s - loss: 0.1376 - acc: 0.9714 - val_loss: 0.1195 - val_acc: 0.9788\n",
      "Epoch 927/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9713 - val_loss: 0.1331 - val_acc: 0.9725\n",
      "Epoch 928/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9710 - val_loss: 0.1241 - val_acc: 0.9773\n",
      "Epoch 929/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9711 - val_loss: 0.1203 - val_acc: 0.9784\n",
      "Epoch 930/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9710 - val_loss: 0.1229 - val_acc: 0.9775\n",
      "Epoch 931/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9712 - val_loss: 0.1204 - val_acc: 0.9791\n",
      "Epoch 932/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9708 - val_loss: 0.1206 - val_acc: 0.9777\n",
      "Epoch 933/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9709 - val_loss: 0.1214 - val_acc: 0.9788\n",
      "Epoch 934/1000\n",
      " - 12s - loss: 0.1381 - acc: 0.9714 - val_loss: 0.1188 - val_acc: 0.9783\n",
      "Epoch 935/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9713 - val_loss: 0.1270 - val_acc: 0.9752\n",
      "Epoch 936/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 12s - loss: 0.1374 - acc: 0.9715 - val_loss: 0.1215 - val_acc: 0.9770\n",
      "Epoch 937/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9713 - val_loss: 0.1237 - val_acc: 0.9768\n",
      "Epoch 938/1000\n",
      " - 12s - loss: 0.1374 - acc: 0.9713 - val_loss: 0.1181 - val_acc: 0.9790\n",
      "Epoch 939/1000\n",
      " - 12s - loss: 0.1377 - acc: 0.9714 - val_loss: 0.1260 - val_acc: 0.9761\n",
      "Epoch 940/1000\n",
      " - 12s - loss: 0.1371 - acc: 0.9717 - val_loss: 0.1204 - val_acc: 0.9786\n",
      "Epoch 941/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9716 - val_loss: 0.1240 - val_acc: 0.9762\n",
      "Epoch 942/1000\n",
      " - 12s - loss: 0.1376 - acc: 0.9716 - val_loss: 0.1195 - val_acc: 0.9788\n",
      "Epoch 943/1000\n",
      " - 12s - loss: 0.1381 - acc: 0.9714 - val_loss: 0.1233 - val_acc: 0.9786\n",
      "Epoch 944/1000\n",
      " - 12s - loss: 0.1373 - acc: 0.9717 - val_loss: 0.1180 - val_acc: 0.9797\n",
      "Epoch 945/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9712 - val_loss: 0.1151 - val_acc: 0.9807\n",
      "Epoch 946/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9712 - val_loss: 0.1202 - val_acc: 0.9781\n",
      "Epoch 947/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9707 - val_loss: 0.1164 - val_acc: 0.9800\n",
      "Epoch 948/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9713 - val_loss: 0.1191 - val_acc: 0.9798\n",
      "Epoch 949/1000\n",
      " - 12s - loss: 0.1387 - acc: 0.9709 - val_loss: 0.1186 - val_acc: 0.9786\n",
      "Epoch 950/1000\n",
      " - 12s - loss: 0.1379 - acc: 0.9713 - val_loss: 0.1192 - val_acc: 0.9792\n",
      "Epoch 951/1000\n",
      " - 12s - loss: 0.1379 - acc: 0.9716 - val_loss: 0.1208 - val_acc: 0.9784\n",
      "Epoch 952/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9713 - val_loss: 0.1218 - val_acc: 0.9791\n",
      "Epoch 953/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9713 - val_loss: 0.1203 - val_acc: 0.9780\n",
      "Epoch 954/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9715 - val_loss: 0.1221 - val_acc: 0.9786\n",
      "Epoch 955/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9713 - val_loss: 0.1198 - val_acc: 0.9784\n",
      "Epoch 956/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9712 - val_loss: 0.1173 - val_acc: 0.9798\n",
      "Epoch 957/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9712 - val_loss: 0.1238 - val_acc: 0.9767\n",
      "Epoch 958/1000\n",
      " - 12s - loss: 0.1389 - acc: 0.9709 - val_loss: 0.1180 - val_acc: 0.9790\n",
      "Epoch 959/1000\n",
      " - 12s - loss: 0.1367 - acc: 0.9722 - val_loss: 0.1190 - val_acc: 0.9792\n",
      "Epoch 960/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9714 - val_loss: 0.1259 - val_acc: 0.9759\n",
      "Epoch 961/1000\n",
      " - 12s - loss: 0.1379 - acc: 0.9714 - val_loss: 0.1178 - val_acc: 0.9794\n",
      "Epoch 962/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9711 - val_loss: 0.1232 - val_acc: 0.9771\n",
      "Epoch 963/1000\n",
      " - 12s - loss: 0.1383 - acc: 0.9714 - val_loss: 0.1180 - val_acc: 0.9795\n",
      "Epoch 964/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9714 - val_loss: 0.1182 - val_acc: 0.9794\n",
      "Epoch 965/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9713 - val_loss: 0.1186 - val_acc: 0.9790\n",
      "Epoch 966/1000\n",
      " - 12s - loss: 0.1388 - acc: 0.9711 - val_loss: 0.1238 - val_acc: 0.9765\n",
      "Epoch 967/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9713 - val_loss: 0.1186 - val_acc: 0.9789\n",
      "Epoch 968/1000\n",
      " - 12s - loss: 0.1377 - acc: 0.9715 - val_loss: 0.1273 - val_acc: 0.9758\n",
      "Epoch 969/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9716 - val_loss: 0.1270 - val_acc: 0.9778\n",
      "Epoch 970/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9712 - val_loss: 0.1190 - val_acc: 0.9785\n",
      "Epoch 971/1000\n",
      " - 12s - loss: 0.1379 - acc: 0.9714 - val_loss: 0.1177 - val_acc: 0.9790\n",
      "Epoch 972/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9712 - val_loss: 0.1253 - val_acc: 0.9772\n",
      "Epoch 973/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9714 - val_loss: 0.1217 - val_acc: 0.9778\n",
      "Epoch 974/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9715 - val_loss: 0.1162 - val_acc: 0.9795\n",
      "Epoch 975/1000\n",
      " - 12s - loss: 0.1390 - acc: 0.9710 - val_loss: 0.1232 - val_acc: 0.9788\n",
      "Epoch 976/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9712 - val_loss: 0.1188 - val_acc: 0.9793\n",
      "Epoch 977/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9710 - val_loss: 0.1190 - val_acc: 0.9796\n",
      "Epoch 978/1000\n",
      " - 12s - loss: 0.1383 - acc: 0.9713 - val_loss: 0.1192 - val_acc: 0.9786\n",
      "Epoch 979/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9715 - val_loss: 0.1187 - val_acc: 0.9795\n",
      "Epoch 980/1000\n",
      " - 12s - loss: 0.1378 - acc: 0.9714 - val_loss: 0.1217 - val_acc: 0.9777\n",
      "Epoch 981/1000\n",
      " - 12s - loss: 0.1388 - acc: 0.9712 - val_loss: 0.1263 - val_acc: 0.9752\n",
      "Epoch 982/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9713 - val_loss: 0.1191 - val_acc: 0.9796\n",
      "Epoch 983/1000\n",
      " - 12s - loss: 0.1376 - acc: 0.9714 - val_loss: 0.1207 - val_acc: 0.9799\n",
      "Epoch 984/1000\n",
      " - 12s - loss: 0.1385 - acc: 0.9710 - val_loss: 0.1205 - val_acc: 0.9779\n",
      "Epoch 985/1000\n",
      " - 12s - loss: 0.1381 - acc: 0.9715 - val_loss: 0.1211 - val_acc: 0.9781\n",
      "Epoch 986/1000\n",
      " - 12s - loss: 0.1376 - acc: 0.9716 - val_loss: 0.1170 - val_acc: 0.9800\n",
      "Epoch 987/1000\n",
      " - 12s - loss: 0.1374 - acc: 0.9719 - val_loss: 0.1165 - val_acc: 0.9798\n",
      "Epoch 988/1000\n",
      " - 12s - loss: 0.1376 - acc: 0.9720 - val_loss: 0.1198 - val_acc: 0.9805\n",
      "Epoch 989/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9715 - val_loss: 0.1192 - val_acc: 0.9792\n",
      "Epoch 990/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9714 - val_loss: 0.1203 - val_acc: 0.9785\n",
      "Epoch 991/1000\n",
      " - 12s - loss: 0.1381 - acc: 0.9712 - val_loss: 0.1175 - val_acc: 0.9795\n",
      "Epoch 992/1000\n",
      " - 12s - loss: 0.1372 - acc: 0.9716 - val_loss: 0.1246 - val_acc: 0.9765\n",
      "Epoch 993/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9713 - val_loss: 0.1218 - val_acc: 0.9783\n",
      "Epoch 994/1000\n",
      " - 12s - loss: 0.1386 - acc: 0.9711 - val_loss: 0.1193 - val_acc: 0.9791\n",
      "Epoch 995/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9712 - val_loss: 0.1189 - val_acc: 0.9791\n",
      "Epoch 996/1000\n",
      " - 12s - loss: 0.1377 - acc: 0.9712 - val_loss: 0.1181 - val_acc: 0.9792\n",
      "Epoch 997/1000\n",
      " - 12s - loss: 0.1380 - acc: 0.9714 - val_loss: 0.1164 - val_acc: 0.9794\n",
      "Epoch 998/1000\n",
      " - 12s - loss: 0.1382 - acc: 0.9713 - val_loss: 0.1162 - val_acc: 0.9803\n",
      "Epoch 999/1000\n",
      " - 12s - loss: 0.1372 - acc: 0.9717 - val_loss: 0.1198 - val_acc: 0.9788\n",
      "Epoch 1000/1000\n",
      " - 12s - loss: 0.1384 - acc: 0.9714 - val_loss: 0.1215 - val_acc: 0.9775\n"
     ]
    }
   ],
   "source": [
    "# dropout_rate = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(2048, activation=\"softplus\", kernel_regularizer=l2(1e-05), bias_regularizer=l2(0.0001), activity_regularizer=l1(1e-07)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256, activation=\"softplus\", kernel_regularizer=l2(1e-05), bias_regularizer=l2(0.0001), activity_regularizer=l1(1e-07)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "adam_opt=Adam(lr = 0.0001, beta_1=0.8, beta_2=0.99)\n",
    "\n",
    "model.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels),\n",
    "                    verbose= 2)\n",
    "\n",
    "with open(extracted_features_dir+'history_'+model_name+'.txt','w') as f:\n",
    "    f.write(str(history.history))\n",
    "\n",
    "    \n",
    "    \n",
    "top_model_path = os.path.join(extracted_features_dir, 'model_'+model_name+'_model.h5')\n",
    "top_model_weights_path = os.path.join(extracted_features_dir, 'model_'+model_name+'_weights.h5')    \n",
    "    \n",
    "model.save_weights(top_model_weights_path)\n",
    "model.save(top_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9502135807924584\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data)\n",
    "\n",
    "predictions = [i.argmax() for i in preds]\n",
    "y_true = [i.argmax() for i in test_labels]\n",
    "cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix\n",
      "[[2829    0    5    5   48   39]\n",
      " [   1  477    2   13   15   11]\n",
      " [   1    0 2933   23   27   95]\n",
      " [   0    5    8 1061   14    9]\n",
      " [   6   11   39   17 2724   32]\n",
      " [  15    1  145   23   66 2878]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "labels = []\n",
    "\n",
    "label = test_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels, title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2829    0    5    5   48   39]\n",
      " [   1  477    2   13   15   11]\n",
      " [   1    0 2933   23   27   95]\n",
      " [   0    5    8 1061   14    9]\n",
      " [   6   11   39   17 2724   32]\n",
      " [  15    1  145   23   66 2878]]\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "      Centromere       0.99      0.97      0.98      2926\n",
      "           Golgi       0.97      0.92      0.94       519\n",
      "     Homogeneous       0.94      0.95      0.94      3079\n",
      "Nuclear_membrane       0.93      0.97      0.95      1097\n",
      "       Nucleolar       0.94      0.96      0.95      2829\n",
      "        Speckled       0.94      0.92      0.93      3128\n",
      "\n",
      "     avg / total       0.95      0.95      0.95     13578\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred=predictions\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "# y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = y_true\n",
    "\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
    "print(confusion_mtx)\n",
    "target_names = classnames\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity :  99.96466431095406\n",
      "Specificity :  100.0\n"
     ]
    }
   ],
   "source": [
    "total=sum(sum(cm))\n",
    "\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
    "print('Sensitivity : ', sensitivity*100 )\n",
    "\n",
    "Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "print('Specificity : ', Specificity*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8039254da195>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'roc_auc_score = '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroc_auc_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[1;34m(y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m    275\u001b[0m     return _average_binary_score(\n\u001b[0;32m    276\u001b[0m         \u001b[0m_binary_roc_auc_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 277\u001b[1;33m         sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    279\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[1;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[0my_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "print('roc_auc_score = ' + str(roc_auc_score(predictions, y_true)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multiclass format is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-1db1fd835276>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    532\u001b[0m     \"\"\"\n\u001b[0;32m    533\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 534\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    535\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    536\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    316\u001b[0m     if not (y_type == \"binary\" or\n\u001b[0;32m    317\u001b[0m             (y_type == \"multiclass\" and pos_label is not None)):\n\u001b[1;32m--> 318\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"{0} format is not supported\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    319\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: multiclass format is not supported"
     ]
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_true, predictions)\n",
    "roc_auc = auc(fpr,tpr)\n",
    "\n",
    "plt.figure(figsize=(7,7))\n",
    "lw = 2\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([-.001, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13578/13578 [==============================] - 0s 18us/step\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict_proba(test_data, batch_size=batch_size, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "classes [0 1] missmatch with the labels [0 1 2 3 4 5]found in the data",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-6142e7628a43>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabel_binarize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\label.py\u001b[0m in \u001b[0;36mlabel_binarize\u001b[1;34m(y, classes, neg_label, pos_label, sparse_output)\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"multilabel-indicator\"\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         raise ValueError(\"classes {0} missmatch with the labels {1}\"\n\u001b[1;32m--> 496\u001b[1;33m                          \"found in the data\".format(classes, unique_labels(y)))\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: classes [0 1] missmatch with the labels [0 1 2 3 4 5]found in the data"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "y = label_binarize(test_labels, classes=[0, 1])\n",
    "for i in range(num_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y[:, i], predict[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y.ravel(), predict.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-a06b4c2bdc3d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_fpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Then interpolate all ROC curves at this points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmean_tpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-a06b4c2bdc3d>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0minterp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mall_fpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfpr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Then interpolate all ROC curves at this points\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmean_tpr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_fpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "from scipy import interp\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(num_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(num_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= num_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'micro'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-4993d04cb2f6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n\u001b[0m\u001b[0;32m     13\u001b[0m          \u001b[0mlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'micro-average ROC curve (area = {0:0.2f})'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m                ''.format(roc_auc[\"micro\"]),linewidth=2)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'micro'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x720 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams['figure.facecolor'] = 'white'\n",
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "from itertools import cycle\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         linewidth=2)\n",
    "plot_name = 'no variation'\n",
    "colors = cycle(['red','blue','green','yellow','orange', 'aqua', 'cornflowerblue'])\n",
    "\n",
    "for i, color in zip(range(num_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(classnames[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "# plt.title('Some extension of Receiver operating characteristic to multi-class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-b1a8bacc62a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "tn, fp, fn, tp = cm.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-8afd59b023d2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtn\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Precision:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Recall:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"tp:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"fp:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",(tp+tn)/(tp+tn+fp+fn))\n",
    "print(\"Precision:\",(tp/(tp+fp)))\n",
    "print(\"Recall:\",(tp/(tp+fn)))\n",
    "print(\"tp:\", tp) \n",
    "print(\"fp:\", fp) \n",
    "print(\"tn:\",tn) \n",
    "print(\"fn:\",fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Target is multiclass but average='binary'. Please choose another average setting.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-6ed5ef63a207>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mf1_score\u001b[1;34m(y_true, y_pred, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    712\u001b[0m     return fbeta_score(y_true, y_pred, 1, labels=labels,\n\u001b[0;32m    713\u001b[0m                        \u001b[0mpos_label\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 714\u001b[1;33m                        sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    715\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mfbeta_score\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight)\u001b[0m\n\u001b[0;32m    826\u001b[0m                                                  \u001b[0maverage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maverage\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m                                                  \u001b[0mwarn_for\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'f-score'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m                                                  sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    829\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[1;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight)\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1039\u001b[0m             raise ValueError(\"Target is %s but average='binary'. Please \"\n\u001b[1;32m-> 1040\u001b[1;33m                              \"choose another average setting.\" % y_type)\n\u001b[0m\u001b[0;32m   1041\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m         warnings.warn(\"Note that pos_label (set to %r) is ignored when \"\n",
      "\u001b[1;31mValueError\u001b[0m: Target is multiclass but average='binary'. Please choose another average setting."
     ]
    }
   ],
   "source": [
    "print('F1 score:', f1_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-33-2723c42e421b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mrecall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mrecall\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mprecision\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'F1 score:'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tp' is not defined"
     ]
    }
   ],
   "source": [
    "recall = (tp/(tp+fn))\n",
    "precision=(tp/(tp+fp))\n",
    "\n",
    "f1 = 2 / ( (1/recall) + (1 / precision))\n",
    "print('F1 score:', f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x272fce60518>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.style.use(\"seaborn-ticks\")\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
