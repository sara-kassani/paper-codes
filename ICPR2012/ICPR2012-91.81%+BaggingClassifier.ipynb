{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6901136358110532938, name: \"/device:XLA_CPU:0\"\n",
       " device_type: \"XLA_CPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 14120685230662926279\n",
       " physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n",
       " device_type: \"XLA_GPU\"\n",
       " memory_limit: 17179869184\n",
       " locality {\n",
       " }\n",
       " incarnation: 17298169232498881769\n",
       " physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 15884438733\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 7357540472836960647\n",
       " physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n",
    "import time\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import keras\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "# import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.regularizers import l2, l1\n",
    "\n",
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, concatenate\n",
    "from keras import optimizers, metrics, models\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.2.4\n",
      "tensorflow Version 1.13.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "# print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', 'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5', 'nasnet_large_no_top.h5', 'xception_weights_tf_dim_ordering_tf_kernels_notop.h5', 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', 'inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5', 'nasnet_mobile_no_top.h5', 'densenet169_weights_tf_dim_ordering_tf_kernels_notop.h5', 'vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', 'densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5', 'mobilenet_1_0_224_tf_no_top.h5', 'densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"../input/full-keras-pretrained-no-top/\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 512\n",
    "img_height, img_width = 128, 128\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '../input/icpr2012-augmented/data_augmented/data_augmented/train/'\n",
    "test_dir = '../input/icpr2012-augmented/data_augmented/data_augmented/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(x):\n",
    "    # 'RGB'->'BGR'\n",
    "    x = x[:, :, ::-1]\n",
    "    # Zero-center by imagenet mean pixel\n",
    "    x[:, :, 0] -= 103.939\n",
    "    x[:, :, 1] -= 116.779\n",
    "    x[:, :, 2] -= 123.68\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 53114 images belonging to 6 classes.\n",
      "Found 13276 images belonging to 6 classes.\n",
      "Found 13578 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "    preprocessing_function = preprocess_input,\n",
    "    validation_split= 0.2,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.2)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'training',\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    subset = 'validation',\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255, preprocessing_function = preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nb_train_samples: 53114\n",
      "nb_validation_samples: 13276\n",
      "nb_test_samples: 13578\n",
      "\n",
      "predict_size_train: 104\n",
      "predict_size_validation: 26\n",
      "predict_size_test: 27\n",
      "\n",
      " num_classes: 6\n"
     ]
    }
   ],
   "source": [
    "nb_train_samples = len(train_generator.filenames)\n",
    "nb_validation_samples = len(validation_generator.filenames)\n",
    "nb_test_samples = len(test_generator.filenames)\n",
    "\n",
    "predict_size_train = int(math.ceil(nb_train_samples / batch_size))\n",
    "predict_size_validation = int(math.ceil(nb_validation_samples / batch_size))\n",
    "predict_size_test = int(math.ceil(nb_test_samples / batch_size))\n",
    "\n",
    "num_classes = len(train_generator.class_indices)\n",
    "\n",
    "print(\"nb_train_samples:\", nb_train_samples)\n",
    "print(\"nb_validation_samples:\", nb_validation_samples)\n",
    "print(\"nb_test_samples:\", nb_test_samples)\n",
    "\n",
    "print(\"\\npredict_size_train:\", predict_size_train)\n",
    "print(\"predict_size_validation:\", predict_size_validation)\n",
    "print(\"predict_size_test:\", predict_size_test)\n",
    "\n",
    "print(\"\\n num_classes:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"extracted_features\")\n",
    "extracted_features_dir = \"extracted_features/\"\n",
    "model_name = \"Xception_InceptionV3_augmented_descriptors\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19_weights =\"../input/full-keras-pretrained-no-top/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "inception_weights =\"../input/full-keras-pretrained-no-top//inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "vgg16_weights =\"../input/full-keras-pretrained-no-top/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "denseNet201_weights =\"../input/full-keras-pretrained-no-top/densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "denseNet121_weights =\"../input/full-keras-pretrained-no-top/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "resenet50_weights =\"../input/full-keras-pretrained-no-top/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "inception_resnet_v2_weights =\"../input/full-keras-pretrained-no-top/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "nasnet_weights =\"../input/full-keras-pretrained-no-top/nasnet_large_no_top.h5\"\n",
    "nasnet_mobile_weights =\"../input/full-keras-pretrained-no-top/nasnet_mobile_no_top.h5\"\n",
    "mobilenet_weights =\"../input/full-keras-pretrained-no-top/mobilenet_1_0_224_tf_no_top.h5\"\n",
    "xception_weights = \"../input/full-keras-pretrained-no-top/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "# from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.applications import DenseNet201\n",
    "# from keras.applications import DenseNet121\n",
    "# from keras.applications import ResNet50\n",
    "# from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "# from keras.applications import NASNetLarge, NASNetMobile\n",
    "# from keras.applications import MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensor = Input(shape = input_shape)  \n",
    "\n",
    "base_model1=InceptionV3(input_shape= input_shape,weights=inception_weights, include_top=False, input_tensor=input_tensor)\n",
    "base_model2=Xception(input_shape= input_shape,weights=xception_weights, include_top=False, input_tensor=input_tensor)\n",
    "\n",
    "x1 = base_model1.output\n",
    "x1 = GlobalAveragePooling2D()(x1)\n",
    "\n",
    "x2 = base_model2.output\n",
    "x2 = GlobalAveragePooling2D()(x2)\n",
    "\n",
    "merge = concatenate([x1, x2])\n",
    "predictions = Dense(num_classes, activation='softmax')(merge)\n",
    "\n",
    "model = Model(inputs=input_tensor,outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, layer in enumerate(model.layers):\n",
    "#     print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1 = model.layers[11].output \n",
    "c1 = GlobalAveragePooling2D()(c1)       \n",
    "\n",
    "c2 = model.layers[21].output\n",
    "c2 = GlobalAveragePooling2D()(c2)       \n",
    "\n",
    "c3 = model.layers[28].output\n",
    "c3 = GlobalAveragePooling2D()(c3)       \n",
    "\n",
    "c4 = model.layers[51].output\n",
    "c4 = GlobalAveragePooling2D()(c4) \n",
    "\n",
    "c5 = model.layers[84].output\n",
    "c5 = GlobalAveragePooling2D()(c5) \n",
    "\n",
    "c6 = model.layers[103].output\n",
    "c6 = GlobalAveragePooling2D()(c6) \n",
    "\n",
    "c7 = model.layers[117].output\n",
    "c7 = GlobalAveragePooling2D()(c7) \n",
    "\n",
    "c8 = model.layers[129].output\n",
    "c8 = GlobalAveragePooling2D()(c8) \n",
    "\n",
    "c9 = model.layers[143].output\n",
    "c9 = GlobalAveragePooling2D()(c9) \n",
    "\n",
    "c10 = model.layers[162].output\n",
    "c10 = GlobalAveragePooling2D()(c10) \n",
    "\n",
    "c11 = model.layers[210].output\n",
    "c11 = GlobalAveragePooling2D()(c11) \n",
    "\n",
    "c12 = model.layers[258].output\n",
    "c12 = GlobalAveragePooling2D()(c12) \n",
    "\n",
    "c13 = model.layers[306].output\n",
    "c13 = GlobalAveragePooling2D()(c13) \n",
    "\n",
    "c14 = model.layers[356].output\n",
    "c14 = GlobalAveragePooling2D()(c14) \n",
    "\n",
    "c15 = model.layers[377].output\n",
    "c15 = GlobalAveragePooling2D()(c15) \n",
    "\n",
    "c16 = model.layers[415].output\n",
    "c16 = GlobalAveragePooling2D()(c16) \n",
    "\n",
    "c17 = model.layers[421].output\n",
    "c17 = GlobalAveragePooling2D()(c17) \n",
    "\n",
    "con = concatenate([c1, c2, c3, c4, c5, c6, c7, c8, c9, c10, c11, c12, c13, c14, c15, c16])\n",
    "\n",
    "bottleneck_final_model = Model(inputs=model.input, outputs=con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_train = bottleneck_final_model.predict_generator(train_generator, predict_size_train, max_q_size=1, pickle_safe=False)\n",
    "np.save(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy', bottleneck_features_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_validation = bottleneck_final_model.predict_generator(validation_generator, predict_size_validation)\n",
    "np.save(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy', bottleneck_features_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bottleneck_features_test = bottleneck_final_model.predict_generator(test_generator, predict_size_test)\n",
    "np.save(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy', bottleneck_features_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "\n",
    "def reset_keras_tf_session():\n",
    "    \"\"\"\n",
    "    this function clears the gpu memory and set the \n",
    "    tf session to not use the whole gpu\n",
    "    \"\"\"\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "#     config = tf.ConfigProto()\n",
    "#     config.gpu_options.allow_growth = True\n",
    "#     set_session(tf.Session(config=config))\n",
    "\n",
    "reset_keras_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.load(extracted_features_dir+'bottleneck_features_train_'+model_name+'.npy')\n",
    "validation_data = np.load(extracted_features_dir+'bottleneck_features_validation_'+model_name+'.npy')\n",
    "test_data = np.load(extracted_features_dir+'bottleneck_features_test_'+model_name+'.npy')\n",
    "\n",
    "train_labels = train_generator.classes\n",
    "train_labels = to_categorical(train_labels, num_classes=num_classes)\n",
    "\n",
    "validation_labels = validation_generator.classes\n",
    "validation_labels = to_categorical(validation_labels, num_classes=num_classes)\n",
    "\n",
    "test_labels = test_generator.classes\n",
    "test_labels = to_categorical(test_labels, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es_callback = keras.callbacks.EarlyStopping(monitor='val_acc', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dropout_rate = 0.5\n",
    "\n",
    "model = Sequential()\n",
    "# model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(2048, activation=\"softplus\", kernel_regularizer=l2(1e-05), bias_regularizer=l2(0.0001), activity_regularizer=l1(1e-07)))\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "model.add(Dense(256, activation=\"softplus\", kernel_regularizer=l2(1e-05), bias_regularizer=l2(0.0001), activity_regularizer=l1(1e-07)))\n",
    "model.add(Dropout(0.5))\n",
    "    \n",
    "model.add(Dense(num_classes, activation=\"softmax\"))\n",
    "\n",
    "adam_opt=Adam(lr = 0.0001, beta_1=0.8, beta_2=0.99)\n",
    "\n",
    "model.compile(optimizer=adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=1000,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels),\n",
    "#                     callbacks=[es_callback],\n",
    "                    verbose= 2)\n",
    "\n",
    "with open(extracted_features_dir+'history_'+model_name+'.txt','w') as f:\n",
    "    f.write(str(history.history))\n",
    "\n",
    "# model.save_weights(top_model_weights_path)\n",
    "# model.save(top_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(test_data)\n",
    "\n",
    "predictions = [i.argmax() for i in preds]\n",
    "y_true = [i.argmax() for i in test_labels]\n",
    "cm = confusion_matrix(y_pred=predictions, y_true=y_true)\n",
    "\n",
    "print('Accuracy {}'.format(accuracy_score(y_true=y_true, y_pred=predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams[\"axes.grid\"] = False\n",
    "plt.rcParams.update({'font.size': 20})\n",
    "\n",
    "labels = []\n",
    "\n",
    "label = test_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "#     plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "plot_confusion_matrix(cm, classes=labels, title=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_pred=predictions\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "# y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = y_true\n",
    "\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
    "print(confusion_mtx)\n",
    "target_names = classnames\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total=sum(sum(cm))\n",
    "\n",
    "sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
    "print('Sensitivity : ', sensitivity )\n",
    "\n",
    "Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "print('Specificity : ', Specificity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_class = model.predict(test_data, verbose=1)\n",
    "\n",
    "y_pred_class = [np.argmax(r) for r in y_pred_class]\n",
    "test_y = [np.argmax(r) for r in test_labels]\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, cohen_kappa_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Precision\n",
    "print('Precision = ', precision_score(test_y, y_pred_class, average='weighted'))\n",
    "# (None, 'micro', 'macro', 'weighted', 'samples')\n",
    "\n",
    "# Recall\n",
    "print('Recall = ', recall_score(test_y, y_pred_class, average='weighted'))\n",
    "\n",
    "# f1_score\n",
    "print('f1_score = ', f1_score(test_y, y_pred_class, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"weighted\"):\n",
    "    label_binarizer = LabelBinarizer()\n",
    "    label_binarizer.fit(y_test)\n",
    "\n",
    "    truth = label_binarizer.transform(y_test)\n",
    "    pred = label_binarizer.transform(y_pred)\n",
    "    return roc_auc_score(truth, pred, average=average)\n",
    "# roc_auc_score\n",
    "print('roc_auc_score = ', multiclass_roc_auc_score(test_y, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve for each class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "predict_class = np.argmax(preds, axis=1)\n",
    "\n",
    "y_pred = preds\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = test_generator.classes\n",
    "\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "y_actual_binary = label_binarize(y_actual, classes=[0, 1, 2, 3, 4, 5])\n",
    "y_pred_binary = y_pred_probabilities\n",
    "n_classes=6\n",
    "lw=2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_actual_binary[:, i], y_pred_binary[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_actual_binary.ravel(), y_pred_binary.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(10, 10))\n",
    "\n",
    "\n",
    "colors = cycle(['red','blue','green','yellow','orange', 'aqua', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(classnames[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn-ticks\")\n",
    "\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import seaborn\n",
    "\n",
    "model_predictions = np.vstack(preds)\n",
    "classes = np.hstack(y_pred)\n",
    "\n",
    "tsne = TSNE(n_components=2)\n",
    "tsne_data = tsne.fit_transform(model_predictions)\n",
    "\n",
    "seaborn.scatterplot(tsne_data[:,0], tsne_data[:,1], hue=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Data Shape : {0}\".format(train_data.shape))\n",
    "print(\"Training Data label Shape : {0}\".format(train_labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score,roc_curve, confusion_matrix, roc_auc_score, auc, f1_score, classification_report\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import KFold, train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=10, shuffle=True, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('DecisionTree Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, test_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "clf.fit(train_data, train_labels)\n",
    "print(\"Train accuracy\", clf.score(train_data, train_labels))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, validation_labels ))\n",
    "print(\"Test accuracy\", clf.score(test_data, test_labels))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(test_labels, y_test_pred)\n",
    "print('RandomForest Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(test_labels, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(test_labels, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = RandomForestClassifier(n_estimators=5)\n",
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, test_labels, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = np.asarray(test_labels)\n",
    "y_test = np.argmax(y_test, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_validation = np.asarray(validation_labels)\n",
    "y_validation = np.argmax(y_validation, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np.asarray(train_labels)\n",
    "y_train = np.argmax(y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clf = SVC()\n",
    "# clf.fit(train_data, y_train)\n",
    "# print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "# print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "# print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "# y_test_pred = clf.predict(test_data)\n",
    "# clf_test = accuracy_score(y_test, y_test_pred)\n",
    "# print('SVM Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "# print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# # print(confusion_matrix(test_labels, y_test_pred))\n",
    "# print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scoring = 'accuracy'\n",
    "# scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "# print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "# print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "# print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "# print (\"Scores of all folds:\", scores)\n",
    "# print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier()\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('XGB Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = AdaBoostClassifier(DecisionTreeClassifier(), n_estimators = 300 )\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy 0.9983620137816771\n",
      "Validation accuracy 0.8128201265441398\n",
      "Test accuracy 0.8859920459566947\n",
      "AdaBoost Classifier test accuracies 0.8860\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92      2926\n",
      "           1       0.87      0.91      0.89       519\n",
      "           2       0.90      0.86      0.88      3079\n",
      "           3       0.87      0.93      0.90      1097\n",
      "           4       0.91      0.92      0.92      2829\n",
      "           5       0.80      0.87      0.83      3128\n",
      "\n",
      "    accuracy                           0.89     13578\n",
      "   macro avg       0.89      0.89      0.89     13578\n",
      "weighted avg       0.89      0.89      0.89     13578\n",
      "\n",
      "0.8859920459566947\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(RandomForestClassifier(), n_estimators = 300 )\n",
    "clf.fit(train_data, y_train)\n",
    "print(\"Train accuracy\", clf.score(train_data, y_train))\n",
    "print(\"Validation accuracy\", clf.score(validation_data, y_validation ))\n",
    "print(\"Test accuracy\", clf.score(test_data, y_test))\n",
    "\n",
    "y_test_pred = clf.predict(test_data)\n",
    "clf_test = accuracy_score(y_test, y_test_pred)\n",
    "print('AdaBoost Classifier test accuracies %.4f' % (clf_test))\n",
    "\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "\n",
    "# print(confusion_matrix(test_labels, y_test_pred))\n",
    "print(accuracy_score(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "scores = cross_val_score(clf, test_data, y_test, cv=k_fold, n_jobs=1, scoring=scoring)\n",
    "\n",
    "print (\"Scores Mean: %.4f and (STDEV %.4f)\" % (np.mean(scores)*100, np.std(scores)))\n",
    "print (\"Best result for fold %s\" % np.argmax(scores))\n",
    "print (\"Best accuracy is\", (scores[np.argmax(scores)]))\n",
    "print (\"Scores of all folds:\", scores)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
