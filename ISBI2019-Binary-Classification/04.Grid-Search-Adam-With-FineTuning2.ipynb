{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 3051520656901445305, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9221160305\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 3805544699293987081\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6683898676\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2838366843348485818\n",
       " physical_device_desc: \"device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "# import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, concatenate\n",
    "from keras import optimizers, metrics, models\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.1.6\n",
      "tensorflow Version 1.10.0\n",
      "dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classes = 2\n",
    "batch_size = 16\n",
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 50\n",
    "\n",
    "nb_train_samples = 59168\n",
    "nb_validation_samples = 18384\n",
    "nb_test_samples = 967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "validation_dir = 'data/validation'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59168 images belonging to 2 classes.\n",
      "Found 18384 images belonging to 2 classes.\n",
      "Found 967 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensembel_model():\n",
    "    NasNetLarge_model = load_model('models/5.NASNetLarge-new-ISBI19-Model.h5', compile=False)\n",
    "    NasNetLarge_model = Model(inputs= NasNetLarge_model.input,outputs = NasNetLarge_model.get_layer('dense_3').output, name='NasNetLarge_model')\n",
    "    VGG19_model = load_model('models/11.VGG19-ISBI19-Model.h5')\n",
    "    VGG19_model = Model(inputs = VGG19_model.input,outputs = VGG19_model.get_layer('dense_3').output, name='VGG19_model')\n",
    "    \n",
    "    img = Input(shape=(224, 224,3),name='img')\n",
    "\n",
    "    feature1=NasNetLarge_model(img)\n",
    "    # feature2=InceptionV3_model(img)\n",
    "\n",
    "    for layer in NasNetLarge_model.layers[:300]:  \n",
    "        layer.trainable = False \n",
    "    for layer in NasNetLarge_model.layers[300:]:  \n",
    "        layer.trainable = True  \n",
    "\n",
    "    feature3=VGG19_model(img)\n",
    "    for layer in VGG19_model.layers[:170]:  \n",
    "        layer.trainable = False \n",
    "    for layer in VGG19_model.layers[170:]:  \n",
    "        layer.trainable = True  \n",
    "\n",
    "    # x = concatenate([feature1,feature2,feature3])\n",
    "    x = concatenate([feature1,feature3])\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64,activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    output = Dense(2, activation='softmax', name='output')(x)\n",
    "\n",
    "    model=Model(inputs=img,outputs=output)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = ensembel_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "         'lr': hp.choice('lr',[0.001, 0.0001, 0.00001,0.000001]),\n",
    "#          'dropout': hp.choice('dropout', [0.4, 0.5, 0.6, 0.7]),\n",
    "#          'batch_size': hp.choice('batch_size', [64]),\n",
    "#          'epochs': hp.choice('epochs', [15, 20, 25, 30, 50]),\n",
    "#          'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['adam']),\n",
    "         'beta_1':hp.choice('beta_1',[0.3,0.4,0.5,0.6,0.7,0.8]),\n",
    "         'beta_2':hp.choice('beta_2',[0.99,0.995,0.7,0.8,0.9,0.999]),\n",
    "#          'decay':hp.choice('decay',[0.0, 0.004, 0.0001, 0.1, 0.3, 0.5]),\n",
    "#          'momentum':hp.choice('momentum',[0.3,0.5,0.7,0.9,1]),\n",
    "#          'amsgrad':hp.choice('amsgrad',[False,True]),\n",
    "#          'nesterov':hp.choice('nesterov',[False,True]),\n",
    "#          'rho':hp.choice('rho',[0.4,0.5,0.6,0.7,0.8,0.9,1]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):   \n",
    "    print ('Parameters testing: ', params)\n",
    "#     batch_size=params['batch_size']\n",
    "\n",
    "#     random_seed = np.random.seed(1132)\n",
    "\n",
    "#     train_datagen = ImageDataGenerator(\n",
    "#         rescale=1. / 255,\n",
    "#         featurewise_center=True,\n",
    "#         featurewise_std_normalization=True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#     train_generator = train_datagen.flow_from_directory(\n",
    "#         train_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = True,\n",
    "#         seed = random_seed,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#     validation_generator = train_datagen.flow_from_directory(\n",
    "#         validation_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = True,\n",
    "#         seed = random_seed,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#     test_generator = test_datagen.flow_from_directory(\n",
    "#         test_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = False,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "   \n",
    "#     adam_opt=Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=None, decay=0.0, amsgrad=params['amsgrad'])\n",
    "#     sgd=SGD(lr=params[\"lr\"], momentum=params['momentum'], decay=0.0, nesterov=params['nesterov'])\n",
    "#     rmsprop=RMSprop(lr=params[\"lr\"], rho=params['rho'], epsilon=None, decay=0.0)\n",
    "\n",
    "#     adam_opt = Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=1e-08, decay=params['decay'])\n",
    "    \n",
    "   \n",
    "    adam_opt = Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=1e-08, decay=0.0)\n",
    "    model.compile(optimizer = adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = nb_train_samples // batch_size,\n",
    "      epochs = 15,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps = nb_validation_samples // batch_size,\n",
    "      verbose = 1)\n",
    "    \n",
    "    score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "    print ('Validation Score: ', score[0])\n",
    "    print ('Validation Accuracy: ',score[1])\n",
    "    \n",
    "    filename = test_generator.filenames\n",
    "    truth = test_generator.classes\n",
    "    label = test_generator.class_indices\n",
    "    indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "    predicts = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "    predict_class = np.argmax(predicts, axis=1)\n",
    "    errors = np.where(predict_class != truth)[0]\n",
    "    print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n",
    "    print(\"*_*\" * 50)\n",
    "#     best_epoch = np.argmax(history.history['val_acc'])\n",
    "#     best_val_acc = np.max(history.history['val_acc'])\n",
    "#     print('Epoch {} - val acc: {}'.format(best_epoch, best_val_acc))\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    return {'loss': score[0], 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_callbacks(params):\n",
    "#     callbacks =[EarlyStopping(monitor='val_acc', patience=5, verbose=1),\n",
    "#                 ModelCheckpoint('callbacks/{}.h5'.format(params['batch_size']), save_best_only=True),\n",
    "#              TensorBoard('tensorlogs/logs-gridsearch', write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)]\n",
    "#     return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters testing:  {'beta_1': 0.3, 'beta_2': 0.995, 'lr': 1e-05}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2371s 641ms/step - loss: 0.6288 - acc: 0.7039 - val_loss: 0.5035 - val_acc: 0.6806\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2297s 621ms/step - loss: 0.4589 - acc: 0.8290 - val_loss: 0.3349 - val_acc: 0.9520\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2296s 621ms/step - loss: 0.3500 - acc: 0.8600 - val_loss: 0.2465 - val_acc: 0.9566\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2295s 621ms/step - loss: 0.2982 - acc: 0.8847 - val_loss: 0.1971 - val_acc: 0.9569\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2296s 621ms/step - loss: 0.2679 - acc: 0.8957 - val_loss: 0.1840 - val_acc: 0.9564\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2296s 621ms/step - loss: 0.2491 - acc: 0.9066 - val_loss: 0.1797 - val_acc: 0.9563\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2298s 621ms/step - loss: 0.2404 - acc: 0.9071 - val_loss: 0.1846 - val_acc: 0.9549\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2302s 622ms/step - loss: 0.2324 - acc: 0.9083 - val_loss: 0.1883 - val_acc: 0.9559\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2299s 622ms/step - loss: 0.2251 - acc: 0.9111 - val_loss: 0.1882 - val_acc: 0.9552\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2300s 622ms/step - loss: 0.2215 - acc: 0.9123 - val_loss: 0.1964 - val_acc: 0.9547\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2300s 622ms/step - loss: 0.2166 - acc: 0.9137 - val_loss: 0.1991 - val_acc: 0.9546\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2301s 622ms/step - loss: 0.2140 - acc: 0.9147 - val_loss: 0.1990 - val_acc: 0.9548\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2304s 623ms/step - loss: 0.2115 - acc: 0.9146 - val_loss: 0.2104 - val_acc: 0.9542\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2300s 622ms/step - loss: 0.2054 - acc: 0.9171 - val_loss: 0.2118 - val_acc: 0.9544\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2294s 620ms/step - loss: 0.2060 - acc: 0.9156 - val_loss: 0.2186 - val_acc: 0.9535\n",
      "Validation Score:  0.21063974637538194\n",
      "Validation Accuracy:  0.955\n",
      "61/60 [==============================] - 27s 439ms/step\n",
      "No of errors = 46/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.8, 'beta_2': 0.9, 'lr': 1e-06}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2387s 646ms/step - loss: 0.2004 - acc: 0.9184 - val_loss: 0.2198 - val_acc: 0.9546\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2322s 628ms/step - loss: 0.2002 - acc: 0.9175 - val_loss: 0.2205 - val_acc: 0.9550\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2318s 627ms/step - loss: 0.2011 - acc: 0.9165 - val_loss: 0.2208 - val_acc: 0.9551\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2316s 626ms/step - loss: 0.1966 - acc: 0.9193 - val_loss: 0.2221 - val_acc: 0.9552\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2317s 626ms/step - loss: 0.1965 - acc: 0.9189 - val_loss: 0.2230 - val_acc: 0.9552\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2316s 626ms/step - loss: 0.1934 - acc: 0.9210 - val_loss: 0.2247 - val_acc: 0.9551\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2317s 627ms/step - loss: 0.1936 - acc: 0.9194 - val_loss: 0.2267 - val_acc: 0.9552\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2316s 626ms/step - loss: 0.1953 - acc: 0.9187 - val_loss: 0.2273 - val_acc: 0.9551\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2312s 625ms/step - loss: 0.1941 - acc: 0.9192 - val_loss: 0.2278 - val_acc: 0.9550\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2314s 626ms/step - loss: 0.1938 - acc: 0.9200 - val_loss: 0.2305 - val_acc: 0.9555\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2315s 626ms/step - loss: 0.1917 - acc: 0.9211 - val_loss: 0.2314 - val_acc: 0.9553\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2315s 626ms/step - loss: 0.1955 - acc: 0.9186 - val_loss: 0.2324 - val_acc: 0.9552\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2317s 626ms/step - loss: 0.1925 - acc: 0.9187 - val_loss: 0.2332 - val_acc: 0.9553\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2318s 627ms/step - loss: 0.1904 - acc: 0.9210 - val_loss: 0.2329 - val_acc: 0.9553\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2314s 626ms/step - loss: 0.1904 - acc: 0.9216 - val_loss: 0.2352 - val_acc: 0.9553\n",
      "Validation Score:  0.24171238861978053\n",
      "Validation Accuracy:  0.95125\n",
      "61/60 [==============================] - 29s 468ms/step\n",
      "No of errors = 44/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.3, 'beta_2': 0.8, 'lr': 0.0001}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2403s 650ms/step - loss: 0.2810 - acc: 0.8976 - val_loss: 0.2857 - val_acc: 0.9530\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2324s 628ms/step - loss: 0.2656 - acc: 0.8981 - val_loss: 0.3469 - val_acc: 0.9521\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2326s 629ms/step - loss: 0.2668 - acc: 0.8968 - val_loss: 0.3593 - val_acc: 0.9527\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2325s 629ms/step - loss: 0.2576 - acc: 0.9030 - val_loss: 0.3744 - val_acc: 0.9525\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2320s 627ms/step - loss: 0.2596 - acc: 0.9022 - val_loss: 0.3792 - val_acc: 0.9526\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2321s 628ms/step - loss: 0.2547 - acc: 0.9029 - val_loss: 0.3843 - val_acc: 0.9531\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2321s 628ms/step - loss: 0.2445 - acc: 0.9067 - val_loss: 0.3912 - val_acc: 0.9529\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2323s 628ms/step - loss: 0.2427 - acc: 0.9080 - val_loss: 0.4003 - val_acc: 0.9525\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2323s 628ms/step - loss: 0.2404 - acc: 0.9101 - val_loss: 0.4049 - val_acc: 0.9535\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2322s 628ms/step - loss: 0.2392 - acc: 0.9115 - val_loss: 0.4221 - val_acc: 0.9525\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2322s 628ms/step - loss: 0.2364 - acc: 0.9129 - val_loss: 0.4335 - val_acc: 0.9522\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2320s 627ms/step - loss: 0.2332 - acc: 0.9136 - val_loss: 0.4351 - val_acc: 0.9525\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2317s 626ms/step - loss: 0.2315 - acc: 0.9126 - val_loss: 0.4581 - val_acc: 0.9538\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2319s 627ms/step - loss: 0.2303 - acc: 0.9144 - val_loss: 0.4548 - val_acc: 0.9544\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2322s 628ms/step - loss: 0.2299 - acc: 0.9143 - val_loss: 0.4677 - val_acc: 0.9535\n",
      "Validation Score:  0.4821702832356095\n",
      "Validation Accuracy:  0.94875\n",
      "61/60 [==============================] - 31s 505ms/step\n",
      "No of errors = 44/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.3, 'beta_2': 0.7, 'lr': 0.001}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2423s 655ms/step - loss: 0.3539 - acc: 0.8419 - val_loss: 0.4822 - val_acc: 0.9520\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2341s 633ms/step - loss: 0.3128 - acc: 0.8671 - val_loss: 0.5220 - val_acc: 0.9515\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2344s 634ms/step - loss: 0.3021 - acc: 0.8833 - val_loss: 0.5055 - val_acc: 0.9519\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2343s 634ms/step - loss: 0.2810 - acc: 0.8952 - val_loss: 0.6246 - val_acc: 0.9516\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2670 - acc: 0.9128 - val_loss: 0.6577 - val_acc: 0.9496\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2700 - acc: 0.9148 - val_loss: 0.6822 - val_acc: 0.9506\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2333s 631ms/step - loss: 0.2653 - acc: 0.9169 - val_loss: 0.6926 - val_acc: 0.9509\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2336s 632ms/step - loss: 0.2575 - acc: 0.9197 - val_loss: 0.7311 - val_acc: 0.9512\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2337s 632ms/step - loss: 0.2586 - acc: 0.9221 - val_loss: 0.7456 - val_acc: 0.9513\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2556 - acc: 0.9223 - val_loss: 0.7077 - val_acc: 0.9512\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2579 - acc: 0.9215 - val_loss: 0.6930 - val_acc: 0.9490\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2558 - acc: 0.9244 - val_loss: 0.7469 - val_acc: 0.9508\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2532 - acc: 0.9276 - val_loss: 0.7246 - val_acc: 0.9507\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2338s 632ms/step - loss: 0.2569 - acc: 0.9259 - val_loss: 0.7412 - val_acc: 0.9506\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2341s 633ms/step - loss: 0.2595 - acc: 0.9243 - val_loss: 0.7584 - val_acc: 0.9508\n",
      "Validation Score:  0.7093650085479021\n",
      "Validation Accuracy:  0.9525\n",
      "61/60 [==============================] - 33s 547ms/step\n",
      "No of errors = 47/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.7, 'beta_2': 0.995, 'lr': 1e-05}\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,672,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: NasNetLarge_model_2/adjust_conv_projection_15/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NasNetLarge_model_2/activation_212/Relu, adjust_conv_projection_15_2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_7/acc/Mean/_70601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_90870_metrics_7/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'NasNetLarge_model_2/adjust_conv_projection_15/convolution', defined at:\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-176a2e060af5>\", line 36, in <module>\n    model = ensembel_model()\n  File \"<ipython-input-12-176a2e060af5>\", line 9, in ensembel_model\n    feature1=NasNetLarge_model(img)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2235, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 780, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,672,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: NasNetLarge_model_2/adjust_conv_projection_15/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NasNetLarge_model_2/activation_212/Relu, adjust_conv_projection_15_2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_7/acc/Mean/_70601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_90870_metrics_7/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,672,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: NasNetLarge_model_2/adjust_conv_projection_15/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NasNetLarge_model_2/activation_212/Relu, adjust_conv_projection_15_2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_7/acc/Mean/_70601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_90870_metrics_7/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-c9777c3a16cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-14-da9f0df0ff64>\u001b[0m in \u001b[0;36mf_nn\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     52\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m       \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_validation_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m       verbose = 1)\n\u001b[0m\u001b[0;32m     55\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,672,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: NasNetLarge_model_2/adjust_conv_projection_15/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NasNetLarge_model_2/activation_212/Relu, adjust_conv_projection_15_2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_7/acc/Mean/_70601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_90870_metrics_7/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\nCaused by op 'NasNetLarge_model_2/adjust_conv_projection_15/convolution', defined at:\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 486, in start\n    self.io_loop.start()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 127, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 117, in _handle_events\n    handler_func(fileobj, events)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tornado\\stack_context.py\", line 276, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2662, in run_cell\n    raw_cell, store_history, silent, shell_futures)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2785, in _run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2903, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2963, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-12-176a2e060af5>\", line 36, in <module>\n    model = ensembel_model()\n  File \"<ipython-input-12-176a2e060af5>\", line 9, in ensembel_model\n    feature1=NasNetLarge_model(img)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 619, in __call__\n    output = self.call(inputs, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2085, in call\n    output_tensors, _, _ = self.run_internal_graph(inputs, masks)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\topology.py\", line 2235, in run_internal_graph\n    output_tensors = _to_list(layer.call(computed_tensor, **kwargs))\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\layers\\convolutional.py\", line 168, in call\n    dilation_rate=self.dilation_rate)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3341, in conv2d\n    data_format=tf_data_format)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 780, in convolution\n    return op(input, filter)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 868, in __call__\n    return self.conv_op(inp, filter)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 520, in __call__\n    return self.call(inp, filter)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 204, in __call__\n    name=self.name)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 1042, in conv2d\n    data_format=data_format, dilations=dilations, name=name)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"C:\\Users\\User\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nResourceExhaustedError (see above for traceback): OOM when allocating tensor with shape[16,672,7,7] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: NasNetLarge_model_2/adjust_conv_projection_15/convolution = Conv2D[T=DT_FLOAT, _class=[\"loc:@train...kpropInput\"], data_format=\"NCHW\", dilations=[1, 1, 1, 1], padding=\"SAME\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](NasNetLarge_model_2/activation_212/Relu, adjust_conv_projection_15_2/kernel/read)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: metrics_7/acc/Mean/_70601 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_90870_metrics_7/acc/Mean\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
