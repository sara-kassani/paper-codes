{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 2232467089428390770, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9221160305\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1899044487927774661\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6683898676\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 2024142322383381888\n",
       " physical_device_desc: \"device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, partial, rand, space_eval\n",
    "from sklearn.metrics import log_loss\n",
    "import sys\n",
    "import time\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from glob import glob\n",
    "import cv2\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import layers\n",
    "from keras import models\n",
    "from keras import optimizers\n",
    "from keras.models import load_model\n",
    "# import keras.callbacks as kcall\n",
    "from keras.optimizers import Adam, RMSprop,SGD\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from keras.applications.xception import Xception, preprocess_input\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.regularizers import l2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Input, concatenate\n",
    "from keras import optimizers, metrics, models\n",
    "from keras.layers import Input, Flatten, Dense\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keras Version 2.1.6\n",
      "tensorflow Version 1.10.0\n",
      "dim_ordering: tf\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "print(\"Keras Version\", keras.__version__)\n",
    "print(\"tensorflow Version\", tf.__version__)\n",
    "print(\"dim_ordering:\", K.image_dim_ordering())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classes = 2\n",
    "batch_size = 16\n",
    "img_height, img_width = 224, 224\n",
    "input_shape = (img_height, img_width, 3)\n",
    "epochs = 50\n",
    "\n",
    "nb_train_samples = 59168\n",
    "nb_validation_samples = 18384\n",
    "nb_test_samples = 967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "validation_dir = 'data/validation'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 59168 images belonging to 2 classes.\n",
      "Found 18384 images belonging to 2 classes.\n",
      "Found 967 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(1142)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n"
     ]
    }
   ],
   "source": [
    "def ensembel_model():\n",
    "    NasNetLarge_model = load_model('models/5.NASNetLarge-new-ISBI19-Model.h5', compile=False)\n",
    "    NasNetLarge_model = Model(inputs= NasNetLarge_model.input,outputs = NasNetLarge_model.get_layer('dense_3').output, name='NasNetLarge_model')\n",
    "    VGG19_model = load_model('models/11.VGG19-ISBI19-Model.h5')\n",
    "    VGG19_model = Model(inputs = VGG19_model.input,outputs = VGG19_model.get_layer('dense_3').output, name='VGG19_model')\n",
    "    \n",
    "    img = Input(shape=(224, 224,3),name='img')\n",
    "\n",
    "    feature1=NasNetLarge_model(img)\n",
    "    # feature2=InceptionV3_model(img)\n",
    "\n",
    "    for layer in NasNetLarge_model.layers[:300]:  \n",
    "        layer.trainable = False \n",
    "    for layer in NasNetLarge_model.layers[300:]:  \n",
    "        layer.trainable = True  \n",
    "\n",
    "    feature3=VGG19_model(img)\n",
    "    for layer in VGG19_model.layers[:170]:  \n",
    "        layer.trainable = False \n",
    "    for layer in VGG19_model.layers[170:]:  \n",
    "        layer.trainable = True  \n",
    "\n",
    "    # x = concatenate([feature1,feature2,feature3])\n",
    "    x = concatenate([feature1,feature3])\n",
    "\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(64,activation='relu')(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    output = Dense(2, activation='softmax', name='output')(x)\n",
    "\n",
    "    model=Model(inputs=img,outputs=output)\n",
    "\n",
    "\n",
    "    return model\n",
    "\n",
    "model = ensembel_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "         'lr': hp.choice('lr',[0.001, 0.0001, 0.00001,0.000001]),\n",
    "#          'dropout': hp.choice('dropout', [0.4, 0.5, 0.6, 0.7]),\n",
    "#          'batch_size': hp.choice('batch_size', [64]),\n",
    "#          'epochs': hp.choice('epochs', [15, 20, 25, 30, 50]),\n",
    "#          'optimizer': hp.choice('optimizer',['sgd','adam','rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['rmsprop']),\n",
    "#          'optimizer': hp.choice('optimizer',['adam']),\n",
    "         'beta_1':hp.choice('beta_1',[0.3,0.4,0.5,0.6,0.7,0.8]),\n",
    "         'beta_2':hp.choice('beta_2',[0.99,0.995,0.7,0.8,0.9,0.999]),\n",
    "         'decay':hp.choice('decay',[0.0, 0.004, 0.0001, 0.1, 0.3, 0.5]),\n",
    "#          'momentum':hp.choice('momentum',[0.3,0.5,0.7,0.9,1]),\n",
    "#          'amsgrad':hp.choice('amsgrad',[False,True]),\n",
    "#          'nesterov':hp.choice('nesterov',[False,True]),\n",
    "#          'rho':hp.choice('rho',[0.4,0.5,0.6,0.7,0.8,0.9,1]),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_nn(params):   \n",
    "    print ('Parameters testing: ', params)\n",
    "#     batch_size=params['batch_size']\n",
    "\n",
    "#     random_seed = np.random.seed(1132)\n",
    "\n",
    "#     train_datagen = ImageDataGenerator(\n",
    "#         rescale=1. / 255,\n",
    "#         featurewise_center=True,\n",
    "#         featurewise_std_normalization=True)\n",
    "\n",
    "#     test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "#     train_generator = train_datagen.flow_from_directory(\n",
    "#         train_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = True,\n",
    "#         seed = random_seed,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#     validation_generator = train_datagen.flow_from_directory(\n",
    "#         validation_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = True,\n",
    "#         seed = random_seed,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "#     test_generator = test_datagen.flow_from_directory(\n",
    "#         test_dir,\n",
    "#         target_size=(img_height, img_width),\n",
    "#         batch_size=batch_size,\n",
    "#         shuffle = False,\n",
    "#         class_mode='categorical')\n",
    "\n",
    "   \n",
    "#     adam_opt=Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=None, decay=0.0, amsgrad=params['amsgrad'])\n",
    "#     sgd=SGD(lr=params[\"lr\"], momentum=params['momentum'], decay=0.0, nesterov=params['nesterov'])\n",
    "#     rmsprop=RMSprop(lr=params[\"lr\"], rho=params['rho'], epsilon=None, decay=0.0)\n",
    "\n",
    "    adam_opt = Adam(lr=params[\"lr\"], beta_1=params[\"beta_1\"], beta_2=params['beta_2'], epsilon=1e-08, decay=params['decay'])\n",
    "    \n",
    "    model.compile(optimizer = adam_opt, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit_generator(\n",
    "      train_generator,\n",
    "      steps_per_epoch = nb_train_samples // batch_size,\n",
    "      epochs = 15,\n",
    "      validation_data = validation_generator,\n",
    "      validation_steps = nb_validation_samples // batch_size,\n",
    "      verbose = 1)\n",
    "    \n",
    "    score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "    print ('Validation Score: ', score[0])\n",
    "    print ('Validation Accuracy: ',score[1])\n",
    "    \n",
    "    filename = test_generator.filenames\n",
    "    truth = test_generator.classes\n",
    "    label = test_generator.class_indices\n",
    "    indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "    predicts = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "    predict_class = np.argmax(predicts, axis=1)\n",
    "    errors = np.where(predict_class != truth)[0]\n",
    "    print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))\n",
    "    print(\"*_*\" * 50)\n",
    "#     best_epoch = np.argmax(history.history['val_acc'])\n",
    "#     best_val_acc = np.max(history.history['val_acc'])\n",
    "#     print('Epoch {} - val acc: {}'.format(best_epoch, best_val_acc))\n",
    "    sys.stdout.flush() \n",
    "    \n",
    "    return {'loss': score[0], 'status': STATUS_OK, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_callbacks(params):\n",
    "#     callbacks =[EarlyStopping(monitor='val_acc', patience=5, verbose=1),\n",
    "#                 ModelCheckpoint('callbacks/{}.h5'.format(params['batch_size']), save_best_only=True),\n",
    "#              TensorBoard('tensorlogs/logs-gridsearch', write_graph=True, write_grads=True, write_images=True, embeddings_freq=0, embeddings_layer_names=None, embeddings_metadata=None)]\n",
    "#     return callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters testing:  {'beta_1': 0.3, 'beta_2': 0.999, 'decay': 0.3, 'lr': 0.001}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2330s 630ms/step - loss: 0.7063 - acc: 0.5960 - val_loss: 0.6493 - val_acc: 0.8596\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2277s 616ms/step - loss: 0.6474 - acc: 0.6682 - val_loss: 0.6222 - val_acc: 0.9380\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2276s 615ms/step - loss: 0.6271 - acc: 0.7008 - val_loss: 0.6060 - val_acc: 0.9409\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2278s 616ms/step - loss: 0.6151 - acc: 0.7175 - val_loss: 0.5954 - val_acc: 0.9433\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2279s 616ms/step - loss: 0.6055 - acc: 0.7302 - val_loss: 0.5871 - val_acc: 0.9440\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2283s 617ms/step - loss: 0.5974 - acc: 0.7431 - val_loss: 0.5805 - val_acc: 0.9453\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2281s 617ms/step - loss: 0.5919 - acc: 0.7483 - val_loss: 0.5748 - val_acc: 0.9468\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2280s 616ms/step - loss: 0.5859 - acc: 0.7597 - val_loss: 0.5702 - val_acc: 0.9471\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2275s 615ms/step - loss: 0.5812 - acc: 0.7677 - val_loss: 0.5660 - val_acc: 0.9481\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2282s 617ms/step - loss: 0.5784 - acc: 0.7696 - val_loss: 0.5622 - val_acc: 0.9481\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2279s 616ms/step - loss: 0.5745 - acc: 0.7726 - val_loss: 0.5590 - val_acc: 0.9478\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2280s 616ms/step - loss: 0.5724 - acc: 0.7749 - val_loss: 0.5562 - val_acc: 0.9484\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2280s 616ms/step - loss: 0.5691 - acc: 0.7836 - val_loss: 0.5536 - val_acc: 0.9485\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2279s 616ms/step - loss: 0.5666 - acc: 0.7850 - val_loss: 0.5512 - val_acc: 0.9485\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2279s 616ms/step - loss: 0.5654 - acc: 0.7870 - val_loss: 0.5488 - val_acc: 0.9487\n",
      "Validation Score:  0.5485156655311585\n",
      "Validation Accuracy:  0.955\n",
      "61/60 [==============================] - 20s 331ms/step\n",
      "No of errors = 52/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.8, 'beta_2': 0.8, 'decay': 0.0, 'lr': 1e-06}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2345s 634ms/step - loss: 0.5442 - acc: 0.8121 - val_loss: 0.5119 - val_acc: 0.9403\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2292s 620ms/step - loss: 0.5128 - acc: 0.8365 - val_loss: 0.4807 - val_acc: 0.9385\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2284s 618ms/step - loss: 0.4840 - acc: 0.8547 - val_loss: 0.4523 - val_acc: 0.9375\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2285s 618ms/step - loss: 0.4614 - acc: 0.8616 - val_loss: 0.4319 - val_acc: 0.9294\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2287s 618ms/step - loss: 0.4341 - acc: 0.8727 - val_loss: 0.4051 - val_acc: 0.9344\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2284s 618ms/step - loss: 0.4139 - acc: 0.8782 - val_loss: 0.3915 - val_acc: 0.9247\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2284s 618ms/step - loss: 0.3949 - acc: 0.8829 - val_loss: 0.3671 - val_acc: 0.9319\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2285s 618ms/step - loss: 0.3776 - acc: 0.8885 - val_loss: 0.3584 - val_acc: 0.9219\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2287s 619ms/step - loss: 0.3619 - acc: 0.8933 - val_loss: 0.3309 - val_acc: 0.9359\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2289s 619ms/step - loss: 0.3470 - acc: 0.8988 - val_loss: 0.3113 - val_acc: 0.9414\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2290s 619ms/step - loss: 0.3341 - acc: 0.9014 - val_loss: 0.2982 - val_acc: 0.9417\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2285s 618ms/step - loss: 0.3224 - acc: 0.9072 - val_loss: 0.2836 - val_acc: 0.9442\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2284s 618ms/step - loss: 0.3121 - acc: 0.9086 - val_loss: 0.2679 - val_acc: 0.9507\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2282s 617ms/step - loss: 0.3027 - acc: 0.9097 - val_loss: 0.2574 - val_acc: 0.9516\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2284s 618ms/step - loss: 0.2934 - acc: 0.9133 - val_loss: 0.2539 - val_acc: 0.9442\n",
      "Validation Score:  0.2565405723452568\n",
      "Validation Accuracy:  0.945\n",
      "61/60 [==============================] - 21s 346ms/step\n",
      "No of errors = 62/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.5, 'beta_2': 0.999, 'decay': 0.3, 'lr': 0.001}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2349s 635ms/step - loss: 0.3123 - acc: 0.8841 - val_loss: 0.2322 - val_acc: 0.9446\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2293s 620ms/step - loss: 0.2978 - acc: 0.8930 - val_loss: 0.2242 - val_acc: 0.9508\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2300s 622ms/step - loss: 0.2901 - acc: 0.8973 - val_loss: 0.2214 - val_acc: 0.9525\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2299s 622ms/step - loss: 0.2905 - acc: 0.8958 - val_loss: 0.2193 - val_acc: 0.9530\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2295s 621ms/step - loss: 0.2880 - acc: 0.8982 - val_loss: 0.2177 - val_acc: 0.9540\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2295s 621ms/step - loss: 0.2832 - acc: 0.8999 - val_loss: 0.2166 - val_acc: 0.9543\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2293s 620ms/step - loss: 0.2826 - acc: 0.8996 - val_loss: 0.2151 - val_acc: 0.9537\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2299s 622ms/step - loss: 0.2816 - acc: 0.9005 - val_loss: 0.2145 - val_acc: 0.9539\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2300s 622ms/step - loss: 0.2823 - acc: 0.8993 - val_loss: 0.2138 - val_acc: 0.9541\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2299s 622ms/step - loss: 0.2832 - acc: 0.8976 - val_loss: 0.2132 - val_acc: 0.9542\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2301s 622ms/step - loss: 0.2816 - acc: 0.9008 - val_loss: 0.2128 - val_acc: 0.9543\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2302s 623ms/step - loss: 0.2796 - acc: 0.9008 - val_loss: 0.2122 - val_acc: 0.9541\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2303s 623ms/step - loss: 0.2800 - acc: 0.9004 - val_loss: 0.2116 - val_acc: 0.9542\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2300s 622ms/step - loss: 0.2785 - acc: 0.9006 - val_loss: 0.2113 - val_acc: 0.9543\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2301s 622ms/step - loss: 0.2782 - acc: 0.9014 - val_loss: 0.2109 - val_acc: 0.9543\n",
      "Validation Score:  0.21958805590867997\n",
      "Validation Accuracy:  0.9475\n",
      "61/60 [==============================] - 23s 373ms/step\n",
      "No of errors = 52/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.5, 'beta_2': 0.8, 'decay': 0.0, 'lr': 0.0001}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2367s 640ms/step - loss: 0.2822 - acc: 0.8895 - val_loss: 0.2434 - val_acc: 0.9511\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2304s 623ms/step - loss: 0.2700 - acc: 0.8955 - val_loss: 0.3123 - val_acc: 0.9523\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2307s 624ms/step - loss: 0.2717 - acc: 0.8974 - val_loss: 0.3414 - val_acc: 0.9521\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2307s 624ms/step - loss: 0.2712 - acc: 0.8964 - val_loss: 0.3620 - val_acc: 0.9518\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2309s 624ms/step - loss: 0.2703 - acc: 0.8985 - val_loss: 0.3643 - val_acc: 0.9523\n",
      "Epoch 6/15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3698/3698 [==============================] - 2309s 624ms/step - loss: 0.2765 - acc: 0.8936 - val_loss: 0.3690 - val_acc: 0.9520\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2310s 625ms/step - loss: 0.2761 - acc: 0.8944 - val_loss: 0.3677 - val_acc: 0.9525\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2309s 624ms/step - loss: 0.2695 - acc: 0.8977 - val_loss: 0.3809 - val_acc: 0.9518\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2309s 624ms/step - loss: 0.2672 - acc: 0.8982 - val_loss: 0.3688 - val_acc: 0.9525\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2308s 624ms/step - loss: 0.2725 - acc: 0.8958 - val_loss: 0.3820 - val_acc: 0.9518\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2304s 623ms/step - loss: 0.2806 - acc: 0.8952 - val_loss: 0.3889 - val_acc: 0.9521\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2307s 624ms/step - loss: 0.2789 - acc: 0.8957 - val_loss: 0.3909 - val_acc: 0.9519\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2310s 625ms/step - loss: 0.2690 - acc: 0.8978 - val_loss: 0.3813 - val_acc: 0.9515\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2308s 624ms/step - loss: 0.2645 - acc: 0.8996 - val_loss: 0.3932 - val_acc: 0.9521\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2308s 624ms/step - loss: 0.2636 - acc: 0.9015 - val_loss: 0.3971 - val_acc: 0.9521\n",
      "Validation Score:  0.3941365613415837\n",
      "Validation Accuracy:  0.95375\n",
      "61/60 [==============================] - 24s 398ms/step\n",
      "No of errors = 47/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.5, 'beta_2': 0.999, 'decay': 0.0, 'lr': 0.0001}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2376s 642ms/step - loss: 0.2877 - acc: 0.8871 - val_loss: 0.3287 - val_acc: 0.9521\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2308s 624ms/step - loss: 0.2845 - acc: 0.8857 - val_loss: 0.3207 - val_acc: 0.9523\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2311s 625ms/step - loss: 0.2811 - acc: 0.8885 - val_loss: 0.3442 - val_acc: 0.9520\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2312s 625ms/step - loss: 0.2736 - acc: 0.8905 - val_loss: 0.3282 - val_acc: 0.9520\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2310s 625ms/step - loss: 0.2609 - acc: 0.8959 - val_loss: 0.3470 - val_acc: 0.9521\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2311s 625ms/step - loss: 0.2889 - acc: 0.8834 - val_loss: 0.3260 - val_acc: 0.9516\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2312s 625ms/step - loss: 0.2690 - acc: 0.8939 - val_loss: 0.3260 - val_acc: 0.9519\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2312s 625ms/step - loss: 0.2600 - acc: 0.8974 - val_loss: 0.3218 - val_acc: 0.9520\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2312s 625ms/step - loss: 0.2629 - acc: 0.8964 - val_loss: 0.3270 - val_acc: 0.9518\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2307s 624ms/step - loss: 0.2483 - acc: 0.9019 - val_loss: 0.3369 - val_acc: 0.9519\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2306s 623ms/step - loss: 0.2432 - acc: 0.9035 - val_loss: 0.3568 - val_acc: 0.9526\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2310s 625ms/step - loss: 0.2393 - acc: 0.9042 - val_loss: 0.3430 - val_acc: 0.9519\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2312s 625ms/step - loss: 0.2346 - acc: 0.9069 - val_loss: 0.3410 - val_acc: 0.9521\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2309s 625ms/step - loss: 0.2327 - acc: 0.9075 - val_loss: 0.3496 - val_acc: 0.9520\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2308s 624ms/step - loss: 0.2310 - acc: 0.9071 - val_loss: 0.3572 - val_acc: 0.9524\n",
      "Validation Score:  0.30314044415950775\n",
      "Validation Accuracy:  0.95875\n",
      "61/60 [==============================] - 26s 429ms/step\n",
      "No of errors = 44/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.4, 'beta_2': 0.995, 'decay': 0.5, 'lr': 1e-05}\n",
      "Epoch 1/15\n",
      "3698/3698 [==============================] - 2391s 646ms/step - loss: 0.2308 - acc: 0.9073 - val_loss: 0.3486 - val_acc: 0.9521\n",
      "Epoch 2/15\n",
      "3698/3698 [==============================] - 2320s 627ms/step - loss: 0.2287 - acc: 0.9090 - val_loss: 0.3467 - val_acc: 0.9520\n",
      "Epoch 3/15\n",
      "3698/3698 [==============================] - 2320s 627ms/step - loss: 0.2323 - acc: 0.9070 - val_loss: 0.3471 - val_acc: 0.9521\n",
      "Epoch 4/15\n",
      "3698/3698 [==============================] - 2322s 628ms/step - loss: 0.2280 - acc: 0.9100 - val_loss: 0.3464 - val_acc: 0.9520\n",
      "Epoch 5/15\n",
      "3698/3698 [==============================] - 2321s 628ms/step - loss: 0.2326 - acc: 0.9072 - val_loss: 0.3465 - val_acc: 0.9520\n",
      "Epoch 6/15\n",
      "3698/3698 [==============================] - 2321s 628ms/step - loss: 0.2285 - acc: 0.9100 - val_loss: 0.3465 - val_acc: 0.9520\n",
      "Epoch 7/15\n",
      "3698/3698 [==============================] - 2321s 628ms/step - loss: 0.2298 - acc: 0.9094 - val_loss: 0.3464 - val_acc: 0.9522\n",
      "Epoch 8/15\n",
      "3698/3698 [==============================] - 2319s 627ms/step - loss: 0.2293 - acc: 0.9081 - val_loss: 0.3462 - val_acc: 0.9521\n",
      "Epoch 9/15\n",
      "3698/3698 [==============================] - 2316s 626ms/step - loss: 0.2302 - acc: 0.9084 - val_loss: 0.3459 - val_acc: 0.9522\n",
      "Epoch 10/15\n",
      "3698/3698 [==============================] - 2321s 628ms/step - loss: 0.2301 - acc: 0.9081 - val_loss: 0.3466 - val_acc: 0.9520\n",
      "Epoch 11/15\n",
      "3698/3698 [==============================] - 2313s 626ms/step - loss: 0.2279 - acc: 0.9099 - val_loss: 0.3464 - val_acc: 0.9520\n",
      "Epoch 12/15\n",
      "3698/3698 [==============================] - 2313s 625ms/step - loss: 0.2265 - acc: 0.9119 - val_loss: 0.3466 - val_acc: 0.9525\n",
      "Epoch 13/15\n",
      "3698/3698 [==============================] - 2314s 626ms/step - loss: 0.2300 - acc: 0.9085 - val_loss: 0.3468 - val_acc: 0.9520\n",
      "Epoch 14/15\n",
      "3698/3698 [==============================] - 2314s 626ms/step - loss: 0.2311 - acc: 0.9085 - val_loss: 0.3468 - val_acc: 0.9521\n",
      "Epoch 15/15\n",
      "3698/3698 [==============================] - 2316s 626ms/step - loss: 0.2262 - acc: 0.9102 - val_loss: 0.3464 - val_acc: 0.9521\n",
      "Validation Score:  0.3042391202971339\n",
      "Validation Accuracy:  0.95625\n",
      "61/60 [==============================] - 28s 456ms/step\n",
      "No of errors = 46/967\n",
      "*_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_**_*\n",
      "Parameters testing:  {'beta_1': 0.5, 'beta_2': 0.99, 'decay': 0.0, 'lr': 0.001}\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "OOM when allocating tensor with shape[16,14,14,336] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_7/Adam/gradients/zeros_357-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_7/Adam/gradients/zeros_357, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/BiasAdd/_51005 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_44717_output/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1277\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1278\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1279\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1263\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1350\u001b[1;33m         run_metadata)\n\u001b[0m\u001b[0;32m   1351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,14,14,336] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_7/Adam/gradients/zeros_357-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_7/Adam/gradients/zeros_357, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/BiasAdd/_51005 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_44717_output/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c9777c3a16cd>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtrials\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTrials\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf_nn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_evals\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    365\u001b[0m             \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    366\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 367\u001b[1;33m             \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_argmin\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    368\u001b[0m         )\n\u001b[0;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(self, fn, space, algo, max_evals, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin)\u001b[0m\n\u001b[0;32m    633\u001b[0m             \u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpass_expr_memo_ctrl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    634\u001b[0m             \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 635\u001b[1;33m             return_argmin=return_argmin)\n\u001b[0m\u001b[0;32m    636\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    637\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len)\u001b[0m\n\u001b[0;32m    383\u001b[0m                     max_queue_len=max_queue_len)\n\u001b[0;32m    384\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 385\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    386\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    387\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    216\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    217\u001b[0m                 \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 218\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    219\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mstopped\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    838\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    839\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 840\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    841\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    842\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-10-dde62f278432>\u001b[0m in \u001b[0;36mf_nn\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m     50\u001b[0m       \u001b[0mvalidation_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m       \u001b[0mvalidation_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnb_validation_samples\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m       verbose = 1)\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate_generator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_generator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\legacy\\interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name +\n\u001b[0;32m     90\u001b[0m                               '` call to the Keras 2 API: ' + signature, stacklevel=2)\n\u001b[1;32m---> 91\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   2228\u001b[0m                     outs = self.train_on_batch(x, y,\n\u001b[0;32m   2229\u001b[0m                                                \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2230\u001b[1;33m                                                class_weight=class_weight)\n\u001b[0m\u001b[0;32m   2231\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2232\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[0;32m   1881\u001b[0m             \u001b[0mins\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1882\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1883\u001b[1;33m         \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1884\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1885\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2480\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2481\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2482\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2483\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    875\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 877\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    878\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1098\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1100\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1101\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1270\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1272\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1273\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1274\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1289\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1291\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1292\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1293\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mResourceExhaustedError\u001b[0m: OOM when allocating tensor with shape[16,14,14,336] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[Node: training_7/Adam/gradients/zeros_357-0-1-TransposeNCHWToNHWC-LayoutOptimizer = Transpose[T=DT_FLOAT, Tperm=DT_INT32, _device=\"/job:localhost/replica:0/task:0/device:GPU:0\"](training_7/Adam/gradients/zeros_357, PermConstNCHWToNHWC-LayoutOptimizer)]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n\n\t [[Node: output/BiasAdd/_51005 = _Recv[client_terminated=false, recv_device=\"/job:localhost/replica:0/task:0/device:CPU:0\", send_device=\"/job:localhost/replica:0/task:0/device:GPU:0\", send_device_incarnation=1, tensor_name=\"edge_44717_output/BiasAdd\", tensor_type=DT_FLOAT, _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(f_nn, space, algo=tpe.suggest, max_evals=30, trials=trials)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
