{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'2.1.6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import keras\n",
    "keras.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 6936054124026338109, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 9221160305\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 1673665978418898298\n",
       " physical_device_desc: \"device: 0, name: GeForce GTX 1080 Ti, pci bus id: 0000:01:00.0, compute capability: 6.1\", name: \"/device:GPU:1\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 6683898676\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 8992179746370486329\n",
       " physical_device_desc: \"device: 1, name: GeForce GTX 1070 Ti, pci bus id: 0000:02:00.0, compute capability: 6.1\"]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.applications import *\n",
    "from keras.models import Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras.applications.xception import preprocess_input\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed=seed)\n",
    "tf.set_random_seed(seed=seed)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "from keras.layers.core import Dropout, Dense\n",
    "from keras.models import Model, load_model\n",
    "from keras.initializers import he_normal, glorot_normal\n",
    "from keras import optimizers\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "based_model_last_block_layer_number = 400\n",
    "transformation_ratio = .5\n",
    "\n",
    "# output_classes = 2\n",
    "batch_size = 32 \n",
    "img_height, img_width = 299, 299\n",
    "epochs = 50\n",
    "\n",
    "nb_train_samples = 632384\n",
    "nb_validation_samples = 184732\n",
    "nb_test_samples = 15744"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'data/train/'\n",
    "validation_dir = 'data/validation'\n",
    "test_dir = 'data/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/train/ 0\n",
      "data/train/cancer 256400\n",
      "data/train/normal 375984\n",
      "******************************\n",
      "data/validation 0\n",
      "data/validation\\cancer 74592\n",
      "data/validation\\normal 110140\n",
      "******************************\n",
      "data/test 0\n",
      "data/test\\cancer 6368\n",
      "data/test\\normal 9376\n"
     ]
    }
   ],
   "source": [
    "for root,dirs,files in os.walk(train_dir):\n",
    "    print (root, len(files))\n",
    "\n",
    "print(\"*\"*30)\n",
    "for root,dirs,files in os.walk(validation_dir):\n",
    "    print (root, len(files))\n",
    "    \n",
    "print(\"*\"*30)\n",
    "for root,dirs,files in os.walk(test_dir):\n",
    "    print (root, len(files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 632384 images belonging to 2 classes.\n",
      "Found 184732 images belonging to 2 classes.\n",
      "Found 15744 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "random_seed = np.random.seed(seed)\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    featurewise_center=True,\n",
    "    featurewise_std_normalization=True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = True,\n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    seed = random_seed,\n",
    "    shuffle = False,\n",
    "    class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.7/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "219062272/219055592 [==============================] - 11s 0us/step\n"
     ]
    }
   ],
   "source": [
    "base_model = InceptionResNetV2(\n",
    "    include_top=False, weights= \"imagenet\", input_shape=(299, 299, 3), pooling='max')\n",
    "\n",
    "x = base_model.output\n",
    "# x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation=\"softmax\", kernel_initializer=glorot_normal(),\n",
    "                    kernel_regularizer=l2(0.0001), bias_regularizer=l2(0.0001))(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adam=Adam(lr=  1e-06, beta_1= 0.3, beta_2=0.8, epsilon=None, decay=0.0, amsgrad=params['amsgrad'])\n",
    "sgd_opt=SGD(lr=1e-06, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "model.compile(optimizer = sgd_opt, loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "19762/19762 [==============================] - 14908s 754ms/step - loss: 1.4229 - acc: 0.5063 - val_loss: 1.0147 - val_acc: 0.5590\n",
      "Epoch 2/50\n",
      "19762/19762 [==============================] - 14880s 753ms/step - loss: 1.3125 - acc: 0.5426 - val_loss: 0.9368 - val_acc: 0.6200\n",
      "Epoch 3/50\n",
      "19762/19762 [==============================] - 14884s 753ms/step - loss: 1.2391 - acc: 0.5716 - val_loss: 0.8892 - val_acc: 0.6580\n",
      "Epoch 4/50\n",
      "19762/19762 [==============================] - 14865s 752ms/step - loss: 1.1832 - acc: 0.5962 - val_loss: 0.8558 - val_acc: 0.6805\n",
      "Epoch 5/50\n",
      "19762/19762 [==============================] - 14867s 752ms/step - loss: 1.1399 - acc: 0.6155 - val_loss: 0.8253 - val_acc: 0.7048\n",
      "Epoch 6/50\n",
      "19762/19762 [==============================] - 14872s 753ms/step - loss: 1.1086 - acc: 0.6313 - val_loss: 0.8148 - val_acc: 0.7121\n",
      "Epoch 7/50\n",
      "19762/19762 [==============================] - 14870s 752ms/step - loss: 1.0779 - acc: 0.6451 - val_loss: 0.7970 - val_acc: 0.7235\n",
      "Epoch 8/50\n",
      "19762/19762 [==============================] - 14876s 753ms/step - loss: 1.0560 - acc: 0.6560 - val_loss: 0.7845 - val_acc: 0.7342\n",
      "Epoch 9/50\n",
      "19762/19762 [==============================] - 14879s 753ms/step - loss: 1.0329 - acc: 0.6664 - val_loss: 0.7706 - val_acc: 0.7408\n",
      "Epoch 10/50\n",
      "19762/19762 [==============================] - 14865s 752ms/step - loss: 1.0143 - acc: 0.6747 - val_loss: 0.7659 - val_acc: 0.7443\n",
      "Epoch 11/50\n",
      "19762/19762 [==============================] - 14873s 753ms/step - loss: 0.9978 - acc: 0.6821 - val_loss: 0.7573 - val_acc: 0.7505\n",
      "Epoch 12/50\n",
      "19762/19762 [==============================] - 14873s 753ms/step - loss: 0.9837 - acc: 0.6885 - val_loss: 0.7434 - val_acc: 0.7585\n",
      "Epoch 13/50\n",
      "19762/19762 [==============================] - 14877s 753ms/step - loss: 0.9684 - acc: 0.6951 - val_loss: 0.7375 - val_acc: 0.7631\n",
      "Epoch 14/50\n",
      "19762/19762 [==============================] - 14879s 753ms/step - loss: 0.9554 - acc: 0.7016 - val_loss: 0.7253 - val_acc: 0.7706\n",
      "Epoch 15/50\n",
      "19762/19762 [==============================] - 14886s 753ms/step - loss: 0.9421 - acc: 0.7065 - val_loss: 0.7223 - val_acc: 0.7725\n",
      "Epoch 16/50\n",
      "19762/19762 [==============================] - 14881s 753ms/step - loss: 0.9293 - acc: 0.7127 - val_loss: 0.7100 - val_acc: 0.7797\n",
      "Epoch 17/50\n",
      "19762/19762 [==============================] - 14875s 753ms/step - loss: 0.9181 - acc: 0.7172 - val_loss: 0.7057 - val_acc: 0.7822\n",
      "Epoch 18/50\n",
      "19762/19762 [==============================] - 14872s 753ms/step - loss: 0.9076 - acc: 0.7217 - val_loss: 0.6953 - val_acc: 0.7873\n",
      "Epoch 19/50\n",
      "19762/19762 [==============================] - 14886s 753ms/step - loss: 0.8968 - acc: 0.7262 - val_loss: 0.6912 - val_acc: 0.7901\n",
      "Epoch 20/50\n",
      "19762/19762 [==============================] - 14881s 753ms/step - loss: 0.8872 - acc: 0.7300 - val_loss: 0.6869 - val_acc: 0.7929\n",
      "Epoch 21/50\n",
      "19762/19762 [==============================] - 14883s 753ms/step - loss: 0.8804 - acc: 0.7340 - val_loss: 0.6770 - val_acc: 0.7990\n",
      "Epoch 22/50\n",
      "19762/19762 [==============================] - 14863s 752ms/step - loss: 0.8704 - acc: 0.7376 - val_loss: 0.6703 - val_acc: 0.8014\n",
      "Epoch 23/50\n",
      "19762/19762 [==============================] - 14874s 753ms/step - loss: 0.8610 - acc: 0.7414 - val_loss: 0.6658 - val_acc: 0.8051\n",
      "Epoch 24/50\n",
      "19762/19762 [==============================] - 14868s 752ms/step - loss: 0.8504 - acc: 0.7452 - val_loss: 0.6641 - val_acc: 0.8058\n",
      "Epoch 25/50\n",
      "19762/19762 [==============================] - 14882s 753ms/step - loss: 0.8452 - acc: 0.7489 - val_loss: 0.6546 - val_acc: 0.8110\n",
      "Epoch 26/50\n",
      "19762/19762 [==============================] - 14878s 753ms/step - loss: 0.8350 - acc: 0.7522 - val_loss: 0.6556 - val_acc: 0.8101\n",
      "Epoch 27/50\n",
      "19762/19762 [==============================] - 14875s 753ms/step - loss: 0.8294 - acc: 0.7547 - val_loss: 0.6481 - val_acc: 0.8143\n",
      "Epoch 28/50\n",
      "19762/19762 [==============================] - 14866s 752ms/step - loss: 0.8234 - acc: 0.7578 - val_loss: 0.6409 - val_acc: 0.8191\n",
      "Epoch 29/50\n",
      "19762/19762 [==============================] - 14892s 754ms/step - loss: 0.8156 - acc: 0.7607 - val_loss: 0.6366 - val_acc: 0.8207\n",
      "Epoch 30/50\n",
      "19762/19762 [==============================] - 14862s 752ms/step - loss: 0.8109 - acc: 0.7629 - val_loss: 0.6319 - val_acc: 0.8236\n",
      "Epoch 31/50\n",
      "19762/19762 [==============================] - 14870s 752ms/step - loss: 0.8042 - acc: 0.7650 - val_loss: 0.6331 - val_acc: 0.8219\n",
      "Epoch 32/50\n",
      "19762/19762 [==============================] - 14868s 752ms/step - loss: 0.7967 - acc: 0.7686 - val_loss: 0.6286 - val_acc: 0.8240\n",
      "Epoch 33/50\n",
      "19762/19762 [==============================] - 14872s 753ms/step - loss: 0.7909 - acc: 0.7713 - val_loss: 0.6223 - val_acc: 0.8280\n",
      "Epoch 34/50\n",
      "19762/19762 [==============================] - 14868s 752ms/step - loss: 0.7830 - acc: 0.7743 - val_loss: 0.6190 - val_acc: 0.8296\n",
      "Epoch 35/50\n",
      "19762/19762 [==============================] - 14875s 753ms/step - loss: 0.7794 - acc: 0.7752 - val_loss: 0.6184 - val_acc: 0.8305\n",
      "Epoch 36/50\n",
      "19762/19762 [==============================] - 14872s 753ms/step - loss: 0.7736 - acc: 0.7786 - val_loss: 0.6103 - val_acc: 0.8345\n",
      "Epoch 37/50\n",
      "19762/19762 [==============================] - 14869s 752ms/step - loss: 0.7667 - acc: 0.7806 - val_loss: 0.6119 - val_acc: 0.8344\n",
      "Epoch 38/50\n",
      "19762/19762 [==============================] - 14873s 753ms/step - loss: 0.7615 - acc: 0.7829 - val_loss: 0.6044 - val_acc: 0.8376\n",
      "Epoch 39/50\n",
      "19762/19762 [==============================] - 14875s 753ms/step - loss: 0.7574 - acc: 0.7848 - val_loss: 0.6001 - val_acc: 0.8400\n",
      "Epoch 40/50\n",
      "19762/19762 [==============================] - 14859s 752ms/step - loss: 0.7513 - acc: 0.7873 - val_loss: 0.6000 - val_acc: 0.8398\n",
      "Epoch 41/50\n",
      "19762/19762 [==============================] - 14881s 753ms/step - loss: 0.7483 - acc: 0.7888 - val_loss: 0.5980 - val_acc: 0.8409\n",
      "Epoch 42/50\n",
      "19762/19762 [==============================] - 14876s 753ms/step - loss: 0.7435 - acc: 0.7909 - val_loss: 0.5923 - val_acc: 0.8440\n",
      "Epoch 43/50\n",
      " 1392/19762 [=>............................] - ETA: 3:29:49 - loss: 0.7407 - acc: 0.7926"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(\n",
    "  train_generator,\n",
    "  steps_per_epoch = nb_train_samples // batch_size,\n",
    "  epochs = epochs,\n",
    "  validation_data = validation_generator,\n",
    "  validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = test_generator.filenames\n",
    "truth = test_generator.classes\n",
    "label = test_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "predicts = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "predict_class = np.argmax(predicts, axis=1)\n",
    "errors = np.where(predict_class != truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truth,predict_class)\n",
    "\n",
    "labels = []\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "    \n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, classes=labels,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve for each class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "y_pred = predicts\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = test_generator.classes\n",
    "\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "y_actual_binary = label_binarize(y_actual, classes=[0, 1])\n",
    "y_pred_binary = y_pred_probabilities#label_binarize(y_pred_probabilities, classes=[0, 1, 2, 3, 4])\n",
    "n_classes=2\n",
    "lw=2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_actual_binary[:, i], y_pred_binary[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_actual_binary.ravel(), y_pred_binary.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "\n",
    "colors = cycle(['red','blue','green','yellow','orange', 'aqua', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(classnames[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=2)\n",
    "\n",
    "\n",
    "colors = cycle(['red','blue','green','yellow','orange', 'aqua', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(classnames[i], roc_auc[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-classs')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('plots/1.Xception-ROC.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
    "print(confusion_mtx)\n",
    "target_names = classnames\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/5.InceptionV3-Public-DataSet-Model.h5')\n",
    "# model.save_weights('models/5.InceptionV3-Public-DataSet-Weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.regularizers import l2\n",
    "\n",
    "base_model = InceptionV3(input_shape=(192, 192, 3), weights='imagenet', include_top=False)\n",
    "x = base_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dense(1024, activation=\"relu\", kernel_regularizer=l2(0.001), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.4)(x)\n",
    "x = Dense(2048, activation=\"relu\", kernel_regularizer=l2(0.01), bias_regularizer=l2(0.0001))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dropout(0.6)(x)\n",
    "predictions = Dense(2, activation=\"softmax\", kernel_regularizer=l2(0.001), bias_regularizer=l2(0.0001))(x)\n",
    "model = Model(input = base_model.input, output = predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd=SGD(lr=1e-06, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "model.compile(optimizer = \"sgd\", loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(\n",
    "  train_generator,\n",
    "  steps_per_epoch = nb_train_samples // batch_size,\n",
    "  epochs = epochs,\n",
    "  validation_data = validation_generator,\n",
    "  validation_steps = nb_validation_samples // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Acc', 'Test Acc'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Training Loss', 'Test Loss'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "N = epochs\n",
    "plt.plot(np.arange(0, N), history.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), history.history[\"acc\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), history.history[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"upper left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate_generator(validation_generator, steps=50)\n",
    "\n",
    "print ('Validation Score: ', score[0])\n",
    "print ('Validation Accuracy: ',score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = test_generator.filenames\n",
    "truth = test_generator.classes\n",
    "label = test_generator.class_indices\n",
    "indexlabel = dict((value, key) for key, value in label.items())\n",
    "\n",
    "predicts = model.predict_generator(test_generator, steps=test_generator.samples/test_generator.batch_size, verbose=1)\n",
    "predict_class = np.argmax(predicts, axis=1)\n",
    "errors = np.where(predict_class != truth)[0]\n",
    "print(\"No of errors = {}/{}\".format(len(errors),test_generator.samples))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(truth,predict_class)\n",
    "\n",
    "labels = []\n",
    "for k,v in indexlabel.items():\n",
    "    labels.append(v)\n",
    "    \n",
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
    "    misclass = 1 - accuracy\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion Matrix')\n",
    "\n",
    "    print(cm)\n",
    "#     fig = plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label\\naccuracy={:0.4f}; misclass={:0.4f}'.format(accuracy, misclass))\n",
    "#     plt.savefig('plots/3.InceptionV3-2-Private-DataSet-CM.png', bbox_inches='tight', dpi = 100) \n",
    "# fig.savefig('plots/1.Xception-CM.png') \n",
    "plt.figure(figsize=(10,10))\n",
    "\n",
    "\n",
    "plot_confusion_matrix(cm, classes=labels,\n",
    "                      title='Confusion Matrix')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROC Curve for each class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "from scipy import interp\n",
    "from itertools import cycle\n",
    "\n",
    "y_pred = predicts\n",
    "y_pred_probabilities=y_pred\n",
    "\n",
    "y_pred = np.argmax(y_pred,axis = 1) \n",
    "y_actual = test_generator.classes\n",
    "\n",
    "classnames=[]\n",
    "for classname in test_generator.class_indices:\n",
    "    classnames.append(classname)\n",
    "\n",
    "y_actual_binary = label_binarize(y_actual, classes=[0, 1])\n",
    "y_pred_binary = y_pred_probabilities#label_binarize(y_pred_probabilities, classes=[0, 1, 2, 3, 4])\n",
    "n_classes=2\n",
    "lw=2\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_actual_binary[:, i], y_pred_binary[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_actual_binary.ravel(), y_pred_binary.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "# Compute macro-average ROC curve and ROC area\n",
    "\n",
    "# First aggregate all false positive rates\n",
    "all_fpr = np.unique(np.concatenate([fpr[i] for i in range(n_classes)]))\n",
    "\n",
    "# Then interpolate all ROC curves at this points\n",
    "mean_tpr = np.zeros_like(all_fpr)\n",
    "for i in range(n_classes):\n",
    "    mean_tpr += interp(all_fpr, fpr[i], tpr[i])\n",
    "\n",
    "# Finally average it and compute AUC\n",
    "mean_tpr /= n_classes\n",
    "\n",
    "fpr[\"macro\"] = all_fpr\n",
    "tpr[\"macro\"] = mean_tpr\n",
    "roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
    "\n",
    "# Plot all ROC curves\n",
    "plt.figure(figsize=(7, 7))\n",
    "\n",
    "\n",
    "colors = cycle(['red','blue','green','yellow','orange', 'aqua', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(classnames[i], roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class')\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zoom in view of the upper left corner.\n",
    "plt.figure(2)\n",
    "plt.xlim(0, 0.2)\n",
    "plt.ylim(0.8, 1)\n",
    "\n",
    "plt.plot(fpr[\"micro\"], tpr[\"micro\"],\n",
    "         label='micro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"micro\"]),\n",
    "         color='deeppink', linestyle=':', linewidth=2)\n",
    "\n",
    "plt.plot(fpr[\"macro\"], tpr[\"macro\"],\n",
    "         label='macro-average ROC curve (area = {0:0.2f})'\n",
    "               ''.format(roc_auc[\"macro\"]),\n",
    "         color='navy', linestyle=':', linewidth=2)\n",
    "\n",
    "\n",
    "colors = cycle(['red','blue','green','yellow','orange', 'aqua', 'cornflowerblue'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=lw,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(classnames[i], roc_auc[i]))\n",
    "\n",
    "    \n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-classs')\n",
    "plt.legend(loc=\"lower right\")\n",
    "# plt.savefig('plots/1.Xception-ROC.png') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_actual, y_pred) \n",
    "print(confusion_mtx)\n",
    "target_names = classnames\n",
    "print(classification_report(y_actual, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save('models/5.InceptionV3-L2-Public-DataSet-Model.h5')\n",
    "# model.save_weights('models/5.InceptionV3-L2-Public-DataSet-Weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
